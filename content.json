{"meta":{"title":"Jerry's Blog","subtitle":null,"description":null,"author":"Jerry Zhu","url":"https://zhusas.github.io"},"pages":[{"title":"about","date":"2018-06-01T08:02:08.000Z","updated":"2018-09-12T05:57:57.038Z","comments":true,"path":"about/index.html","permalink":"https://zhusas.github.io/about/index.html","excerpt":"","text":"飘在武汉，一个把他乡当故乡的人 网络上经常以 Jerry 之名出现 目前是一名运维工程师，专注于云计算、容器、高可用、网络、数据库和分布式技术 博客文章大部分是我原创，翻译和转载的文章在标题上已经注明 目前就职于网化商城，担任运维（运维就我一个人）"},{"title":"分类&标签","date":"2018-08-02T06:33:33.000Z","updated":"2018-08-02T06:34:22.904Z","comments":true,"path":"tags/index.html","permalink":"https://zhusas.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Ansible开车之路（一）","slug":"ansible-story","date":"2018-09-12T03:03:00.000Z","updated":"2018-09-12T08:55:28.917Z","comments":true,"path":"2018/09/12/ansible-story/","link":"","permalink":"https://zhusas.github.io/2018/09/12/ansible-story/","excerpt":"使用Ansible也有一段时间了，最近不是很忙，所以有时间来总结一下开车经验，温故而知新。 为什么要自动化？","text":"使用Ansible也有一段时间了，最近不是很忙，所以有时间来总结一下开车经验，温故而知新。 为什么要自动化？ Ansible 是一款功能十分强大的开源自动化工具。不同于其他管理工具的是，它还是一款部署和编排工具。可以从多方面大幅提升生产效率，轻松应对各种自动化挑战, 并可以为其他自动化解决方案的多项核心功能提供更有效的替代方案。其中的一个很酷的功能是如何在不停机的情况下，实现持续集成和持续部署 (CI/CD)。 我想在部署的时候冲杯咖啡喝，所以我要自动化。 为什么要实现零停机？出现停机和业务中断，不仅会造成企业的收入及声誉损失，还会影响客户的服务体验。对于业务和用户遍布全球所有时区的网化商城，只有在最严峻复杂的升级过程中才会进行停机处理（当然不包括更新应用版本），关键系统停机也会给生产效率带来重大影响。 因此，需要自动化部署流程，避免人为的操作失误带来的影响，来实现能够不影响运营能力的方式进行更新的目标，我们公司就是这种情况（这牛逼吹得。。。。。。） Ansible简介Ansilbe可以部署一群远程主机，远程的主机可以是远程虚拟机或物理机， 也可以是本地主机。Ansilbe通过SSH协议实现远程节点和管理节点之间的通信。理论上说，只要运维通过ssh登录到一台远程主机上能做的操作，Ansible都可以做到。 Ansible的架构及工作机制Ansilbe管理节点和远程主机节点通过ssh协议进行通信。所以Ansible配置的时候只需要保证从Ansible管理节点通过SSH能够连接到被管理的远程的远程节点即可。。但是SSH必须配置为公钥认证登录方式，而非密码认证。 执行Ansible或者Ansible-playbook（会读取Playbook文件）时，Ansible会遵循预先编排的规则将playbooks逐条拆解为Play，注意是逐条拆解啊，再将Play组织成Ansible可识别的Task，随后调用Task设计的所有Module和Plugin，根据Inventory中定义的主机列表通过SSH（Linux默认）将Task以零食文件或者命令的形式传输到远程主机执行并返回执行结果，如果是临时文件则执行完毕后自动删除。 接下来唠嗑一下上图的几个关键组成部分： USER：就是使用Ansible的人或程序（例如Jenkins构建成功后调用Ansible执行部署操作）。 INVENTORY：被管理的主机清单，Ansible根据这个文件来获知往哪些主机执行才做。 MODULES：执行Task中用到的功能模块，多数为内置的核心模块，也有扩展模块，Github上也有很多大牛开源的第三方模块，应有尽有。 PLUGINS：模块功能的补充，如连接类型插件、循环插件、变量插件等。 API：第三方程序调用的应用程序编程接口。 好了，还有不明白的可以自行谷歌，接下来把工作中用到Ansible的地方，以一例一一篇方式分享。","categories":[],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://zhusas.github.io/tags/Ansible/"}]},{"title":"Redis在Docker Swarm中的HA和LB","slug":"redis-service-on-swarm","date":"2018-09-11T05:41:00.000Z","updated":"2018-09-12T01:28:07.384Z","comments":true,"path":"2018/09/11/redis-service-on-swarm/","link":"","permalink":"https://zhusas.github.io/2018/09/11/redis-service-on-swarm/","excerpt":"业务场景之一Redis在业务场景中也很重要，涉及到的，所以这次迁移到docker swarm中来跑，目标是高可用及负载均衡，任意一台机器关掉，服务不中断。","text":"业务场景之一Redis在业务场景中也很重要，涉及到的，所以这次迁移到docker swarm中来跑，目标是高可用及负载均衡，任意一台机器关掉，服务不中断。 为什么用Docker Swarm service的方式这个是根据业务数据的写入方式来决定的，也考虑过Redis cluster，哨兵，swarm volume+分布式存储的方式，因为业务数据没有持久化的需求，仅仅是把redis当做业务多类型键值缓存服务来使用，所以这里保证Redis服务高可用即可。 docker swarm的搭建略过，不懂的同学可以自行Google（为什么不用百度，你懂的~~） Let’s do it!好，先建立Redis的服务，复制三个副本 1docker service create --name redis -p 6379:6379 --replicas 3 --restart-condition on-failure redis 看看运行效果： Good~，接下来配置HAproxy 先准备好配置文件，考虑一下部署策略，如果要以service方式来部署，建议采用分布式存储文件如Ceph，GlusterFS，OpenStack cinder等解决方案。这里条件有限，采取单机部署， 1docker run -d --name haproxy -v /data/haproxy_config:/usr/local/etc/haproxy -p 29000:29000 -p 443:443 -p 172.16.2.5:16379:16379 haproxy 备注：-v /data/haproxy_config:/usr/local/etc/haproxy 挂载编辑好的 配置文件到haproxy到容器里面 好，看看HAproxy的配置： 123456789101112frontend haproxy_redisbind *:16379mode tcplog globaldefault_backend redis_serverbackend redis_servermode tcpbalance sourceserver redis1 172.16.2.2:6379 check port 6379 inter 20s rise 2 fall 3server redis2 172.16.2.3:6379 check port 6379 inter 20s rise 2 fall 3server redis3 172.16.2.4:6379 check port 6379 inter 20s rise 2 fall 3 然后开始模拟测试，随意关掉一台，OK。应用仍能提供服务，再关掉一台，还有一台。 那有人说，全挂了咋办啊，额。。。。。。难道上线不做监控报警吗？第一台有问题了就应第一时间知道并处理了啊~~~","categories":[],"tags":[{"name":"haproxy","slug":"haproxy","permalink":"https://zhusas.github.io/tags/haproxy/"},{"name":"docker swarm","slug":"docker-swarm","permalink":"https://zhusas.github.io/tags/docker-swarm/"},{"name":"redis","slug":"redis","permalink":"https://zhusas.github.io/tags/redis/"}]},{"title":"memcached在docker swarm中的负载均衡","slug":"memecached-LB-swarm","date":"2018-09-05T06:52:00.000Z","updated":"2018-09-11T05:47:22.705Z","comments":true,"path":"2018/09/05/memecached-LB-swarm/","link":"","permalink":"https://zhusas.github.io/2018/09/05/memecached-LB-swarm/","excerpt":"话说上次在docker swarm里面实现了MongoDB复制集之后，可以愉快地重启运行复制集节点的机器了，存储的资料也不担心硬盘挂掉而丢失， 真是快哉~ 所以，再接再厉，把Redis和Memcached也迁移到docker swarm跑起来。 先来说说memcached的业务场景及特性，知己知彼，百战百胜嘛","text":"话说上次在docker swarm里面实现了MongoDB复制集之后，可以愉快地重启运行复制集节点的机器了，存储的资料也不担心硬盘挂掉而丢失， 真是快哉~ 所以，再接再厉，把Redis和Memcached也迁移到docker swarm跑起来。 先来说说memcached的业务场景及特性，知己知彼，百战百胜嘛 memcached场景之一 用户要是忘记了密码，或者新注册用户等，总之在需要接收手机短信验证码的时候，得先输入正确的验证码，应用在生成图形验证码的时候，会往memecached里面写入验证码的哈希值，跟用户输入转换的哈希值作比较。 所以，这是一个对可用性有要求的场景，辣么，memcached必须不能单实例跑了（你看上图是一群）。 memcached特性 在Memcached中可以保存的item数据量是没有限制的，只要内存足够； Memcached单进程最大使用内存为2GB，要使用更多内存，可以分别在不同端口启动多个Memcached进程； Memcached是一种无阻塞的socket通信方式的服务，基于libevent库，由于无阻塞通信，对内存读写速度非常之快； Memcached分为服务器和客户端，可以配置多个服务器和客户端，应用于分布式的服务非常广泛； Memcached作为小规模的数据分布式平台是非常高效的； memcached存在的问题 本身没有内置分布式功能，无法实现使用多台memcachd服务器来存储不同的数据，最大程度的使用相同的资源。服务器之间没有任何通信，并且不进行任何数据复制备份，所以当任何服务器节点出现故障时，会出现单点故障，如果需要实现高可用，就需要通过其他方式。 那么有问题，就会有解决方案，来张图： 这次要用到跨主机通讯，当您需要在不同Docker主机上运行的容器进行通信时，或者当多个应用程序使用swarm服务协同工作时，Overlay networks是最佳选择。 haproxy之上是应用，不考虑会话保持之类，纯粹在应用和memcached之间充当一个tcp负载均衡。 这里使用默认的overlay网络 为什么要加HAproxy？虽然docker的overlay网络能实现内部的负载均衡，但是万一swarm内运行服务的某节点挂了，IP都不通，那如何是好啊，该加还是得加。 那HAproxy挂了呢，挂了就上keepalived，利用vrrp协议，避免单点，这里不铺开。 先建立memcached的service 1docker service create --name memcached --replicas=3 -p 11211:11211 memcached 名为memcached且开放了11211端口的service，三个swarm节点上都有容器实例。 启动并配置HAproxy 配置文件相关配置段如下： 123456789101112frontend haproxy_memcachedbind *:8090mode tcplog globaldefault_backend memcached_serverbackend memcached_servermode tcpbalance sourceserver memcached1 172.16.10.1:11211 checkserver memcached2 172.16.10.2:11211 checkserver memcached3 172.16.10.3:11211 check balance sourceharoxy 将用户IP经过hash计算后 指定到固定的真实服务器上（类似于nginx 的IP hash 指令） 172.16.10.1~3运行memcached service的docker swarm节点IP 容器服务还有自动重新启动策略，重启策略控制Docker守护程序在退出后是否重新启动容器。Docker支持以下重启策略：none、on-failure、any， 默认为any。 OK，打完收工。","categories":[],"tags":[{"name":"memcached","slug":"memcached","permalink":"https://zhusas.github.io/tags/memcached/"},{"name":"docker swarm","slug":"docker-swarm","permalink":"https://zhusas.github.io/tags/docker-swarm/"},{"name":"HAproxy","slug":"HAproxy","permalink":"https://zhusas.github.io/tags/HAproxy/"}]},{"title":"HAproxy解决nginx-gridfs在MongoDB副本集选举后的读取问题","slug":"haproxy-replica-set","date":"2018-08-08T05:47:00.000Z","updated":"2018-09-12T01:25:21.900Z","comments":true,"path":"2018/08/08/haproxy-replica-set/","link":"","permalink":"https://zhusas.github.io/2018/08/08/haproxy-replica-set/","excerpt":"接上回，自从搭建起副本集之后，很嗨，再也不担心单机挂了之后数据丢失了。应用往MongoDB副本集写也做了相应配置。 在做nginx读取MongoDB副本集数据测试中，发现了新问题","text":"接上回，自从搭建起副本集之后，很嗨，再也不担心单机挂了之后数据丢失了。应用往MongoDB副本集写也做了相应配置。 在做nginx读取MongoDB副本集数据测试中，发现了新问题 按照 https://github.com/mdirolf/nginx-gridfs 中连接副本集的配置例子，如下： 123456location /gridfs/ &#123; gridfs my_app field=filename type=string; mongo &quot;foo&quot; 10.7.2.27:27017 10.7.2.28:27017;&#125; 在主节点关闭后，其设置的第二个节点是不起作用的（我设置了五个，均不起作用，nginx读取MongoDB节点中的文件报错） 由此可见nginx-gridfs插件这里是有问题的，但是我们的web服务器已经在使用了这个插件，不能轻易更换，只能另寻他法。 经过测试，发现副本集在原主节点挂掉后，余下节点（包括新选举的主节点和从节点）都可以使用直连模式来读取文件。 于是一个大胆的想法浮现了，何不在nginx和副本集之间加个负载均衡器？ 嗯，我选了HAproxy。 HAproxy的介绍百度一大堆，我就不重复了，直接上配置文件（部分以变量代替） 123456789101112131415161718192021222324252627282930global maxconn 50000 #默认最大连接数,需考虑ulimit-n限制 log 127.0.0.1 local0defaults mode tcp #四层反向代理，不受套接字文件数量限制 timeout connect 20s #haproxy将客户端请求转发至后端服务器所等待的超时时长 timeout client 30s #客户端非活动状态的超时时长 timeout server 30s #客户端与服务器端建立连接后，等待服务器端的超时时长 timeout check 10s #健康状态监测时的超时时间，过短会误判，过长资源消耗\\ timeout http-keep-alive 60s #长连接超时 #option redispatch #当使用了cookie时，haproxy将会将其请求的后端服务器的serverID插入到cookie中，以保证会话的SESSION持久性 #retries 3 #后端服务器的失败重连次数，链接失败次数超过此处值会将对应后端服务器标记不可用frontend mongo-in bind *:29000 log global #使用全局日志配置 #option tcplog #option dontlognull default_backend mongo #定义默认转发的后端服务器backend mongo #定义后端服务群default_servers balance roundrobin #分发策略,这里是轮询模式 #check启用健康监测，监测MongoDB的服务端口，每个2秒监测一次，失败3次标记为不可用，成功2次恢复为可用 server mongo_rs1 $MONGODB_RS1_IP:$MONGODB_PORT check port $MONGODB_PORT inter 2s rise 2 fall 3 server mongo_rs2 $MONGODB_RS2_IP:$MONGODB_PORT check port $MONGODB_PORT inter 2s rise 2 fall 3 server mongo_rs3 $MONGODB_RS3_IP:$MONGODB_PORT check port $MONGODB_PORT inter 2s rise 2 fall 3 server mongo_rs4 $MONGODB_RS4_IP:$MONGODB_PORT check port $MONGODB_PORT inter 2s rise 2 fall 3 server mongo_rs5 $MONGODB_RS5_IP:$MONGODB_PORT check port $MONGODB_PORT inter 2s rise 2 fall 3 上了之后，问题解决，哈哈哈哈哈。。。。。。。。。。。。。。。。。 总结 如果用HAproxy转发HTTP连接，须考虑Linux的open files限制，如果是tcp的代理，可以忽略，其在内核就完成转发了。 多看官方文档。 任何解决方案都要考虑业务场景的真实需求。 这里因为对从节点的数据实时性要求不是即时同步，首要需求是数据的多份拷贝的完整性和服务的高可用。","categories":[],"tags":[{"name":"haproxy","slug":"haproxy","permalink":"https://zhusas.github.io/tags/haproxy/"},{"name":"replica set","slug":"replica-set","permalink":"https://zhusas.github.io/tags/replica-set/"},{"name":"mongodb","slug":"mongodb","permalink":"https://zhusas.github.io/tags/mongodb/"},{"name":"nginx","slug":"nginx","permalink":"https://zhusas.github.io/tags/nginx/"}]},{"title":"Ansible和Docker Swarm还有MongoDB Replica Set","slug":"nsible和Docker-Swarm还有MongoDB-Replica-Set","date":"2018-08-07T06:34:00.000Z","updated":"2018-09-07T02:51:39.984Z","comments":true,"path":"2018/08/07/nsible和Docker-Swarm还有MongoDB-Replica-Set/","link":"","permalink":"https://zhusas.github.io/2018/08/07/nsible和Docker-Swarm还有MongoDB-Replica-Set/","excerpt":"工作需要，Let’s do it. 策略 事先确定Replica Set的成员数量，因为这跟能Replica Set中能容忍挂掉的成员数量有直接关系 Replica Set中的voting成员数量要提前确定，MongoDB的Replica Set最大可以拥有50个成员，其中包括最多7个voting成员 部署奇数成员数的Replica Set 操作系统采用Ubuntu16.04.4 LTS 64bit 原计划五台机器单机跑docker实例，也可以创建replica set ，但是日后还有其他测试要用到swarm环境，所以干脆一步到位，五台机器全部作为swarm node","text":"工作需要，Let’s do it. 策略 事先确定Replica Set的成员数量，因为这跟能Replica Set中能容忍挂掉的成员数量有直接关系 Replica Set中的voting成员数量要提前确定，MongoDB的Replica Set最大可以拥有50个成员，其中包括最多7个voting成员 部署奇数成员数的Replica Set 操作系统采用Ubuntu16.04.4 LTS 64bit 原计划五台机器单机跑docker实例，也可以创建replica set ，但是日后还有其他测试要用到swarm环境，所以干脆一步到位，五台机器全部作为swarm node IP规划 Replica Set 角色 swarm角色 物理机器名 IP CPU 内存 主节点 管理节点 docker-swarm01 192.168.0.233 i5-4590 8G 从节点 工作节点 docker-swarm02 192.168.0.232 Celeron G1840 8G 从节点 工作节点 docker-swarm03 192.168.0.242 i7-4790 16G 从节点 工作节点 docker-swarm04 192.168.0.241 i7-6700 8G 从节点 工作节点 docker-swarm05 192.168.0.230 i5-4590 8G 按照表格规划好的，修改各机器的IP和机器名 这里我们使用五台机器搭建swarm集群，root账号操作，顺序如下： 准备工作，免密登录，初始化设置等。 替换系统的默认软件源为网易镜像源。 增加科技大docker安装源，安装好docker-ce最新稳定版本。 docker hub镜像源替换为国内DaoCloud加速源。（你也可以用已有的docker hub加速器） 上传MongoDB测试数据（这一步可以提前上传到主节点），这里我上传到了docker-swarm01。 建立docker swarm，并把各节点加入swarm。 每个节点建立存放MongoDB的数据volume，并做好命名工作。 每个节点建立MongoDB Replica Set的节点service，并做好命名工作。 初始化MongoDB Replica Set。 还原备份数据到Replica Set中。 查看数据同步情况，确认同步完毕。 进行访问测试。 准备工作1、配置IP地址，ubuntu16.04的话，修改/etc/network/interfaces文件即可。 2、配置Ansible与目标机器的ssh免密登录，这里以swarm01为例。 123456# 生成ssh keyssh-keygen -t rsa -b 8192 -C Ansible-key# 拷贝ssh key到远程主机，ssh的时候就不需要输入密码了ssh-copy-id root@192.168.0.233 # ssh的时候不会提示是否保存keyssh-keyscan 192.168.0.233 &gt;&gt; ~/.ssh/known_hosts 3、修改/etc/ansible/hosts和/etc/hosts文件 不修改/etc/hosts的话，Ansible会报错 /etc/hosts文件加入以下内容： 12345192.168.0.233 swarm01192.168.0.232 swarm02192.168.0.242 swarm03192.168.0.241 swarm04192.168.0.230 swarm05 /etc/ansible/hosts文件加入以下内容： 123456[swarm]swarm01 ansble_ssh_host=192.168.0.233 ansible_ssh_port=22 ansible_ssh_user=\"root\"swarm02 ansble_ssh_host=192.168.0.232 ansible_ssh_port=22 ansible_ssh_user=\"root\"swarm03 ansble_ssh_host=192.168.0.242 ansible_ssh_port=22 ansible_ssh_user=\"root\"swarm04 ansble_ssh_host=192.168.0.241 ansible_ssh_port=22 ansible_ssh_user=\"root\"swarm05 ansble_ssh_host=192.168.0.230 ansible_ssh_port=22 ansible_ssh_user=\"root\" 替换系统的默认软件源为网易镜像源12345#这里采用Ansible的copy模块+修改好的sources.list文件上传到对应位置即可ansible swarm -m copy -a \"src=/opt/sources.list dest=/etc/apt/sources.list owner=root group=root mode=0644 backup=yes\"#给swarm各节点系统升级软件包ansible swarm -m apt -a \"force_apt_get=yes state=latest upgrade=yes update_cache=yes autoremove=yes\" 增加科技大docker安装源，安装好docker-ce最新稳定版本一键脚本在此 https://github.com/zhusas/docker-ce.init.git 这个脚本也包含了docker hub镜像源替换为国内自定义加速源。 这是之前写的一个脚本，用ansible的script模块可以使用，其内容也可以写成playbook，这里就直接用脚本操作，日后再完善playbook，放到Github上。 123456789101112131415#批量运行脚本ansible swarm -m script -a \"/opt/docker-ce.repo.init.sh\"#验证一下安装的docker版本root@Ansible:/opt# ansible swarm -a \"docker -v\"swarm01 | SUCCESS | rc=0 &gt;&gt;Docker version 18.03.1-ce, build 9ee9f40swarm03 | SUCCESS | rc=0 &gt;&gt;Docker version 18.03.1-ce, build 9ee9f40swarm05 | SUCCESS | rc=0 &gt;&gt;Docker version 18.03.1-ce, build 9ee9f40swarm02 | SUCCESS | rc=0 &gt;&gt;Docker version 18.03.1-ce, build 9ee9f40swarm04 | SUCCESS | rc=0 &gt;&gt;Docker version 18.03.1-ce, build 9ee9f40 建立docker swarm，并把各节点加入swarm以下端口必须保持畅通： TCP port 2377 ：swarm集群管理信息通讯端口 TCP and UDP port 7946 ：swarm节点之间的通讯端口 UDP port 4789 ： overlay网络通讯端口 如果你建立了一个加密的overlay网络 (–opt encrypted)，你还徐确保 ip protocol 50 (ESP) 能够正常通讯。 下面开始操作： 123456789101112131415161718192021root@Ansible:/opt# ansible swarm01 -m shell -a \"docker swarm init --advertise-addr 192.168.0.233\" swarm01 | SUCCESS | rc=0 &gt;&gt;Swarm initialized: current node (wum4rkn8jk4qb97yib9kggirv) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-5wooyyq98crvrs0zv49ktg0bguua90k7in2ij1me81ljfgpkqt-7o9simk0nit9avq3637gzh0a5 192.168.0.233:2377To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.root@Ansible:/opt# ansible swarm -m shell -a \"docker swarm join --token SWMTKN-1-5wooyyq98crvrs0zv49ktg0bguua90k7in2ij1me81ljfgpkqt-7o9simk0nit9avq3637gzh0a5 192.168.0.233:2377\"swarm01 | FAILED | rc=1 &gt;&gt;Error response from daemon: This node is already part of a swarm. Use \"docker swarm leave\" to leave this swarm and join another one.non-zero return codeswarm03 | SUCCESS | rc=0 &gt;&gt;This node joined a swarm as a worker.swarm04 | SUCCESS | rc=0 &gt;&gt;This node joined a swarm as a worker.swarm05 | SUCCESS | rc=0 &gt;&gt;This node joined a swarm as a worker.swarm02 | SUCCESS | rc=0 &gt;&gt;This node joined a swarm as a worker.root@Ansible:/opt# 可以看到，建立了swarm管理节点之后，运行docker swarm join命令，swarm01会报“Error response from daemon: This node is already part of a swarm. Use “docker swarm leave” to leave this swarm and join another one.non-zero return code”，意思是提醒你这已经是swarm的一部分了，不过没关系，哈哈。swarm02~05已经顺利加入。 我们用命令看看 OK了。 这里提醒一下的是，一般服务器都是网卡，建立swarm时候，最好加上–listen-addr 参数。我这里测试的机器都是单网卡，影响不大。各位切记哦。 明确一下计划基本计划是将MongoDB副本集的每个成员定义为单独的swarm服务，并使用docker service的约束参数来防止swarm的scaling特性将它们从数据卷移开，因为数据卷存放在每个节点上，没法跟着容器漂移到其他节点， 这保留了Docker提供的所有操作优势，同时消除了scaling故障恢复功能（会影响MongoDB副本集的可用性）。通过命令将MongoDB服务固定到与其数据卷相同的swarm节点，在每个节点上设置标签。 稍后在创建服务时，将在约束中使用这些标签。 给swarm各节点加标签123456789101112131415root@Ansible:~# ansible swarm01 -m shell -a \"docker node update --label-add mongo.rs=1 docker-swarm01\"swarm01 | SUCCESS | rc=0 &gt;&gt;docker-swarm01root@Ansible:~# ansible swarm01 -m shell -a \"docker node update --label-add mongo.rs=2 docker-swarm02\"swarm01 | SUCCESS | rc=0 &gt;&gt;docker-swarm02root@Ansible:~# ansible swarm01 -m shell -a \"docker node update --label-add mongo.rs=3 docker-swarm03\"swarm01 | SUCCESS | rc=0 &gt;&gt;docker-swarm03root@Ansible:~# ansible swarm01 -m shell -a \"docker node update --label-add mongo.rs=4 docker-swarm04\"swarm01 | SUCCESS | rc=0 &gt;&gt;docker-swarm04root@Ansible:~# ansible swarm01 -m shell -a \"docker node update --label-add mongo.rs=5 docker-swarm05\"swarm01 | SUCCESS | rc=0 &gt;&gt;docker-swarm05 这步感觉不够优雅，此时playbook的价值就体现出来了。我这是为了展现详细步骤才这样。 建立MongoDB replica set在docker swarm的overlay专用网络swarm跨节点通讯必备 123456789101112131415161718192021222324252627282930313233343536373839root@Ansible:~# ansible swarm01 -m docker_network -a \"name=mongo_network driver=overlay\"swarm01 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"docker_network\": &#123; \"Attachable\": false, \"ConfigFrom\": &#123; \"Network\": \"\" &#125;, \"ConfigOnly\": false, \"Containers\": null, \"Created\": \"2018-07-16T08:29:15.88390955Z\", \"Driver\": \"\", \"EnableIPv6\": false, \"IPAM\": &#123; \"Config\": [], \"Driver\": \"default\", \"Options\": null &#125;, \"Id\": \"ku3waawi7hqrj02zh9sfvgcfk\", \"Ingress\": false, \"Internal\": false, \"Labels\": null, \"Name\": \"mongo_network\", \"Options\": null, \"Scope\": \"swarm\" &#125; &#125;, \"changed\": true&#125;root@Ansible:~# ansible swarm01 -a \"docker network ls\"swarm01 | SUCCESS | rc=0 &gt;&gt;NETWORK ID NAME DRIVER SCOPE4127d48c4ee3 bridge bridge local898954254fae docker_gwbridge bridge localce65005a6830 host host localsqsf18n9lco7 ingress overlay swarmku3waawi7hqr mongo_network overlay swarmd7d752f1abcc none null local 建立存放MongoDB的数据Volume123456789101112131415root@Ansible:~# ansible swarm01 -m docker_volume -a \"name=rsdata1\"swarm01 | SUCCESS =&gt; &#123; \"ansible_facts\": &#123; \"docker_volume\": &#123; \"CreatedAt\": \"2018-07-16T16:40:16+08:00\", \"Driver\": \"local\", \"Labels\": null, \"Mountpoint\": \"/var/lib/docker/volumes/rsdata1/_data\", \"Name\": \"rsdata1\", \"Options\": &#123;&#125;, \"Scope\": \"local\" &#125; &#125;, \"changed\": true&#125; 其他四台以此类推，建立volume。 建立完毕后，如下： 12345678910111213141516root@Ansible:/opt# ansible swarm -a \"docker volume ls\"swarm03 | SUCCESS | rc=0 &gt;&gt;DRIVER VOLUME NAMElocal rsdata3swarm05 | SUCCESS | rc=0 &gt;&gt;DRIVER VOLUME NAMElocal rsdata5swarm01 | SUCCESS | rc=0 &gt;&gt;DRIVER VOLUME NAMElocal rsdata1swarm04 | SUCCESS | rc=0 &gt;&gt;DRIVER VOLUME NAMElocal rsdata4swarm02 | SUCCESS | rc=0 &gt;&gt;DRIVER VOLUME NAMElocal rsdata2 在swarm01（管理节点）上建立replica set各个节点服务123456789docker service create --replicas 1 --network mongo_network --mount type=volume,source=rsdata1,target=/data/db --constraint 'node.labels.mongo.rs==1' -p 27017:27017 --name mongo_rs1 mongo:3.6 mongod --replSet \"whmallRS\"docker service create --replicas 1 --network mongo_network --mount type=volume,source=rsdata2,target=/data/db --constraint 'node.labels.mongo.rs==2' -p 27018:27017 --name mongo_rs2 mongo:3.6 mongod --replSet \"whmallRS\"docker service create --replicas 1 --network mongo_network --mount type=volume,source=rsdata3,target=/data/db --constraint 'node.labels.mongo.rs==3' -p 27019:27017 --name mongo_rs3 mongo:3.6 mongod --replSet \"whmallRS\"docker service create --replicas 1 --network mongo_network --mount type=volume,source=rsdata4,target=/data/db --constraint 'node.labels.mongo.rs==4' -p 27020:27017 --name mongo_rs4 mongo:3.6 mongod --replSet \"whmallRS\"docker service create --replicas 1 --network mongo_network --mount type=volume,source=rsdata5,target=/data/db --constraint 'node.labels.mongo.rs==5' -p 27021:27017 --name mongo_rs5 mongo:3.6 mongod --replSet \"whmallRS\" -p &lt;发布端口&gt;:&lt;目标端口&gt;&lt;目标端口&gt;为Docker容器中所监听的端口，&lt;发布端口&gt;为Swarm集群中使得服务可以访问的端口。 –constraint ‘node.labels.mongo.rs==2’这个参数作用是通过定义约束表达式来限制可以调度任务的节点，因为没做分布式存储，万一docker-swarm02上mongo.rs2这个服务飘到了docker-swarm05上去了，服务读取不到数据，那就懵逼了。必须找行政妹子多搞几台PC做分布式存储，GlusterFS就不错。。。。。 必须的~~ 看看状况 初始化MongoDB Replica Set123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194#初始化命令docker exec -it $(docker ps -qf label=com.docker.swarm.service.name=mongo_rs1) mongo --eval 'rs.initiate( &#123; _id : \"whmallRS\", members: [&#123; _id: 1, host: \"mongo_rs1:27017\" &#125;, &#123; _id: 2, host: \"mongo_rs2:27017\" &#125;, &#123; _id: 3, host: \"mongo_rs3:27017\" &#125;, &#123; _id: 4, host: \"mongo_rs4:27017\" &#125;, &#123; _id: 5, host: \"mongo_rs5:27017\" &#125;], settings: &#123; getLastErrorDefaults: &#123; w: \"majority\", wtimeout: 30000 &#125;&#125;&#125;)'MongoDB shell version v3.6.6connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.6.6&#123; \"ok\" : 1, \"operationTime\" : Timestamp(1531928549, 1), \"$clusterTime\" : &#123; \"clusterTime\" : Timestamp(1531928549, 1), \"signature\" : &#123; \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"), \"keyId\" : NumberLong(0) &#125; &#125;&#125;#查看replica set状态docker exec -it $(docker ps -qf label=com.docker.swarm.service.name=mongo_rs1) mongo --eval 'rs.status()'MongoDB shell version v3.6.6connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.6.6&#123; \"set\" : \"whmallRS\", \"date\" : ISODate(\"2018-07-18T15:44:54.605Z\"), \"myState\" : 1, \"term\" : NumberLong(1), \"syncingTo\" : \"\", \"syncSourceHost\" : \"\", \"syncSourceId\" : -1, \"heartbeatIntervalMillis\" : NumberLong(2000), \"optimes\" : &#123; \"lastCommittedOpTime\" : &#123; \"ts\" : Timestamp(1531928691, 1), \"t\" : NumberLong(1) &#125;, \"readConcernMajorityOpTime\" : &#123; \"ts\" : Timestamp(1531928691, 1), \"t\" : NumberLong(1) &#125;, \"appliedOpTime\" : &#123; \"ts\" : Timestamp(1531928691, 1), \"t\" : NumberLong(1) &#125;, \"durableOpTime\" : &#123; \"ts\" : Timestamp(1531928691, 1), \"t\" : NumberLong(1) &#125; &#125;, \"members\" : [ &#123; \"_id\" : 1, \"name\" : \"mongo_rs1:27017\", \"health\" : 1, \"state\" : 1, \"stateStr\" : \"PRIMARY\", \"uptime\" : 1103, \"optime\" : &#123; \"ts\" : Timestamp(1531928691, 1), \"t\" : NumberLong(1) &#125;, \"optimeDate\" : ISODate(\"2018-07-18T15:44:51Z\"), \"syncingTo\" : \"\", \"syncSourceHost\" : \"\", \"syncSourceId\" : -1, \"infoMessage\" : \"\", \"electionTime\" : Timestamp(1531928560, 1), \"electionDate\" : ISODate(\"2018-07-18T15:42:40Z\"), \"configVersion\" : 1, \"self\" : true, \"lastHeartbeatMessage\" : \"\" &#125;, &#123; \"_id\" : 2, \"name\" : \"mongo_rs2:27017\", \"health\" : 1, \"state\" : 2, \"stateStr\" : \"SECONDARY\", \"uptime\" : 145, \"optime\" : &#123; \"ts\" : Timestamp(1531928691, 1), \"t\" : NumberLong(1) &#125;, \"optimeDurable\" : &#123; \"ts\" : Timestamp(1531928691, 1), \"t\" : NumberLong(1) &#125;, \"optimeDate\" : ISODate(\"2018-07-18T15:44:51Z\"), \"optimeDurableDate\" : ISODate(\"2018-07-18T15:44:51Z\"), \"lastHeartbeat\" : ISODate(\"2018-07-18T15:44:54.127Z\"), \"lastHeartbeatRecv\" : ISODate(\"2018-07-18T15:44:54.464Z\"), \"pingMs\" : NumberLong(0), \"lastHeartbeatMessage\" : \"\", \"syncingTo\" : \"mongo_rs1:27017\", \"syncSourceHost\" : \"mongo_rs1:27017\", \"syncSourceId\" : 1, \"infoMessage\" : \"\", \"configVersion\" : 1 &#125;, &#123; \"_id\" : 3, \"name\" : \"mongo_rs3:27017\", \"health\" : 1, \"state\" : 2, \"stateStr\" : \"SECONDARY\", \"uptime\" : 145, \"optime\" : &#123; \"ts\" : Timestamp(1531928691, 1), \"t\" : NumberLong(1) &#125;, \"optimeDurable\" : &#123; \"ts\" : Timestamp(1531928691, 1), \"t\" : NumberLong(1) &#125;, \"optimeDate\" : ISODate(\"2018-07-18T15:44:51Z\"), \"optimeDurableDate\" : ISODate(\"2018-07-18T15:44:51Z\"), \"lastHeartbeat\" : ISODate(\"2018-07-18T15:44:54.117Z\"), \"lastHeartbeatRecv\" : ISODate(\"2018-07-18T15:44:54.276Z\"), \"pingMs\" : NumberLong(0), \"lastHeartbeatMessage\" : \"\", \"syncingTo\" : \"mongo_rs1:27017\", \"syncSourceHost\" : \"mongo_rs1:27017\", \"syncSourceId\" : 1, \"infoMessage\" : \"\", \"configVersion\" : 1 &#125;, &#123; \"_id\" : 4, \"name\" : \"mongo_rs4:27017\", \"health\" : 1, \"state\" : 2, \"stateStr\" : \"SECONDARY\", \"uptime\" : 145, \"optime\" : &#123; \"ts\" : Timestamp(1531928691, 1), \"t\" : NumberLong(1) &#125;, \"optimeDurable\" : &#123; \"ts\" : Timestamp(1531928691, 1), \"t\" : NumberLong(1) &#125;, \"optimeDate\" : ISODate(\"2018-07-18T15:44:51Z\"), \"optimeDurableDate\" : ISODate(\"2018-07-18T15:44:51Z\"), \"lastHeartbeat\" : ISODate(\"2018-07-18T15:44:54.186Z\"), \"lastHeartbeatRecv\" : ISODate(\"2018-07-18T15:44:54.583Z\"), \"pingMs\" : NumberLong(1), \"lastHeartbeatMessage\" : \"\", \"syncingTo\" : \"mongo_rs1:27017\", \"syncSourceHost\" : \"mongo_rs1:27017\", \"syncSourceId\" : 1, \"infoMessage\" : \"\", \"configVersion\" : 1 &#125;, &#123; \"_id\" : 5, \"name\" : \"mongo_rs5:27017\", \"health\" : 1, \"state\" : 2, \"stateStr\" : \"SECONDARY\", \"uptime\" : 145, \"optime\" : &#123; \"ts\" : Timestamp(1531928691, 1), \"t\" : NumberLong(1) &#125;, \"optimeDurable\" : &#123; \"ts\" : Timestamp(1531928691, 1), \"t\" : NumberLong(1) &#125;, \"optimeDate\" : ISODate(\"2018-07-18T15:44:51Z\"), \"optimeDurableDate\" : ISODate(\"2018-07-18T15:44:51Z\"), \"lastHeartbeat\" : ISODate(\"2018-07-18T15:44:54.119Z\"), \"lastHeartbeatRecv\" : ISODate(\"2018-07-18T15:44:54.401Z\"), \"pingMs\" : NumberLong(0), \"lastHeartbeatMessage\" : \"\", \"syncingTo\" : \"mongo_rs1:27017\", \"syncSourceHost\" : \"mongo_rs1:27017\", \"syncSourceId\" : 1, \"infoMessage\" : \"\", \"configVersion\" : 1 &#125; ], \"ok\" : 1, \"operationTime\" : Timestamp(1531928691, 1), \"$clusterTime\" : &#123; \"clusterTime\" : Timestamp(1531928691, 1), \"signature\" : &#123; \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"), \"keyId\" : NumberLong(0) &#125; &#125;&#125; 这一个基于docker swarm的MongoDB Replica Set就成了。 以上适合新建MongoDB副本集的情况，要是原来就是单实例，数据也备份了，要升级为副本集怎么办啊，那就继续往下看吧。 还原备份数据到Replica Set中备份数据先准备好，解压到volume在宿主机上的路径 启动一个单节点的副本集 先删除原来的所有服务，回到docker swarm刚搭建完毕的时候 12345678910111213#删除服务docker service rm mongo_rs1 mongo_rs2 mongo_rs3 mongo_rs4 mongo_rs5#确认swarm的节点状态docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSIONwum4rkn8jk4qb97yib9kggirv * docker-swarm01 Ready Active Leader 18.03.1-cebimxst6zhx732ckule02fozrb docker-swarm02 Ready Active 18.03.1-cewnb80zj4ltg5fvfpdfel8dmoe docker-swarm03 Ready Active 18.03.1-ce8hnm8uht550vuvljwk4zqym8u docker-swarm04 Ready Active 18.03.1-ce9i2q8ovsca5lwfzkympnmdcm0 docker-swarm05 Ready Active 18.03.1-ce ​ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139#启动一个单节点的副本集docker service create --replicas 1 --network mongo_network --mount type=volume,src=rsdata1,dst=/data/db --constraint 'node.labels.mongo.rs==1' -p 27017:27017 --name mongo_rs1 mongo:3.6 mongod --replSet \"whmallRS\"3idwgelktbji869q10z31fi0eoverall progress: 1 out of 1 tasks 1/1: running [==================================================&gt;] verify: Service converged #初始化副本集docker exec -it $(docker ps -qf label=com.docker.swarm.service.name=mongo_rs1) mongo --eval 'rs.initiate( &#123; _id : \"whmallRS\", members: [ &#123; _id : 1, host: \"mongo_rs1:27017\" &#125; ], settings: &#123; getLastErrorDefaults: &#123; w: \"majority\", wtimeout: 30000 &#125;&#125;&#125;)'MongoDB shell version v3.6.6connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.6.6&#123; \"ok\" : 1, \"operationTime\" : Timestamp(1531987463, 1), \"$clusterTime\" : &#123; \"clusterTime\" : Timestamp(1531987463, 1), \"signature\" : &#123; \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"), \"keyId\" : NumberLong(0) &#125; &#125;&#125;#查看副本集状态docker exec -it $(docker ps -qf label=com.docker.swarm.service.name=mongo_rs1) mongo --eval 'rs.status()'MongoDB shell version v3.6.6connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.6.6&#123; \"set\" : \"whmallRS\", \"date\" : ISODate(\"2018-07-19T08:06:30.690Z\"), \"myState\" : 1, \"term\" : NumberLong(1), \"syncingTo\" : \"\", \"syncSourceHost\" : \"\", \"syncSourceId\" : -1, \"heartbeatIntervalMillis\" : NumberLong(2000), \"optimes\" : &#123; \"lastCommittedOpTime\" : &#123; \"ts\" : Timestamp(1531987585, 1), \"t\" : NumberLong(1) &#125;, \"readConcernMajorityOpTime\" : &#123; \"ts\" : Timestamp(1531987585, 1), \"t\" : NumberLong(1) &#125;, \"appliedOpTime\" : &#123; \"ts\" : Timestamp(1531987585, 1), \"t\" : NumberLong(1) &#125;, \"durableOpTime\" : &#123; \"ts\" : Timestamp(1531987585, 1), \"t\" : NumberLong(1) &#125; &#125;, \"members\" : [ &#123; \"_id\" : 1, \"name\" : \"mongo_rs1:27017\", \"health\" : 1, \"state\" : 1, \"stateStr\" : \"PRIMARY\", \"uptime\" : 875, \"optime\" : &#123; \"ts\" : Timestamp(1531987585, 1), \"t\" : NumberLong(1) &#125;, \"optimeDate\" : ISODate(\"2018-07-19T08:06:25Z\"), \"syncingTo\" : \"\", \"syncSourceHost\" : \"\", \"syncSourceId\" : -1, \"infoMessage\" : \"\", \"electionTime\" : Timestamp(1531987463, 2), \"electionDate\" : ISODate(\"2018-07-19T08:04:23Z\"), \"configVersion\" : 1, \"self\" : true, \"lastHeartbeatMessage\" : \"\" &#125; ], \"ok\" : 1, \"operationTime\" : Timestamp(1531987585, 1), \"$clusterTime\" : &#123; \"clusterTime\" : Timestamp(1531987585, 1), \"signature\" : &#123; \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"), \"keyId\" : NumberLong(0) &#125; &#125;&#125;#查看副本集配置docker exec -it $(docker ps -qf label=com.docker.swarm.service.name=mongo_rs1) mongo --eval 'rs.config()'MongoDB shell version v3.6.6connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.6.6&#123; \"_id\" : \"whmallRS\", \"version\" : 1, \"protocolVersion\" : NumberLong(1), \"members\" : [ &#123; \"_id\" : 1, \"host\" : \"mongo_rs1:27017\", \"arbiterOnly\" : false, \"buildIndexes\" : true, \"hidden\" : false, \"priority\" : 1, \"tags\" : &#123; &#125;, \"slaveDelay\" : NumberLong(0), \"votes\" : 1 &#125;],\"settings\" : &#123; \"chainingAllowed\" : true, \"heartbeatIntervalMillis\" : 2000, \"heartbeatTimeoutSecs\" : 10, \"electionTimeoutMillis\" : 10000, \"catchUpTimeoutMillis\" : -1, \"catchUpTakeoverDelayMillis\" : 30000, \"getLastErrorModes\" : &#123; &#125;, \"getLastErrorDefaults\" : &#123; \"w\" : \"majority\", \"wtimeout\" : 30000 &#125;, \"replicaSetId\" : ObjectId(\"5b504606b5471294515460d0\") &#125;&#125; OK，现在往副本集里面添加新成员，不过要注意两点： 1、当新添加的辅助节点的投票和优先级设置大于零时，在其初始同步期间，辅助节点仍然计为投票成员，即使它不能提供读取也不能成为主节点，因为其数据尚未一致。 2、这可能导致大多数投票成员在线但不能选出主要成员的情况。要避免这种情况，请考虑最初新添加的成员的priority的值为0，同样votes的值也为0。然后，一旦成员转换到SECONDARY状态，使用rs.reconfig（）更新其priority和votes的值。 好，余下四个节点，依次建立副本集节点的swarm service 1234567docker service create --replicas 1 --network mongo_network --mount type=volume,src=rsdata2,dst=/data/db --constraint 'node.labels.mongo.rs==2' -p 27018:27017 --name mongo_rs2 mongo:3.6 mongod --replSet \"whmallRS\"docker service create --replicas 1 --network mongo_network --mount type=volume,src=rsdata3,dst=/data/db --constraint 'node.labels.mongo.rs==3' -p 27019:27017 --name mongo_rs3 mongo:3.6 mongod --replSet \"whmallRS\"docker service create --replicas 1 --network mongo_network --mount type=volume,src=rsdata4,dst=/data/db --constraint 'node.labels.mongo.rs==4' -p 27020:27017 --name mongo_rs4 mongo:3.6 mongod --replSet \"whmallRS\"docker service create --replicas 1 --network mongo_network --mount type=volume,src=rsdata5,dst=/data/db --constraint 'node.labels.mongo.rs==5' -p 27021:27017 --name mongo_rs5 mongo:3.6 mongod --replSet \"whmallRS\" 添加mongo_rs2节点，数据自动开始同步 1234567891011121314151617#添加mongo_rs2到副本集中docker exec -it $(docker ps -qf label=com.docker.swarm.service.name=mongo_rs1) mongo --eval 'rs.add( &#123; host: \"mongo_rs2:27017\", priority: 0, votes: 0 &#125; )'MongoDB shell version v3.6.6connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.6.6&#123; \"ok\" : 1, \"operationTime\" : Timestamp(1531990143, 1), \"$clusterTime\" : &#123; \"clusterTime\" : Timestamp(1531990143, 1), \"signature\" : &#123; \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"), \"keyId\" : NumberLong(0) &#125; &#125;&#125; 余下节点按照以上方法依次加入。这要等一段时间，四个节点要同步数据，够呛。 重新配置副本集成员的权重与投票参数这里有几点要注意：1、数据全部同步完毕后，注意这是节点的priority和votes的值都为零，需要做调整，调整过程可能会引起主节点重新选举，所以建议此步骤在维护窗口期进行哦。2、建议在维护窗口期间调整优先级设置。重新配置优先级可以强制当前主服务器降级，从而导致选举。在选举之前，副本集的主节点会关闭所有打开的客户端连接。除非你更改了副本集的默认读策略。3、rs.reconfig（）shell方法可以强制当前主节点降级，从而导致选举。当副本集主节点关闭时，mongod将关闭所有客户端连接。虽然这通常只需要10-20秒，但是建议在计划的维护期间进行这些更改。 避免重新配置包含不同MongoDB版本成员的副本集，因为验证规则可能因MongoDB版本而异。 1234cfg = rs.conf();cfg.members[1].priority = 2;cfg.members[1].votes = 1;rs.reconfig(cfg); 第一个语句使用rs.conf（）方法检索包含副本集的当前配置的文档，并将文档设置为本地变量cfg。第二个语句将members [n] .priority值设置为members数组中的第二个文档。有关其他设置，请参阅副本集配置设置。 要访问数组中的成员配置文档，该语句使用数组索引而不是副本集成员的成员[n] ._ id字段。最后一条语句使用修改过的cfg调用rs.reconfig（）方法来初始化此新配置。 总结 使用分布式存储文件系统是一个好主意，如ceph、Gluster等。 overlay网络中要确保运行副本集的跨主机容器能互相ping通，副本集依靠这个来检查节点心跳。 官方文档是必须看的。","categories":[],"tags":[{"name":"replica set","slug":"replica-set","permalink":"https://zhusas.github.io/tags/replica-set/"},{"name":"mongodb","slug":"mongodb","permalink":"https://zhusas.github.io/tags/mongodb/"},{"name":"ansible","slug":"ansible","permalink":"https://zhusas.github.io/tags/ansible/"},{"name":"docker","slug":"docker","permalink":"https://zhusas.github.io/tags/docker/"},{"name":"swarm","slug":"swarm","permalink":"https://zhusas.github.io/tags/swarm/"}]},{"title":"LVS实战","slug":"LVS实战","date":"2018-08-06T06:55:00.000Z","updated":"2018-08-06T06:56:26.869Z","comments":true,"path":"2018/08/06/LVS实战/","link":"","permalink":"https://zhusas.github.io/2018/08/06/LVS实战/","excerpt":"LVS基本简介LB集群的架构和原理很简单，就是当用户的请求过来时，会直接分发到Director Server上，然后它把用户的请求根据设置好的调度算法，智能均衡地分发到后端真正服务器(real server)上。为了避免不同机器上用户请求得到的数据不一样，需要用到了共享存储，这样保证所有用户请求的数据是一样的。 LVS是 Linux Virtual Server 的简称，也就是Linux虚拟服务器。这是一个由章文嵩博士发起的一个开源项目，它的官方网站是 http://www.linuxvirtualserver.org 现在 LVS 已经是 Linux 内核标准的一部分。使用 LVS 可以达到的技术目标是：通过 LVS 达到的负载均衡技术和 Linux 操作系统实现一个高性能高可用的 Linux 服务器集群，它具有良好的可靠性、可扩展性和可操作性。从而以低廉的成本实现最优的性能。LVS 是一个实现负载均衡集群的开源软件项目，LVS架构从逻辑上可分为调度层、Server集群层和共享存储。","text":"LVS基本简介LB集群的架构和原理很简单，就是当用户的请求过来时，会直接分发到Director Server上，然后它把用户的请求根据设置好的调度算法，智能均衡地分发到后端真正服务器(real server)上。为了避免不同机器上用户请求得到的数据不一样，需要用到了共享存储，这样保证所有用户请求的数据是一样的。 LVS是 Linux Virtual Server 的简称，也就是Linux虚拟服务器。这是一个由章文嵩博士发起的一个开源项目，它的官方网站是 http://www.linuxvirtualserver.org 现在 LVS 已经是 Linux 内核标准的一部分。使用 LVS 可以达到的技术目标是：通过 LVS 达到的负载均衡技术和 Linux 操作系统实现一个高性能高可用的 Linux 服务器集群，它具有良好的可靠性、可扩展性和可操作性。从而以低廉的成本实现最优的性能。LVS 是一个实现负载均衡集群的开源软件项目，LVS架构从逻辑上可分为调度层、Server集群层和共享存储。 工作原理： LVS工作于OSI四层,根据请求报文的目标IP和目标PORT将其转发至后端主机集群中的某台服务器（根据调度算法);其原理是通过ipvsadm用户空间的命令行工具定义lvs规则控制工作于内核上的netfilter INPUT钩子之上的程序代码IPVS实现调度算法。 1. 首先用户向负载均衡器调度器（Director Server）发起请求，负载均衡器将请求发往至内核空间，交给内核模块进行检测。2. 内核模块中的PREROUTING链首先会收到用户请求，判断目标地址是否是负载均衡器的IP地址，如果是，则将数据包发往INPUT链。3. IPVS模块是工作在INPUT链上的，当用户请求到达INPUT链上时，IPVS会将用户请求和自己已定义好的集群服务作对比，如果用户请求的就是定义的集群服务，那么IPVA会强行修改数据包里的目标IP地址和目标端口，并将新的数据包发往POSTROUTING链。4. POSTROUTING链接收到数据包发现目标IP地址刚好是自己的后端的服务器，那么通过选路，将数据包最终发送给后端的服务器。 LVS的组成 LVS 由2部分程序组成，包括 ipvs 和 ipvsadm。 ipvs(ip virtual server)：一段代码工作在内核空间，叫ipvs，是真正生效实现调度的代码。 ipvsadm：另外一段是工作在用户空间，叫ipvsadm，负责为ipvs内核框架编写规则，定义谁是集群服务，而谁是后端真实的服务器(Real Server) LVS相关术语 DS：Director Server。指的是前端负载均衡器节点。 RS：Real Server。后端真实的工作服务器。 VIP：向外部直接面向用户请求，作为用户请求的目标的IP地址。 DIP：Director Server IP，主要用于和内部主机通讯的IP地址。 RIP：Real Server IP，后端服务器的IP地址。 CIP：Client IP，访问客户端的IP地址。 LVS的调度算法 静态方法：仅根据算法本身进行调度 轮叫调度 rr这种算法是最简单的，就是按依次循环的方式将请求调度到不同的服务器上，该算法最大的特点就是简单。轮询算法假设所有的服务器处理请求的能力都是一样的，调度器会将所有的请求平均分配给每个真实服务器，不管后端 RS 配置和处理能力，非常均衡地分发下去。 加权轮叫 wrr这种算法比 rr 的算法多了一个权重的概念，可以给 RS 设置权重，权重越高，那么分发的请求数越多，权重的取值范围 0 – 100。主要是对rr算法的一种优化和补充， LVS 会考虑每台服务器的性能，并给每台服务器添加要给权值，如果服务器A的权值为1，服务器B的权值为2，则调度到服务器B的请求会是服务器A的2倍。权值越高的服务器，处理的请求越多。 源地址散列调度算法 sh与目标地址散列调度算法类似，但它是根据源地址散列算法进行静态分配固定的服务器资源。 目标地址散列调度算法 dh该算法是根据目标 IP 地址通过散列函数将目标 IP 与服务器建立映射关系，出现服务器不可用或负载过高的情况下，发往该目标 IP 的请求会固定发给该服务器。 动态方法：根据算法及各RS当前的负载状态进行评估，算法最后体现为overhead的值。 最少链接 lc这个算法会根据后端 RS 的连接数来决定把请求分发给谁，比如 RS1 连接数比 RS2 连接数少，那么请求就优先发给 RS1 加权最少链接 wlc这个算法比 lc 多了一个权重的概念，适用于后端RS性能不一样的时候,最为通用且为默认的动态方法 基于局部性的最少连接调度算法 lblc这个算法是请求数据包的目标 IP 地址的一种调度算法，该算法先根据请求的目标 IP 地址寻找最近的该目标 IP 地址所有使用的服务器，如果这台服务器依然可用，并且有能力处理该请求，调度器会尽量选择相同的服务器，否则会继续选择其它可行的服务器 复杂的基于局部性最少的连接算法 lblcr记录的不是要给目标 IP 与一台服务器之间的连接记录，它会维护一个目标 IP 到一组服务器之间的映射关系，防止单点服务器负载过高。 SED：Shortest Expection Delay权重大的RS如果排在后面的话，请求连接会被排在其前面权重小的机器所处理，导致排在后面权重大的RS闲置。 NQ: Nerver Queue累死权重大的RS，SED算法的改进。 好了，说着这么多理论，毛主席说实践是检验理论的唯一标准^_^ 实战-搭建一套LVS-DR模型的高性能集群，并实现以下功能： (1)、wordpress程序通过nfs共享给各个Realserver； (2)、后端realserver中的nginx和php分离 软件环境：1、vmware workstation 14 PRO，2、lnmp一键安装脚本3、CentOS7.4+Nginx1.12+WordPress4.9.1+PHP-7.2+MariaDB10.2 拓扑图 IP分配 LVS-DR1DIP:192.168.0.249VIP:192.168.0.228 NGINX主机1RIP:192.168.0.247VIP:192.168.0.228 NGINX主机2RIP:192.168.0.246VIP:192.168.0.228 PHP主机1192.168.0.233 PHP主机2192.168.0.232 NFS主机192.168.0.231 MariaDB主机1192.168.0.251 配置MariaDB主机1 12345678910登录MariaDB，建立数据库。MariaDB [(none)]&gt; create database wordpress;Query OK, 1 row affected (0.00 sec)MariaDB [(none)]&gt; grant all on wordpress.* to &apos;wp&apos;@&apos;192.168.%&apos; identified by &apos;123456&apos;;Query OK, 0 rows affected (0.01 sec)MariaDB [(none)]&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.00 sec) 安装配置NFS主机 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#安装NFS组件yum install nfs-utils rpcbind#设置RPC、NFS开机启动 systemctl enable rpcbind.servicesystemctl enable nfs.service#启动nfssystemctl start rpcbind.servicesystemctl start nfs.service#建立WordPress在NFS主机上的存放目录mkdir /data#下载WordPresscd /datawget https://wordpress.org/latest.tar.gz#解压tar xvf latest.tar.gz#配置WordPresscd wordpresscp wp-config-sample.php wp-config.phpvim wp-config.php#修改wp-config.php内容如下// ** MySQL settings - You can get this info from your web host ** ///** The name of the database for WordPress */define('DB_NAME', 'wordpress');/** MySQL database username */define('DB_USER', 'wp');/** MySQL database password */define('DB_PASSWORD', '123456');/** MySQL hostname */define('DB_HOST', '192.168.0.251');/** Database Charset to use in creating database tables. */define('DB_CHARSET', 'utf8');/** The Database Collate type. Don't change this if in doubt. */define('DB_COLLATE', '');#如下配置nfs[root@NFS ~]# cat /etc/exports/data/wordpress/ 192.168.0.0/24(rw,sync,no_wdelay,no_root_squash)之后记得重启一下nfs服务 来来来，nfs的权限设置科普一下 rw ：读写； ro ：只读； sync ：同步模式，内存中数据时时写入磁盘； async ：不同步，把内存中数据定期写入磁盘中； no_root_squash ：加上这个选项后，root用户就会对共享的目录拥有至高的权限控制，就像是对本机的目录操作一样。不安全，不建议使用； root_squash ：和上面的选项对应，root用户对共享目录的权限不高，只有普通用户的权限，即限制了root； all_squash ：不管使用NFS的用户是谁，他的身份都会被限定成为一个指定的普通用户身份； anonuid/anongid ：要和root_squash 以及 all_squash一同使用，用于指定使用NFS的用户限定后的uid和gid，前提是本机的/etc/passwd中存在这个uid和gid。 在2台PHP-FPM主机及NGINX主机上挂载NFS主机上的WordPress共享目录 123456[root@PHP1 opt]# mkdir -pv /opt/wordpressmkdir: created directory ‘/opt/wordpress’mount -t nfs 192.168.0.231:/data/wordpress /opt/wordpress也可以在主机上/etc/fstab文件中加入如下内容，实现开机自启：192.168.0.231:/data/wordpress /opt/wordpress nfs defaults 0 0 在两台NGINX主机上编辑nginx.conf文件，支持PHP-FPM 1234567891011121314151617181920212223upstream phpserver &#123; server 192.168.0.233:9000 weight=1; #权重可以根据实际情况调整。 server 192.168.0.232:9000 weight=1; &#125;server &#123; listen 80; server_name localhost; location / &#123; root /opt/wordpress; index index.html index.htm index.php; &#125; location ~ \\.php$ &#123; root /opt/wordpress; #此路径为php机器上的路径，非nginx机器上的。 fastcgi_pass phpserver; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125;&#125; 在两台PHP-FPM主机上编辑PHP-FPM.conf文件 如下： 1234567891011121314151617181920212223242526272829303132333435;;;;;;;;;;;;;;;;;;;;; Pool Definitions ;;;;;;;;;;;;;;;;;;;;;[www]listen = 192.168.0.233:9000listen.backlog = -1listen.allowed_clients = 192.168.0.247，192.168.0.246;listen.owner = www;listen.group = www;listen.mode = 0666user = wwwgroup = wwwpm = dynamicpm.max_children = 33pm.start_servers = 22pm.min_spare_servers = 16pm.max_spare_servers = 33pm.max_requests = 2048pm.process_idle_timeout = 10srequest_terminate_timeout = 120request_slowlog_timeout = 0pm.status_path = /php-fpm_statusslowlog = log/slow.logrlimit_files = 51200rlimit_core = 0catch_workers_output = yes;env[HOSTNAME] = PHP2env[PATH] = /usr/local/bin:/usr/bin:/binenv[TMP] = /tmpenv[TMPDIR] = /tmpenv[TEMP] = /tmp php文件存放的地方，要确保php配置文件中配置的user要有读权限，这里用的是www用户。 好了，现在分别在浏览器里面输入192.168.0.246 192.168.0.247 出来以下画面后，就可以开始配置lvs了 好，下面开始配置大名鼎鼎的lvs，上古神器~~ 首先在LVS的机器上，查看是否支持IPVS 来一段风骚的命令 1grep -C 10 -i \"ipvs\" /boot/config-$(uname -r) 参数简介:-i：ignorecase，忽略字符的大小写；-A #：after, 后#行-B #：before，前#行-C #：context，前后各#行 可以看到如下图，基本上都是默认支持滴 配置lvs的Director 1、先来系统层面的配置 #先打开系统的路由转发 [root@LVS-DR1 ~]# echo 1 &gt; /proc/sys/net/ipv4/ip_forward [root@LVS-DR1 ~]# cat /proc/sys/net/ipv4/ip_forward 1 123#系统的路由转发永久生效方法[root@LVS-DR1 ~]#echo \"net.ipv4.ip_forward = 1\" &gt;&gt; /etc/sysctl.conf[root@LVS-DR1 ~]#sysctl -p 123456789101112131415161718192021222324#配置虚拟网卡[root@LVS-DR1 ~]# ifconfig ens32:0 192.168.0.228 netmask 255.255.255.0 broadcast 192.168.0.228 up[root@LVS-DR1 ~]# ifconfigens32: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.0.249 netmask 255.255.255.0 broadcast 192.168.0.255 inet6 fe80::20c:29ff:fe13:618e prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:13:61:8e txqueuelen 1000 (Ethernet) RX packets 11013 bytes 726061 (709.0 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 724 bytes 86827 (84.7 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0ens32:0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.0.228 netmask 255.255.255.0 broadcast 192.168.0.228 ether 00:0c:29:13:61:8e txqueuelen 1000 (Ethernet)lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 1 (Local Loopback) RX packets 72 bytes 5720 (5.5 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 72 bytes 5720 (5.5 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 2、 定义集群服务及服务上的RS 12345678910[root@LVS-DR1 ~]# ipvsadm -A -t 192.168.0.228:80 -s wlc[root@LVS-DR1 ~]# ipvsadm -a -t 192.168.0.228:80 -r 192.168.0.247:80 -g -w 1[root@LVS-DR1 ~]# ipvsadm -a -t 192.168.0.228:80 -r 192.168.0.246:80 -g -w 1[root@LVS-DR1 ~]# ipvsadm -lnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -&gt; RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 192.168.0.228:80 wlc -&gt; 192.168.0.246:80 Route 1 0 0 -&gt; 192.168.0.247:80 Route 1 0 0 配置两台RealServer 1234567echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignoreecho 1 &gt; /proc/sys/net/ipv4/conf/$interface/arp_ignoreecho 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announceecho 2 &gt; /proc/sys/net/ipv4/conf/$interface/arp_announceifconfig $interface_alias $vip broadcast $vip netmask 255.255.255.255 uproute add -host $vip dev $interface_alias 其实用脚本更科学 Director脚本 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#!/bin/bash#定义参数，vip、rip、权重、端口、调度算法，lvs类型等vip=192.168.0.228rip=('192.168.0.246' '192.168.0.247')weight=('1' '2')port=80scheduler=rripvstype='-g'interface_alias='ens32:0'case $1 in start) #清空Linux防火墙的规则 iptables -F -t filter #清空lvs规则 ipvsadm -C ifconfig $interface_alias $vip broadcast $vip netmask 255.255.255.255 up echo 1 &gt; /proc/sys/net/ipv4/ip_forward ipvsadm -A -t $vip:$port -s $scheduler [ $? -eq 0 ] &amp;&amp; echo \"ipvs service $vip:$port added.\" || exit 2 for i in `seq 0 $[$&#123;#rip[@]&#125;-1]`; do ipvsadm -a -t $vip:$port -r $&#123;rip[$i]&#125; $ipvstype -w $&#123;weight[$i]&#125; [ $? -eq 0 ] &amp;&amp; echo \"RS $&#123;rip[$i]&#125; added.\" done touch /var/lock/subsys/ipvs ;; stop) echo 0 &gt; /proc/sys/net/ipv4/ip_forward ipvsadm -C ifconfig $interface_alias down rm -f /var/lock/subsys/ipvs echo \"ipvs stopped.\" ;; status) if [ -f /var/lock/subsys/ipvs ]; then echo \"ipvs is running.\" ipvsadm -L -n else echo \"ipvs is stopped.\" fi ;; *) echo \"Usage: `basename $0` &#123;start|stop|status&#125;\" exit 3 ;;esac RS的脚本 12345678910111213141516171819202122232425262728293031323334353637#!/bin/bash#vip=192.168.0.228interface_alias=\"lo:0\"interface=\"lo\" case $1 in start) echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 1 &gt; /proc/sys/net/ipv4/conf/$interface/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 2 &gt; /proc/sys/net/ipv4/conf/$interface/arp_announce ifconfig $interface_alias $vip broadcast $vip netmask 255.255.255.255 up route add -host $vip dev $interface_alias ;; stop) echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/$interface/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/$interface/arp_announce ifconfig $interface_alias down ;; status) if ifconfig lo:0 |grep $vip &amp;&gt; /dev/null; then echo \"ipvs is running.\" else echo \"ipvs is stopped.\" fi ;; *) echo \"Usage: `basename $0` &#123;start|stop|status&#125;\" exit 1esac 做完以上工作，lvs就可以正常访问了，可以看到lvs也起作用了，上图。 好，大功告成。","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://zhusas.github.io/tags/nginx/"},{"name":"lvs","slug":"lvs","permalink":"https://zhusas.github.io/tags/lvs/"},{"name":"wordpress","slug":"wordpress","permalink":"https://zhusas.github.io/tags/wordpress/"}]},{"title":"源码编译LNMP","slug":"源码编译LNMP","date":"2018-08-06T06:46:00.000Z","updated":"2018-08-06T06:47:17.548Z","comments":true,"path":"2018/08/06/源码编译LNMP/","link":"","permalink":"https://zhusas.github.io/2018/08/06/源码编译LNMP/","excerpt":"源码编译安装LNMP架构环境先下载nmp三件套wget http://nginx.org/download/nginx-1.12.0.tar.gz wget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-boost-5.7.18.tar.gz","text":"源码编译安装LNMP架构环境先下载nmp三件套wget http://nginx.org/download/nginx-1.12.0.tar.gz wget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-boost-5.7.18.tar.gz wget http://tw1.php.net/get/php-5.6.30.tar.gz/from/this/mirror -O php-5.6.30.tar.gz 编译安装Nginx1、建立Nginx的程序目录 123[root@CentOS7 ~]# mkdir -pv /opt/nginxmkdir: 已创建目录 &quot;/opt/nginx&quot;[root@CentOS7 ~]# 2、 安装依赖包 1[root@CentOS7 opt]# yum -y install openssl-devel pcre-devel zlib-devel 3、创建nginx用户和组 1[root@CentOS7 opt]# useradd -U nginx -s /sbin/nologin 前戏做足，接下来开始编译了，啊啊啊～～～～～ 4、进入到nginx源码目录 12[root@CentOS7 opt]# cd nginx-1.12.0/[root@CentOS7 nginx-1.12.0]# 输入以下编译命令： 123456789101112131415161718192021./configure --prefix=/opt/nginx \\--with-select_module \\--with-threads \\--with-file-aio \\--with-http_ssl_module \\--with-http_v2_module \\--with-http_realip_module \\--with-http_sub_module \\--with-http_dav_module \\--with-http_flv_module \\--with-http_gunzip_module \\--with-http_gzip_static_module \\--with-http_secure_link_module \\--with-http_degradation_module \\--with-http_slice_module \\--with-http_stub_status_module \\--without-mail_pop3_module \\--without-mail_imap_module \\--without-mail_smtp_module \\--with-stream \\--with-stream_ssl_module \\ 敲两下回车 如下输出： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130checking for OS + Linux 3.10.0-514.16.1.el7.x86_64 x86_64checking for C compiler ... found + using GNU C compiler + gcc version: 4.8.5 20150623 (Red Hat 4.8.5-11) (GCC) checking for gcc -pipe switch ... foundchecking for -Wl,-E switch ... foundchecking for gcc builtin atomic operations ... foundchecking for C99 variadic macros ... foundchecking for gcc variadic macros ... foundchecking for gcc builtin 64 bit byteswap ... foundchecking for unistd.h ... foundchecking for inttypes.h ... foundchecking for limits.h ... foundchecking for sys/filio.h ... not foundchecking for sys/param.h ... foundchecking for sys/mount.h ... foundchecking for sys/statvfs.h ... foundchecking for crypt.h ... foundchecking for Linux specific featureschecking for epoll ... foundchecking for EPOLLRDHUP ... foundchecking for EPOLLEXCLUSIVE ... not foundchecking for O_PATH ... foundchecking for sendfile() ... foundchecking for sendfile64() ... foundchecking for sys/prctl.h ... foundchecking for prctl(PR_SET_DUMPABLE) ... foundchecking for sched_setaffinity() ... foundchecking for crypt_r() ... foundchecking for sys/vfs.h ... foundchecking for nobody group ... foundchecking for poll() ... foundchecking for /dev/poll ... not foundchecking for kqueue ... not foundchecking for crypt() ... not foundchecking for crypt() in libcrypt ... foundchecking for F_READAHEAD ... not foundchecking for posix_fadvise() ... foundchecking for O_DIRECT ... foundchecking for F_NOCACHE ... not foundchecking for directio() ... not foundchecking for statfs() ... foundchecking for statvfs() ... foundchecking for dlopen() ... not foundchecking for dlopen() in libdl ... foundchecking for sched_yield() ... foundchecking for SO_SETFIB ... not foundchecking for SO_REUSEPORT ... foundchecking for SO_ACCEPTFILTER ... not foundchecking for SO_BINDANY ... not foundchecking for IP_BIND_ADDRESS_NO_PORT ... not foundchecking for IP_TRANSPARENT ... foundchecking for IP_BINDANY ... not foundchecking for IP_RECVDSTADDR ... not foundchecking for IP_PKTINFO ... foundchecking for IPV6_RECVPKTINFO ... foundchecking for TCP_DEFER_ACCEPT ... foundchecking for TCP_KEEPIDLE ... foundchecking for TCP_FASTOPEN ... foundchecking for TCP_INFO ... foundchecking for accept4() ... foundchecking for kqueue AIO support ... not foundchecking for Linux AIO support ... foundchecking for int size ... 4 byteschecking for long size ... 8 byteschecking for long long size ... 8 byteschecking for void * size ... 8 byteschecking for uint32_t ... foundchecking for uint64_t ... foundchecking for sig_atomic_t ... foundchecking for sig_atomic_t size ... 4 byteschecking for socklen_t ... foundchecking for in_addr_t ... foundchecking for in_port_t ... foundchecking for rlim_t ... foundchecking for uintptr_t ... uintptr_t foundchecking for system byte ordering ... little endianchecking for size_t size ... 8 byteschecking for off_t size ... 8 byteschecking for time_t size ... 8 byteschecking for AF_INET6 ... foundchecking for setproctitle() ... not foundchecking for pread() ... foundchecking for pwrite() ... foundchecking for pwritev() ... foundchecking for sys_nerr ... foundchecking for localtime_r() ... foundchecking for posix_memalign() ... foundchecking for memalign() ... foundchecking for mmap(MAP_ANON|MAP_SHARED) ... foundchecking for mmap(&quot;/dev/zero&quot;, MAP_SHARED) ... foundchecking for System V shared memory ... foundchecking for POSIX semaphores ... not foundchecking for POSIX semaphores in libpthread ... foundchecking for struct msghdr.msg_control ... foundchecking for ioctl(FIONBIO) ... foundchecking for struct tm.tm_gmtoff ... foundchecking for struct dirent.d_namlen ... not foundchecking for struct dirent.d_type ... foundchecking for sysconf(_SC_NPROCESSORS_ONLN) ... foundchecking for openat(), fstatat() ... foundchecking for getaddrinfo() ... foundchecking for PCRE library ... foundchecking for PCRE JIT support ... foundchecking for OpenSSL library ... foundchecking for zlib library ... foundcreating objs/MakefileConfiguration summary + using threads + using system PCRE library + using system OpenSSL library + using system zlib library nginx path prefix: &quot;/opt/nginx&quot; nginx binary file: &quot;/opt/nginx/sbin/nginx&quot; nginx modules path: &quot;/opt/nginx/modules&quot; nginx configuration prefix: &quot;/opt/nginx/conf&quot; nginx configuration file: &quot;/opt/nginx/conf/nginx.conf&quot; nginx pid file: &quot;/opt/nginx/logs/nginx.pid&quot; nginx error log file: &quot;/opt/nginx/logs/error.log&quot; nginx http access log file: &quot;/opt/nginx/logs/access.log&quot; nginx http client request body temporary files: &quot;client_body_temp&quot; nginx http proxy temporary files: &quot;proxy_temp&quot; nginx http fastcgi temporary files: &quot;fastcgi_temp&quot; nginx http uwsgi temporary files: &quot;uwsgi_temp&quot; nginx http scgi temporary files: &quot;scgi_temp&quot;[root@CentOS7 nginx-1.12.0]# make -j4 &amp;&amp; make install 好，接下来/opt/nginx 目录下已经有文件集目录生成了，运行./sbin/nginx -V看看输出啥，如下： 1234567[root@CentOS7 sbin]# ./nginx -Vnginx version: nginx/1.12.0built by gcc 4.8.5 20150623 (Red Hat 4.8.5-11) (GCC) built with OpenSSL 1.0.1e-fips 11 Feb 2013TLS SNI support enabledconfigure arguments: --prefix=/opt/nginx --with-select_module --with-threads --with-file-aio --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_secure_link_module --with-http_degradation_module --with-http_slice_module --with-http_stub_status_module --without-mail_pop3_module --without-mail_imap_module --without-mail_smtp_module --with-stream --with-stream_ssl_module[root@CentOS7 sbin]# 嗦嘎，编译成功！ 运行试试，记得配置防火墙规则，如果你要关掉防火墙也可以 [root@CentOS7 html]# systemctl stop firewalld.service[root@CentOS7 html]# systemctl disable firewalld.service 上边两条命令拿去不谢。 开机ngixn还要启动啊，init脚本得做好咧，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495#!/bin/bash# nginx This shell script takes care of starting and stopping# nginx## chkconfig: - 13 68# description: nginx is a web server### BEGIN INIT INFO# Provides: $named# Short-Description: start|stop|status|restart|configtest ### END INIT INFO#variablesNGINX_BIN=&quot;/opt/nginx/sbin/nginx&quot;NGINX_CONF=&quot;/opt/nginx/conf/nginx.conf&quot;NGINX_PID=&quot;/opt/nginx/logs/nginx.pid&quot;NETSTAT=&quot;/bin/netstat&quot;alter=$1prog=nginx#load system function. /etc/rc.d/init.d/functions#function:echo ok or errorfunction if_no &#123;if [ $2 == 0 ]; thenecho -n $&quot;$1 $&#123;prog&#125;:&quot; &amp;&amp; success &amp;&amp; echoelseecho -n $&quot;$1 $&#123;prog&#125;:&quot; &amp;&amp; failure &amp;&amp; echofi&#125;#start nginxfunction start &#123;if [ -s $&#123;NGINX_PID&#125; ]; thenecho &quot;nginx already running&quot; elseif [ `$&#123;NETSTAT&#125; -tnpl | grep nginx | wc -l` -eq 0 ]; thenrm -f $&#123;NGINX_PID&#125; 2&gt;/dev/null$&#123;NGINX_BIN&#125; -c $&#123;NGINX_CONF&#125; if_no start $? else$&#123;NETSTAT&#125; -tnpl | grep nginx | awk &apos;&#123; print $7&#125;&apos; | cut -d &apos;/&apos; -f 1 &gt; $&#123;NGINX_PID&#125;if_no start $?fifi&#125;#stop nginxfunction stop &#123;if [ -s $&#123;NGINX_PID&#125; ]; thencat $&#123;NGINX_PID&#125; | xargs kill -QUITif_no stop $?else if [ `$&#123;NETSTAT&#125; -tnpl | grep nginx | wc -l` -eq 0 ]; thenrm -f $&#123;NGINX_PID&#125; 2&gt;/dev/nullif_no stop 0elserm -f $&#123;NGINX_PID&#125; 2&gt;/dev/nullkill `$&#123;NETSTAT&#125; -tnpl | grep nginx | awk &apos;&#123; print $7&#125;&apos; | cut -d &apos;/&apos; -f 1`if_no stop $?fifi&#125;function restart &#123;if [ -s $&#123;NGINX_PID&#125; ]; thencat $&#123;NGINX_PID&#125; | xargs kill -HUPif_no restart $?elsestopsleep 1startfi&#125;function status &#123;$&#123;NETSTAT&#125; -tnpl | grep nginx | grep LISTEN[ $? == 0 ] &amp;&amp; echo &quot;nginx is running&quot; || echo &quot;nginx is not running&quot;&#125;function configtest &#123;$&#123;NGINX_BIN&#125; -t&#125;case $alter instart)start;;stop)stop;;restart)restart;;status)status;;configtest)configtest;;*)echo &quot;use:$&#123;NGINX&#125; &#123;start|stop|restart|status|configtest&#125;&quot;;;esac 脚本根据自己的Nginx安装路径设置好，加上可执行权限，放到/etc/init.d/目录下，之后使用下面两行命令开机启动： 12[root@CentOS7 init.d]# chkconfig --add nginx [root@CentOS7 init.d]# chkconfig nginx on Nginx的安装配置就到这里啦 源码编译安装MySQL参考资料 Installing MySQL from Source https://dev.mysql.com/doc/refman/5.7/en/source-installation.html How to Get MySQL https://dev.mysql.com/doc/refman/5.7/en/getting-mysql.html Building MySQL Server with CMake https://dev.mysql.com/doc/internals/en/cmake.html 港真，看官方文档很重要，会给你指点迷津，少走弯路～～～～～ 开始啦，之前已经下载好源码包mysql-boost-5.7.18.tar.gz ，开始脱（jie）衣（ya）服（suo），开搞！啊啊啊～～～ 不过要注意哦，官网文档有这么一段“温馨提示”： 123456789101112131415161718192021Source Installation System RequirementsInstallation of MySQL from source requires several development tools. Some of these tools are needed no matter whether you use a standard source distribution or a development source tree. Other tool requirements depend on which installation method you use.To install MySQL from source, the following system requirements must be satisfied, regardless of installation method: CMake, which is used as the build framework on all platforms. CMake can be downloaded from http://www.cmake.org. A good make program. Although some platforms come with their own make implementations, it is highly recommended that you use GNU make 3.75 or higher. It may already be available on your system as gmake. GNU make is available from http://www.gnu.org/software/make/. A working ANSI C++ compiler. See the description of the FORCE_UNSUPPORTED_COMPILER. option for some guidelines. The Boost C++ libraries are required to build MySQL (but not to use it). Boost 1.59.0 must be installed. To obtain Boost and its installation instructions, visit the official site. After Boost is installed, tell the build system where the Boost files are located by defining the WITH_BOOST option when you invoke CMake. For example: shell&gt; cmake . -DWITH_BOOST=/usr/local/boost_1_59_0Adjust the path as necessary to match your installation.Sufficient free memory. If you encounter problems such as “internal compiler error” when compiling large source files, it may be that you have too little memory. If compiling on a virtual machine, try increasing the memory allocation.Perl is needed if you intend to run test scripts. Most Unix-like systems include Perl. On Windows, you can use a version such as ActiveState Perl. 为了照顾英文不好的同学，我简单说几句 1、必须安装cmake，新版的MySQL采用cmak来编译。 2、linux系统中的make版本最少在3.75及以上 3、linux必须有C++编译器 4、必须安装Boost 1.59.0，指定的1.59.0版本，其他的高版本、低版本都不行，就这一个版本 下载boost1.59 [root@CentOS7 opt]# yum remove boost-1.53.0-26.el7.x86_64 #删除系统自带的低版本boost[root@CentOS7 opt]# wget https://dl.bintray.com/boostorg/release/1.59.0/source/boost_1_59_0.tar.gz #下载新版本的boost 创建mysql用户、用户组及目录 [root@CentOS7 /]# mkdir -pv /opt/mysql5.7/{conf,data}mkdir: created directory /opt/mysql5.7&#39; mkdir: created directory/opt/mysql5.7/conf’mkdir: created directory `/opt/mysql5.7/data’ [root@CentOS7 /]# groupadd -r mysql &amp;&amp; useradd -r -g mysql -s /bin/false -M mysql #增加mysql用户及用户组 安装依赖包保平安 yum install zlib-devel ncurses ncurses-devel bison 进入源码目录编译安装 [root@CentOS7 opt]# cd mysql-5.7.18/[root@CentOS7 mysql-5.7.18]# 输入以下编译参数： cmake . -DCMAKE_INSTALL_PREFIX=/opt/mysql5.7 -DMYSQL_DATADIR=/opt/mysql5.7/data -DSYSCONFDIR=/opt/mysql5.7/conf -DWITH_INNOBASE_STORAGE_ENGINE=1 -DWITH_ARCHIVE_STORAGE_ENGINE=1 -DWITH_BLACKHOLE_STORAGE_ENGINE=1 -DMYSQL_UNIX_ADDR=/opt/mysql5.7/mysql.sock -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DENABLED_LOCAL_INFILE=1 -DWITH_BOOST=/opt/tools -DENABLE_DOWNLOADS=1 -DDOWNLOAD_BOOST=1 -DWITH_MYISAM_STORAGE_ENGINE=1 -DWITH_INNODB_MEMCACHED=on 敲回车 等一会儿，看到最后一句 – Build files have been written to: /opt/mysql-5.7.18 ，哈哈，OK。 PS：这里有个坑，官方文档说的不是很清楚，boost1.59的压缩包下载下来后，-DWITH_BOOST的设置为压缩包所在的目录就行，也不用解压，例如我的boost1.59的压缩包放在/opt路径下，我这里就设置为-DWITH_BOOST=/opt 下一步就make -j 8 &amp;&amp; make install 嘿嘿，我用的是Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz 无惊无险，编译完成，接下来就是要做初始化啦 官方MySQL5.7文档里面有这么一段话： After installing MySQL, you must initialize the data directory, including the tables in the mysql system database.在安装MySQL,您必须初始化数据目录,包括MySQL系统数据库中的表。 As of MySQL 5.7.6, use the server to initialize the data directory:自MySQL 5.7.6起，使用MySQL服务器初始化数据目录: 命令例子shell&gt; bin/mysqld –initialize –user=mysql Before MySQL 5.7.6, use mysql_install_db:在MySQL 5.7.6之前,使用mysql_install_db: 命令例子shell&gt; bin/mysql_install_db –user=mysql OK，我这里采用的是mysqld –initialize来做初始化，哈哈哈哈哈哈哈～～～～～～～ 进入MySQL应用目录[root@CentOS7 ~]# cd /opt/mysql5.7/[root@CentOS7 mysql5.7]# 初始化MySQL 12345678910[root@CentOS7 mysql5.7]# ./bin/mysqld --initialize --user=mysql --basedir=/opt/mysql5.7 --datadir=/opt/mysql5.7/data2017-06-12T05:41:26.221750Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).2017-06-12T05:41:26.350566Z 0 [Warning] InnoDB: New log files created, LSN=457902017-06-12T05:41:26.375260Z 0 [Warning] InnoDB: Creating foreign key constraint system tables.2017-06-12T05:41:26.429865Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: c6bc1e39-4f31-11e7-ac7a-000c29bf2761.2017-06-12T05:41:26.430714Z 0 [Warning] Gtid table is not ready to be used. Table &apos;mysql.gtid_executed&apos; cannot be opened.2017-06-12T05:41:26.431659Z 1 [Note] A temporary password is generated for root@localhost: kTsP_fwzx9zY[root@CentOS7 mysql5.7]# date2017年 06月 12日 星期一 13:41:36 CST[root@CentOS7 mysql5.7]# 会自动完成初始化，并生成一个临时的密码，如上。 上边有个报警 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use –explicit_defaults_for_timestamp server option (see documentation for more details). 我是乖乖仔，照做，删除掉data目录下初始化生成的文件，再来一波: 12345678910[root@CentOS7 mysql5.7]# rm -rf data/*[root@CentOS7 mysql5.7]# ll data/总用量 0[root@CentOS7 mysql5.7]# ./bin/mysqld --initialize --user=mysql --basedir=/opt/mysql5.7 --datadir=/opt/mysql5.7/data --explicit_defaults_for_timestamp2017-06-12T07:04:15.856329Z 0 [Warning] InnoDB: New log files created, LSN=457902017-06-12T07:04:15.877492Z 0 [Warning] InnoDB: Creating foreign key constraint system tables.2017-06-12T07:04:15.931186Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: 58c9d7b2-4f3d-11e7-a336-000c29bf2761.2017-06-12T07:04:15.931749Z 0 [Warning] Gtid table is not ready to be used. Table &apos;mysql.gtid_executed&apos; cannot be opened.2017-06-12T07:04:15.932352Z 1 [Note] A temporary password is generated for root@localhost: l&gt;58J50te/vw[root@CentOS7 mysql5.7]# 报警没有了，嘿嘿。 编辑配置文件，添加以下内容 123456789101112131415[client]port=3306socket=/tmp/mysql.sockdefault-character-set=utf8[mysqld]basedir =/usr/local/mysqldatadir =/mydata/dataport =3306server_id =1socket =/tmp/mysql.sockpid-file=/mydata/data/mysql.pidbind-address=localhost#skip-grant-tables 拷贝配置文件cp support-files/my-default.cnf /opt/mysql5.7/conf/my.cnf 拷贝启动脚本cp support-files/mysql.server /etc/init.d/mysqld chmod +x /etc/init.d/mysqld 编辑启动脚本主要编辑basedir和datadir这两项 chkconfig –add mysqldchkconfig mysqld on [root@CentOS7 opt]# service mysqld startStarting MySQL. [ 确定 ] [root@CentOS7 opt]# service mysqld statusMySQL running (104746) [ 确定 ] 1234567891011121314151617[root@CentOS7 opt]# netstat -ntlpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:111 0.0.0.0:* LISTEN 1/systemd tcp 0 0 192.168.122.1:53 0.0.0.0:* LISTEN 14334/dnsmasq tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 14074/sshd tcp 0 0 127.0.0.1:631 0.0.0.0:* LISTEN 14071/cupsd tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 14300/master tcp 0 0 127.0.0.1:6010 0.0.0.0:* LISTEN 98390/sshd: root@pt tcp 0 0 127.0.0.1:6011 0.0.0.0:* LISTEN 103809/sshd: root@p tcp6 0 0 :::3306 :::* LISTEN 104746/mysqld tcp6 0 0 :::111 :::* LISTEN 1/systemd tcp6 0 0 :::22 :::* LISTEN 14074/sshd tcp6 0 0 ::1:631 :::* LISTEN 14071/cupsd tcp6 0 0 ::1:25 :::* LISTEN 14300/master tcp6 0 0 ::1:6010 :::* LISTEN 98390/sshd: root@pt tcp6 0 0 ::1:6011 :::* LISTEN 103809/sshd: root@p 爽爽爽～～～～～ 全局变量为了直接使用，加到环境变量里，修改/etc/profile文件，在文件末尾添加：export PATH=/opt/mysql5.7/bin:$PATH source /etc/profile 设置root用户可以远程访问 123456789101112131415161718192021[root@CentOS7 data]# mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 3Server version: 5.7.17Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.mysql&gt; set password = password(&apos;123456&apos;);mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos; WITH GRANT OPTION;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; flush privileges; Query OK, 0 rows affected (0.00 sec) 关闭CentOS7的防火墙，再用第三方数据库管理工具连接测试，OK啦。 MySQL5.7 编译安装完毕 源码编译安装PHP5安装依赖库保平安 yum -y install gd zlib zlib-devel openssl openssl-devel libxml2 libxml2-devel libjpeg libjpeg-devel libpng libpng-devel libticonv.x86_64 libticonv-devel.x86_64 具备第三方源的前提下的平安符yum -y install gd zlib zlib-devel openssl openssl-devel libxml2 libxml2-devel libjpeg libjpeg-devel libpng libpng-devel libticonv.x86_64 libticonv-devel.x86_64 php-mcrypt libmcrypt libmcrypt-devel mhash mhash-devel libevent libevent-devel libxml2 libxml2-devel bzip2-devel libcurl-devel libjpeg-devel libpng-devel freetype-devel 依赖包的一些点滴 扩展支持(mcrypt、mhash扩展和libevent) 如果想让编译的php支持mcrypt、mhash扩展和libevent，需要安装以下包libmcryptlibmcrypt-develmhashmhash-devel 说明：mcrypt扩展库可以实现加密解密功能，就是既能将明文加密，也可以密文还原。mhash是基于离散数学原理的不可逆向的php加密方式扩展库，其在默认情况下不开启。mhash的可以用于创建校验数值，消息摘要，消息认证码，以及无需原文的关键信息保存（如密码）等。 centos源不能安装libmcrypt-devel，由于版权的原因没有自带mcrypt的包，不过我在centos7中安装了epel源，哈哈哈。 使用yum命令安装 # yum install php-mcrypt libmcrypt libmcrypt-devel mhash mhash-devel libevent相关包libevent是一个异步事件通知库文件，其API提供了在某文件描述上发生某事件时或其超时时执行回调函数的机制它主要用来替换事件驱动的网络服务器上的event loop机制。目前来说， libevent支持/dev/poll、kqueue、select、poll、epoll及Solaris的event ports。可以根据需要安装libevent，系统一般会自带libevent，但版本有些低。 使用yum命令安装 yum install libevent libevent-devel 支持xml的相关包bzip2 是一个基于Burrows-Wheeler 变换的无损压缩软件能够高效的完成文件数据的压缩libcurl主要功能就是用不同的协议连接和沟通不同的服务器，也就是相当封装了的sockPHPlibcurl允许你用不同的协议连接和沟通不同的服务器 yum install libxml2 libxml2-devel bzip2-devel libcurl-devel 图形相关的rpm包通常对应的错误提示：JIS-mapped Japanese font support in GD yum install libjpeg-devel libpng-devel freetype-devel 来个一条龙yum -y install gd zlib zlib-devel openssl openssl-devel libxml2 libxml2-devel libjpeg libjpeg-devel libpng libpng-devel libticonv.x86_64 libticonv-devel.x86_64 php-mcrypt libmcrypt libmcrypt-devel mhash mhash-devel libevent libevent-devel libxml2 libxml2-devel bzip2-devel libcurl-devel libjpeg-devel libpng-devel freetype-devel 前戏做足，好戏开始，各位同学往下面看，下面哦。。。。。。 [root@CentOS7 php-5.6.30]# tar zxvf php-5.6.30.tar.gz #解压源码包 [root@CentOS7 tools]# cd php-5.6.30/ #进入PHP源码目录 [root@CentOS7 php-5.6.30]# 输下编译命令: 123456789101112131415161718192021222324252627282930313233./configure --prefix=/opt/php \\--sysconfdir=/opt/php/etc \\--enable-fpm \\--enable-pcntl \\--enable-shmop \\--enable-sysvmsg \\--enable-sysvsem \\--enable-sysvshm \\--enable-sockets \\--enable-shared \\--enable-mbstring \\--enable-xml \\--enable-opcache \\--enable-bcmath \\--enable-soap \\--enable-zip \\--with-mysqli=/opt/mysql5.7/bin/mysql_config \\--with-mysql=/opt/mysql5.7 \\--with-openssl \\--with-freetype-dir \\--with-jpeg-dir \\--with-png-dir \\--with-zlib \\--with-libxml-dir=/usr \\--with-iconv \\--with-mhash \\--with-mcrypt \\--with-config-file-path=/opt/php/etc \\--with-config-file-scan-dir=/opt/php/etc/php.d \\--with-bz2 \\--with-curl \\--with-gettext \\--with-gd \\ –with-mysqli=/opt/mysql5.7/bin/mysql_config 和–with-mysql=/opt/mysql5.7 这两个参数，我指向了自己编译安装的MySQL5.7.17 目录 最后看到下面这一段话： 12345678910111213141516171819202122232425262728293031323334Generating filesconfigure: creating ./config.statuscreating main/internal_functions.ccreating main/internal_functions_cli.c+--------------------------------------------------------------------+| License: || This software is subject to the PHP License, available in this || distribution in the file LICENSE. By continuing this installation || process, you are bound by the terms of this license agreement. || If you do not agree with the terms of this license, you must abort || the installation process at this point. |+--------------------------------------------------------------------+Thank you for using PHP.config.status: creating php5.specconfig.status: creating main/build-defs.hconfig.status: creating scripts/phpizeconfig.status: creating scripts/man1/phpize.1config.status: creating scripts/php-configconfig.status: creating scripts/man1/php-config.1config.status: creating sapi/cli/php.1config.status: creating sapi/fpm/php-fpm.confconfig.status: creating sapi/fpm/init.d.php-fpmconfig.status: creating sapi/fpm/php-fpm.serviceconfig.status: creating sapi/fpm/php-fpm.8config.status: creating sapi/fpm/status.htmlconfig.status: creating sapi/cgi/php-cgi.1config.status: creating ext/phar/phar.1config.status: creating ext/phar/phar.phar.1config.status: creating main/php_config.hconfig.status: main/php_config.h is unchangedconfig.status: executing default commands[root@CentOS7 php-5.6.30]# 然后就是 make -j 8 &amp;&amp; make install 就这么完成了编译安装php5.6.30 为php-fpm提供Sysv init脚本，并将其添加至服务列表 1234[root@CentOS7 ~]# cp /opt/tools/php-5.6.30/sapi/fpm/init.d.php-fpm /etc/rc.d/init.d/php-fpm[root@CentOS7 ~]# chmod +x /etc/rc.d/init.d/php-fpm[root@CentOS7 ~]# chkconfig --add php-fpm &amp;&amp; chkconfig php-fpm on[root@CentOS7 ~]# 为php-fpm提供配置文件 12345678910[root@CentOS7 ~]# cd /opt/php/etc/[root@CentOS7 etc]# lspear.conf php-fpm.conf.default[root@CentOS7 etc]# cp php-fpm.conf.default php-fpm.conf[root@CentOS7 etc]# ll总用量 52-rw-r--r-- 1 root root 1167 6月 13 15:51 pear.conf-rw-r--r-- 1 root root 22752 6月 13 16:05 php-fpm.conf-rw-r--r-- 1 root root 22752 6月 13 15:51 php-fpm.conf.default[root@CentOS7 etc]# 编辑php-fpm的配置文件 123456配置fpm的相关选项为你所需要的值，并启用pid文件（如下最后一行）：pm.max_children = 150pm.start_servers = 8pm.min_spare_servers = 5pm.max_spare_servers = 10pid = run/php-fpm.pid 接下来就可以启动php-fpm了 service php-fpm start [root@CentOS7 etc]# ps axuf |grep php 123456789101112[root@CentOS7 etc]# ps axuf |grep phproot 74719 0.0 0.0 112664 972 pts/1 S+ 16:21 0:00 \\_ grep --color=auto phproot 74700 0.0 0.1 125980 5032 ? Ss 16:21 0:00 php-fpm: master process (/opt/php/etc/php-fpm.conf)nobody 74701 0.0 0.1 128064 5108 ? S 16:21 0:00 \\_ php-fpm: pool wwwnobody 74702 0.0 0.1 128064 5108 ? S 16:21 0:00 \\_ php-fpm: pool wwwnobody 74703 0.0 0.1 128064 5108 ? S 16:21 0:00 \\_ php-fpm: pool wwwnobody 74704 0.0 0.1 128064 5112 ? S 16:21 0:00 \\_ php-fpm: pool wwwnobody 74705 0.0 0.1 128064 5112 ? S 16:21 0:00 \\_ php-fpm: pool wwwnobody 74706 0.0 0.1 128064 5112 ? S 16:21 0:00 \\_ php-fpm: pool wwwnobody 74707 0.0 0.1 128064 5112 ? S 16:21 0:00 \\_ php-fpm: pool wwwnobody 74708 0.0 0.1 128064 5112 ? S 16:21 0:00 \\_ php-fpm: pool www[root@CentOS7 etc]# 整合nginx和php5 1、编辑 /opt/nginx/conf/nginx.conf，启用如下选项： 1234567location ~ \\.php$ &#123; root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; include fastcgi_params; &#125; 2、vim /opt/nginx/conf/fastcgi_params，将其内容更改为如下内容： 1234567891011121314151617fastcgi_param GATEWAY_INTERFACE CGI/1.1;fastcgi_param SERVER_SOFTWARE nginx;fastcgi_param QUERY_STRING $query_string;fastcgi_param REQUEST_METHOD $request_method;fastcgi_param CONTENT_TYPE $content_type;fastcgi_param CONTENT_LENGTH $content_length;fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;fastcgi_param SCRIPT_NAME $fastcgi_script_name;fastcgi_param REQUEST_URI $request_uri;fastcgi_param DOCUMENT_URI $document_uri;fastcgi_param DOCUMENT_ROOT $document_root;fastcgi_param SERVER_PROTOCOL $server_protocol;fastcgi_param REMOTE_ADDR $remote_addr;fastcgi_param REMOTE_PORT $remote_port;fastcgi_param SERVER_ADDR $server_addr;fastcgi_param SERVER_PORT $server_port;fastcgi_param SERVER_NAME $server_name; 并在所支持的主页面格式中添加php格式的主页，类似如下： 1234location / &#123; root html; index index.php index.html index.htm; &#125; 而后重新载入nginx的配置文件： service nginx reload 3、在/opt/nginx/html新建index.php的测试页面，测试php是否能正常工作： 123&lt;?phpphpinfo();?&gt; 接着就可以通过浏览器访问此测试页面了。 此处有个坑 浏览器访问，不能解析，显示“ File not found.” fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; 这一句有问题， /scripts是一个目录名，也就是你站点的根目录，比如说，你访问/index.php这个文件，其实就是访问操作系统中/scripts/index.php这个文件，这个文件是否存在？/scripts 改成 $document_root 就好了，呵呵。 一键搭建LNMP源码编译环境请移步https://github.com/zhusas/lnmp","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://zhusas.github.io/tags/nginx/"},{"name":"php","slug":"php","permalink":"https://zhusas.github.io/tags/php/"},{"name":"lnmp","slug":"lnmp","permalink":"https://zhusas.github.io/tags/lnmp/"},{"name":"MySQL","slug":"MySQL","permalink":"https://zhusas.github.io/tags/MySQL/"}]},{"title":"sed和awk的详细用法","slug":"sed和awk的详细用法","date":"2018-08-06T06:30:00.000Z","updated":"2018-08-06T06:31:40.595Z","comments":true,"path":"2018/08/06/sed和awk的详细用法/","link":"","permalink":"https://zhusas.github.io/2018/08/06/sed和awk的详细用法/","excerpt":"sed用法sed(Stream EDitor)是一款流编辑器，用来对文本进行过滤与替换操作。其原理是：通过文件或管道读取文件内容，但是sed默认并不直接修改源文件，而是一次仅读取文件的一行至模式空间(pattern space)根据sed指令进行编辑并输出结果后清除模式空间，即所有的操作都是在模式空间中进行的。","text":"sed用法sed(Stream EDitor)是一款流编辑器，用来对文本进行过滤与替换操作。其原理是：通过文件或管道读取文件内容，但是sed默认并不直接修改源文件，而是一次仅读取文件的一行至模式空间(pattern space)根据sed指令进行编辑并输出结果后清除模式空间，即所有的操作都是在模式空间中进行的。 语法格式 sed [option]… ‘script’ inputfile… OPTIONS选项 -n，–quite，–silent：静默输出，即不输出模式中的内容至输出 -e script：使用多个脚本指令执行编辑 -f /PATH/TO/SCRIPT_FILE：从指定的文件中读取编辑脚本 -r：支持在脚本中使用正则表达式 -i，–in-place：直接在文件原处执行编辑，即修改源文件 SCRIPT，地址定界+编辑指令 地址定界 (1) 不给地址：对全文进行处理； (2) 单地址 12345#：指定的行$：文件的最后一行/PATTERN/：被模式匹配到的每一行 (3) 地址范围 1234567m,n：指定m行到n行#,+n：指定#行到#+n行/pat1/,/pat2/：匹配到的pat1到pat2之间的行#,/pat/：第#行到匹配到pat (4) 步进：~ 1231~2：所有奇数行，从一开始，步进22~2：所有偶数行，从二开始，步进2 注意：如果//中正则表达式为空，则匹配最近一次正则表达式的匹配地址！ 编辑命令 d：删除 p：显示模式空间的内容 a \\text：在行后面追加内容，支持使用\\n(换行符)实现多行追加 i \\text：在行前面插入内容，支持使用\\n(换行符)实现多行追加 c \\text：替换行为单行或多行文本，支持使用\\n(换行符) w /PATH/TO/SOMEFILE：保存模式空间匹配到的行至指定文件中 r /PATH/FROM/SOMEFILE：读取指定文件的文本流至模式空间中匹配到的行的行后 =：为模式空间中的行打印行号 !：取反条件 s/pattern/replacement/flags：替换，支持使用其他分隔符，如：s@@@, s### 12345678替换标记(flags)： #：替换行内匹配到的第#次的内容 g：行内全局替换 p：显示替换成功的行 w /PATH/TO/SOMEFILE：将替换后的结果保存至指定文件replacement： &amp;：用pattern匹配到的内容进行替换 \\n：在pattern中使用\\(\\)指定时，匹配第n个子串 【难点】高级编辑命令： 123456789101112131415161718h：把模式空间中的内容覆盖至保持空间中；H：把模式空间中的内容追加至保持空间中；g：把保持空间中的内容覆盖至模式空间中；G：把保持空间中的内容追加至模式空间中；x：把模式空间中的内容与保持空间中的内容互换；n：显示并清空模式空间，然后读取匹配到的行的下一行覆盖至模式空间；N：追加读取匹配到的行的下一行至模式空间中；d：删除模式空间中的行；D：删除多行模式空间中的所有行；示例： sed -n &apos;n;p&apos; FILE：显示偶数行； sed &apos;1!G;h;$!d&apos; FILE：逆序显示文件的内容； sed ’$!d&apos; FILE：取出最后一行； sed &apos;$!N;$!D&apos; FILE：取出文件后两行； sed &apos;/^$/d;G&apos; FILE：删除原有的所有空白行，而后为所有的非空白行后添加一个空白行； sed &apos;n;d&apos; FILE：显示奇数行； sed &apos;G&apos; FILE：在原有的每行后方添加一个空白行； awk用法其用法博大精深，且听我细细道来 首先，grep，sed，awk三者区别，回顾一下： grep, egrep, fgrep文本过滤工具，只读不写，加上各种正则及关键字，那叫一个爽快。 sed行编辑器，有模式空间及保持空间，实现文本行的编辑及输出。 awk报告生成器，格式化文本输出；功能及其强大，不光可用正则，还可以使用条件判断语句，函数、数组，不愧为上古神器。 有一点很重要，也很激励人心，就是“结合awk与其他工具诸如grep和sed，将会使shell编程更加容易，也更有逼格。” awk命令的使用格式：awk [options] ‘program’ file1,file2,… awk [options] ‘PATTERN { action }’ file1,file2,… program与PATTERN { action }的关系很多同学在刚开始学习awk的时候，这里常常犯迷糊，me too！所以我觉得这个关系先理清楚，对awk往后的学习是有帮助的。 program包括PATTERN和ACTION，PATTERN和ACTION最少得有一个，语句之间用分号分隔 【理解关键点】模式( pattern ) 用于匹配输入中的每行文本。对于匹配上的每行文本，awk 都执行对应的 动作( action )。模式和动作之间使用花括号隔开。awk 顺序扫描每一行文本，并使用 记录分隔符（一般是换行符）将读到的每一行作为 记录，使用 域分隔符( 一般是空格符或制表符 ) 将一行文本分割为多个 域， 每个域分别可以使用 $1, $2, … $n 表示。$1 表示第一个域，$2 表示第二个域，$n 表示第 n 个域。 $0 表示整个记录。模式或动作都可以不指定，缺省模式的情况下，将匹配所有行。缺省动作的情况下，将执行动作 {print}，即打印整个记录。 先来说说ACTION其中最常用的ACTION参数之一就是print和printf了，前者实现打印输出，后者实现格式化输出 print 语法： print item1, item2, … 要点 (1) 逗号分隔符； (2) 输出的各item可以字符串，也可以是数值；当前记录的字段、变量或awk的表达式； (3) 如省略item，相当于print $0,打印整行字符 printf命令，这个就很有内涵了 要点： (1) FORMAT必须给出; (2) 不会自动换行，需要显式给出换行控制符，\\n (3) FORMAT中需要分别为后面的每个item指定一个格式化符号； 语法： printf 格式符/修饰符, item1, item2, … 123456789101112131415格式符： %c: 显示字符的ASCII码； %d, %i: 显示十进制整数； %e, %E: 科学计数法数值显示； %f：显示为浮点数； %g, %G：以科学计数法或浮点形式显示数值； %s：显示字符串； %u：无符号整数； %%: 显示%自身；修饰符： #[.#]：第一个数字控制显示的宽度；第二个#表示小数点后的精度； %3.1f -: 左对齐 +：显示数值的符号 记住哦，格式符和修饰符可以灵活组合使用 ACTION还支持以下干货(1) Expressions表达式 (2) Control statements：if, while等； (3) Compound statements：组合语句； (4) input statements (5) output statements（print printf） 我们来看看控制语句： (1)if(condition) {statments} ：单分支if语句 (2)if(condition) {statments} else {statements} ：双分支if语句 (3)while(conditon) {statments} (4)do {statements} while(condition) ：循环体 (5)for(expr1;expr2;expr3) {statements} (6)break (7)continue (8)delete array[index] (9)delete array (10)exit 支持这么多，已经看傻,下面一个个来看看： if-else 1234567891011语法：if(condition) statement [else statement]~]# awk -F: &apos;&#123;if($3&gt;=1000) &#123;printf &quot;Common user: %s\\n&quot;,$1&#125; else &#123;printf &quot;root or Sysuser: %s\\n&quot;,$1&#125;&#125;&apos; /etc/passwd~]# awk -F: &apos;&#123;if($NF==&quot;/bin/bash&quot;) print $1&#125;&apos; /etc/passwd~]# awk &apos;&#123;if(NF&gt;5) print $0&#125;&apos; /etc/fstab~]# df -h | awk -F[%] &apos;/^\\/dev/&#123;print $1&#125;&apos; | awk &apos;&#123;if($NF&gt;=20) print $1&#125;&apos;使用场景：对awk取得的整行或某个字段做条件判断； while循环 12345678语法：while(condition) statement条件“真”，进入循环；条件“假”，退出循环；~]# awk &apos;/^[[:space:]]*linux16/&#123;i=1;while(i&lt;=NF) &#123;print $i,length($i); i++&#125;&#125;&apos; /etc/grub2.cfg~]# awk &apos;/^[[:space:]]*linux16/&#123;i=1;while(i&lt;=NF) &#123;if(length($i)&gt;=7) &#123;print $i,length($i)&#125;; i++&#125;&#125;&apos; /etc/grub2.cfg 使用场景：对一行内的多个字段逐一类似处理时使用；对数组中的各元素逐一处理时使用； do-while循环 12语法：do statement while(condition)意义：至少执行一次循环体 for循环 123456789语法：for(expr1;expr2;expr3) statementfor(variable assignment;condition;iteration process) &#123;for-body&#125;~]# awk &apos;/^[[:space:]]*linux16/&#123;for(i=1;i&lt;=NF;i++) &#123;print $i,length($i)&#125;&#125;&apos; /etc/grub2.cfg特殊用法： 能够遍历数组中的元素； 语法：for(var in array) &#123;for-body&#125; switch语句 1语法：switch(expression) &#123;case VALUE1 or /REGEXP/: statement; case VALUE2 or /REGEXP2/: statement; ...; default: statement&#125; next 123提前结束对本行的处理而直接进入下一行；~]# awk -F: &apos;&#123;if($3%2!=0) next; print $1,$3&#125;&apos; /etc/passwd 数组array 1234567891011 关联数组：array[index-expression]index-expression: (1) 可使用任意字符串；字符串要使用双引号； (2) 如果某数组元素事先不存在，在引用时，awk会自动创建此元素，并将其值初始化为“空串”； 若要判断数组中是否存在某元素，要使用&quot;index in array&quot;格式进行； weekdays[mon]=&quot;Monday&quot; 若要遍历数组中的每个元素，要使用for循环； for(var in array) &#123;for-body&#125; 函数 123456789内置函数 数值处理： rand()：返回0和1之间一个随机数； 字符串处理： length([s])：返回指定字符串的长度； sub(r,s,[t])：以r表示的模式来查找t所表示的字符中的匹配的内容，并将其第一次出现替换为s所表示的内容； gsub(r,s,[t])：以r表示的模式来查找t所表示的字符中的匹配的内容，并将其所有出现均替换为s所表示的内容； split(s,a[,r])：以r为分隔符切割字符s，并将切割后的结果保存至a所表示的数组中； 好，上边ACTION啰嗦完了，哈哈哈哈哈，下面就要高潮咧O(∩_∩)O哈哈~ PATTERNPATTERN有什么，有很多，超乎你的想象，它支持 123456789101112131415161718192021(1) empty：空模式，匹配每一行；(2) /regular expression/：仅处理能够被此处的模式匹配到的行；(3) relational expression: 关系表达式；【结果有“真”有“假”；结果为“真”才会被处理】； 【真：结果为非0值，非空字符串】这个跟bash的命令返回值不一样；(4) line ranges：行范围， startline,endline：/pat1/,/pat2/ 例子：[root@CentOS7 ~]# awk -F: &apos;/^h/,/^u/&#123;print $1&#125;&apos; /etc/passwd 注意： 不支持直接给出数字的格式 可以使用如下方式： ~]# awk -F: &apos;(NR&gt;=2&amp;&amp;NR&lt;=10)&#123;print $1&#125;&apos; /etc/passwd (5) BEGIN/END模式 BEGIN&#123;&#125;: 仅在开始处理文件中的文本之前执行一次； END&#123;&#125;：仅在文本处理完成之后执行一次 ； 选项[options]​-F：指明输入时用到的字段分隔符； -v var=value: 自定义变量； awk的options主要用来定义各种变量和使用各种內建变量。 内建变量 123456789101112131415161718FS：input field seperator，默认为空白字符；OFS：output field seperator，默认为空白字符；RS：input record seperator，输入时的换行符；ORS：output record seperator，输出时的换行符；NF：number of field，字段数量 &#123;print NF&#125;, &#123;print $NF&#125; 它们之间是有区别的，NF是有多少个字段数量，而$NF表示最后一个字段的内容NR：number of record, 行数；FNR：各文件分别计数；行数；$0：代表一行，读一行进行切片FILENAME：当前文件名；ARGC：命令行参数的个数；ARGV：数组，保存的是命令行所给定的各参数；PS：在awk中要做变量替换，是不能用引号引起来的 自定义变量 123(1) -v var=value #变量名区分字符大小写哦；(2) 在program中直接定义 好了，awk就介绍到这里，下面来写例子 例子1：显示/etc/passwd的账户 12345#cat /etc/passwd |awk -F &apos;:&apos; &apos;&#123;print $1&#125;&apos; rootdaemonbinsys 上边这种是awk+action的示例，每行都会执行action{print $1}。 -F指定域分隔符为’:’。 例子2：搜索/etc/passwd有root关键字的所有行 12awk -F: '/root/' /etc/passwdroot:x:0:0:root:/root:/bin/bash 上边这种是pattern的使用示例，匹配了pattern(这里是root)的行才会执行action(没有指定action，默认输出每行的内容)。 搜索支持正则，例如找root开头的: awk -F: ‘/^root/‘ /etc/passwd 例子3：搜索/etc/passwd有root关键字的所有行，并显示对应的shell 12awk -F: '/root/&#123;print $7&#125;' /etc/passwd /bin/bash 上边这里指定了匹配了pattern(这里是root)的行才会执行action{print $7} 例子4：删除/boot/grub/grub.conf文件中所有行的行首的空白字符 sed ‘s/^[[:space:]]+//‘ /boot/grub/grub.conf 这里的sed使用了查找替换，思路就是先查找文件中所有行的行首的空白字符，用正则的行首锚定空字符，之后查找替换为空，即删除。 例子5：删除/etc/fstab文件中所有以#开头，后跟至少一个空白字符的行的行首的#和空白字符 sed ‘s/^#[[:space:]]*//‘ /etc/fstab 同样是查找替换的套路，参照例子4 例子6：把/etc/fstab文件的奇数行另存为/tmp/fstab.3 sed ‘1~2!d’ /etc/fstab &gt; /tmp/fstab.3 sed ‘1~2w /tmp/fstab.3’ /etc/fstab 这里用到了sed地址定界中的步进+编辑命令，两种不同的编辑命令实现，真是飞刀又见飞刀，套路又见套路，套路就是熟悉其语法，命令，灵活组合使用。 例子7：echo一个文件路径给sed命令，取出其基名；进一步地，取出其路径名 路径名 echo “/tmp/test/fstab” | sed ‘s#[^/]+\\?$##’ 上边sed的#为分隔符，[^/]指匹配指定范围外的任意单个字符， +：匹配其前面的字符1次或多次：即其前面的字符要出现至少1次； \\?：匹配其前面的字符0次或1次；即其前面的字符是可有可无的； $：行尾锚定；用于模式的最右侧 基名 echo “/tmp/test/fstab” | sed ‘s#(\\/.*\\/)##’ 12345上边的sed分隔符为#，用到了sed的查找替换、正则表达式及其分组，形式为\\(正则表达式\\)正则为\\/.*\\/，其中\\为转移符，正则抽取出来就是/.*/ 意思就是匹配到/开头的以/结尾期间的任意单个字符任意次。各位应该明白了吧。 例子8：统计指定文件中所有行中每个单词出现的次数 awk ‘{for(i=1;i&lt;=NF;i++){count[$i]++}}END{for(i in count) {print i,count[i]}}’ /etc/fstab 12345678910111213141516171819202122232425262728293031323334353637383940[root@CentOS7 ~]# awk '&#123;for(i=1;i&lt;=NF;i++)&#123;count[$i]++&#125;&#125;END&#123;for(i in count) &#123;print i,count[i]&#125;&#125;' /etc/fstabswap 2fstab(5), 1filesystems, 1on 1/etc/fstab 1/boot 1more 1mount(8) 1pages 1'/dev/disk' 1/dev/mapper/cl_centos7-swap 1blkid(8) 1See 1/dev/mapper/cl_centos7-root 1for 1and/or 1anaconda 1/ 1findfs(8), 1under 117:33:09 1Created 1UUID=fe2021fb-ac21-474d-8256-f72b87fc915a 10 6info 1Accessible 122 1# 7defaults 3xfs 2man 1are 1reference, 1Mar 1by 2maintained 12017 1Wed 1[root@CentOS7 ~]# 7、统计当前系统上所有tcp连接的各种状态的个数； netstat -n | awk ‘/^tcp/ {++state[$NF]} END {for(key in state) print key,”t”,state[key]}’ 例子 1234567root@xxx:~# netstat -n | awk '/^tcp/ &#123;++state[$NF]&#125; END &#123;for(key in state) print key,\"t\",state[key]&#125;'FIN_WAIT2 t 71CLOSE_WAIT t 1TIME_WAIT t 2049ESTABLISHED t 1392LAST_ACK t 3FIN_WAIT1 t 4 8、统计指定的web访问日志中各ip的资源访问次数： awk ‘{ip[$1]++}END{for(i in ip) print i,ip[i]}’ /opt/nginx/logs/access.log 9、写一个脚本：定义一个数组，数组元素为/var/log目录下所有以.log结尾的文件的名字；显示每个文件的行数； 123456789[root@CentOS7 ~]# cat week15_title9.sh #!/bin/bashfiles=/var/log/*.logfor i in $filesdo wc -l $idone 输出如下： 1234567891011[root@CentOS7 ~]# ./week15_title9.sh 248 /var/log/boot.log9 /var/log/openlmi-install.log177 /var/log/vmware-install.log326 /var/log/vmware-vmsvc.log85 /var/log/vmware-vmusr.log10 /var/log/wpa_supplicant.log436 /var/log/Xorg.0.log320 /var/log/Xorg.9.log328 /var/log/yum.log[root@CentOS7 ~]# 10、写一个脚本，能从所有同学中随机挑选一个同学回答问题；进一步地：可接受一个参数，做为要挑选的同学的个数； 123456789101112[root@CentOS7 ~]# cat week15_title10.sh#!/bin/bashif [ $1 ];then #判断有无脚本参数传入，如有则执行，没有就执行else的语句 for((i=1;i&lt;=$1;i++));do a=$[$RANDOM%11] #定义一个0~10的随机数 echo $a doneelse a=$[$RANDOM%11] echo $afi 11、授权centos用户可以运行fdisk命令完成磁盘管理，以及使用mkfs或mke2fs实现文件系统管理； 12visudocentos ALL=(root) NOPASSWD:/sbin/fdisk,/sbin/mke2fs,/sbin/mkfs 12、授权gentoo用户可以运行逻辑卷管理的相关命令； 12visudogentoo ALL=(root) lvm 13、基于pam_time.so模块，限制用户通过sshd服务远程登录只能在工作时间进行； 12vim /etc/ssh/sshd_config UsePAM yes #开启Pam模块认证 ​ 1234567/lib64/security/pam_time.so #确保pam_time.so存在 vim /etc/pam.d/sshd增加 account required pam_time.sovim /etc/security/time.conf添加 *;*;*;MoTuWeThFr0900-1800 14、基于pam_listfile.so模块，定义仅某些用户，或某些组内的用户可登录系统； 123456789[root@localhost ~]# vim /etc/sshd_userlistrootcentosgentoochmod 600 /etc/sshd_userlistchown root /etc/sshd_userlistvim /etc/pam.d/sshd #auth required pam_listfile.so item=user sense=allow file=/etc/sshd_userlist onerr=succeed","categories":[],"tags":[{"name":"awk","slug":"awk","permalink":"https://zhusas.github.io/tags/awk/"},{"name":"sed","slug":"sed","permalink":"https://zhusas.github.io/tags/sed/"}]},{"title":"Linux防火墙的随笔","slug":"Linux防火墙的随笔","date":"2018-08-06T06:25:00.000Z","updated":"2018-08-06T06:26:07.472Z","comments":true,"path":"2018/08/06/Linux防火墙的随笔/","link":"","permalink":"https://zhusas.github.io/2018/08/06/Linux防火墙的随笔/","excerpt":"基本语法：iptables [-t 表][操作命令] [链][规则匹配器][-j 目标动作]","text":"基本语法：iptables [-t 表][操作命令] [链][规则匹配器][-j 目标动作] 系统的INPUT和OUTPUT默认策略为DROP； 12iptables -P INPUT DROPiptables -P OUTPUT DROP 1、限制本地主机的web服务器在周一不允许访问；新请求的速率不能超过100个每秒；web服务器包含了admin字符串的页面不允许访问；web服务器仅允许响应报文离开本机； 本地主机的web服务器在周一不允许访问 1iptables -A INPUT -p tcp --dport 80 -m time ! --weekdays Mon -j ACCEPT 新请求速率不能超过100个每秒 1iptables -A INPUT -p tcp --dport 80 -m limit --limit 100/s web包含admin字符串的页面不允许访问 1iptables -A INPUT -p tcp --dport 80 -m string --algo bm --string 'admin' -j REJECT web服务器仅允许响应报文离开主机 1iptables -A OUTPUT -p tcp --sport 80 -m state --state ESTABLISHED -j ACCEPT 2、在工作时间，即周一到周五的8:30-18:00，开放本机的ftp服务给172.16.0.0网络中的主机访问；数据下载请求的次数每分钟不得超过5个； 1iptables -A INPUT -p tcp --dport 21 -s 172.16.0.0 -m time ! --weekdays 6,7 -m time --timestart 8:30 --timestop 18:00 -m limit --limit 5/m 3、开放本机的ssh服务给172.16.x.1-172.16.x.100中的主机，x为你的座位号，新请求建立的速率一分钟不得超过2个；仅允许响应报文通过其服务端口离开本机； 123iptables -A INPUT -p tcp --dport 22 -m iprange --src-range 172.16.0.1-172.16.0.100 -m limit --limit 2/miptables -A OUTPUT -p tcp --sport 22 -m iprange --dst-range 172.16.0.1-172.16.0.100 -m state --state ESTABLISHED -j ACCEPT 4、拒绝TCP标志位全部为1及全部为0的报文访问本机； 1iptables -A INPUT -p tcp --tcp-flags ALL ALL -j DROP 5、允许本机ping别的主机；但不开放别的主机ping本机； 123iptables -A INPUT -p icmp --icmp-type 0 -j ACCEPTiptables -A OUTPUT -p icmp --icmp-type 8 -j ACCEPT iptables -N clean_in 创建一条自定义链clean_in iptables -A clean_in -d 255.255.255.255 -p icmp -j DROP 丢弃同网络的的icmp协议包 iptables -A clean_in -d 172.16.255.255 -p icmp -j DROP 丢弃来源172.16网络的icmp协议包 iptables -A clean_in -p tcp ! –syn -m state –state NEW -j DROP 丢弃syn状态不为1且为NEW 的连接 iptables -A clean_in -p tcp –tcp-flags ALL ALL -j DROP 丢弃所有tcp标志位为1的数据包 iptables -A clean_in -p tcp –tcp-flags ALL NONE -j DROP 在clean_in链中添加一条规则，丢弃tcp报文中tcp标志位都为0的 iptables -A clean_in -d 172.16.100.7 -j RETURN 在clean_in链中添加一条规则，遇到目的端为172.16.100.7的主机，返回调用位置 iptables -A INPUT -d 172.16.100.7 -j clean_in 在clean_in链中添加一条规则，遇到目的端为172.16.100.7的主机，调用clean_in iptables -A INPUT -i lo -j ACCEPT 允许回环接口进 iptables -A OUTPUT -o lo -j ACCEPT 允许回环接口出 iptables -A INPUT -i eth0 -m multiport -p tcp –dports 53,113,135,137,139,445 -j DROP 丢弃通过eth0网卡访问53,113,135,137,139,445端口的tcp报文 iptables -A INPUT -i eth0 -m multiport -p udp –dports 53,113,135,137,139,445 -j DROP 丢弃通过eth0网卡访问53,113,135,137,139,445端口的udp报文 iptables -A INPUT -i eth0 -p udp –dport 1026 -j DROP 丢弃通过eth0网卡访问1026端口的udp报文 iptables -A INPUT -i eth0 -m multiport -p tcp –dports 1433,4899 -j DROP 丢弃通过eth0网卡访问1433,4899端口的tcp报文 iptables -A INPUT -p icmp -m limit –limit 10/second -j ACCEPT 接收icmp报文限速每秒10次 通过tcp_wrapper控制vsftpd仅允许172.16.0.0/255.255.0.0网络中的主机访问，但172.16.100.3除外；对所被被拒绝的访问尝试都记录在/var/log/tcp_wrapper.log日志文件中； 12345vim /etc/host.allow vsftpd:172.16. EXCEPT 172.16.100.3 vim /etc/host.deny vsftdp:ALL :spawn /bin/echo $(date) login attemp from %c to %s,%d &gt;&gt; /bar/log/tcp_wrapper.log","categories":[],"tags":[]},{"title":"vsftp文件共享服务","slug":"vsftp文件共享服务","date":"2018-08-06T06:15:00.000Z","updated":"2018-08-06T06:17:59.749Z","comments":true,"path":"2018/08/06/vsftp文件共享服务/","link":"","permalink":"https://zhusas.github.io/2018/08/06/vsftp文件共享服务/","excerpt":"1)基于虚拟用户的访问形式 2)匿名用户只允许下载，不允许上传 3)禁锢所有的用户于其家目录当中 4)限制最大并发连接数为200 5)匿名用户的最大传输速率512KB/s 6)虚拟用户的账号存储在mysql数据库当中 7)数据库通过NFS进行共享 先科(zhuang)普(bi) 我们登录FTP有三种方式，匿名登录、本地用户登录和虚拟用户登录。","text":"1)基于虚拟用户的访问形式 2)匿名用户只允许下载，不允许上传 3)禁锢所有的用户于其家目录当中 4)限制最大并发连接数为200 5)匿名用户的最大传输速率512KB/s 6)虚拟用户的账号存储在mysql数据库当中 7)数据库通过NFS进行共享 先科(zhuang)普(bi) 我们登录FTP有三种方式，匿名登录、本地用户登录和虚拟用户登录。 匿名登录：在登录FTP时使用默认的用户名，一般是ftp或anonymous。 本地用户登录：使用系统用户登录，在/etc/passwd中。 虚拟用户登录：这是FTP专有用户，有两种方式实现虚拟用户，本地数据文件和数据库服务器。 FTP虚拟用户是FTP服务器的专有用户，使用虚拟用户登录FTP，只能访问FTP服务器提供的资源，大大增强了系统的安全。 测试环境 NFS&amp;MySQL服务器 192.168.0.248 vsftp 服务器 192.168.0.235 一、通过NFS服务器共享数据库 1、在192.168.0.248服务器上启动nfs服务，设置共享目录为/nfs_data [root@CentOS6 ~]# mkdir -pv /nfs_datamkdir: created directory `/nfs_data’ 2、安装组件 yum install rpcbind nfs-server nfs-lock nfs-idmap 3、启动nfs服务 1234567891011[root@CentOS7 ~]# systemctl start nfs-server.service[root@CentOS7 ~]# systemctl status nfs-server.service ● nfs-server.service - NFS server and services Loaded: loaded (/usr/lib/systemd/system/nfs-server.service; enabled; vendor preset: disabled) Active: active (exited) since 五 2017-03-24 16:38:33 CST; 1 day 7h ago Main PID: 37384 (code=exited, status=0/SUCCESS) CGroup: /system.slice/nfs-server.service3月 24 16:38:33 CentOS7 systemd[1]: Starting NFS server and services...3月 24 16:38:33 CentOS7 systemd[1]: Started NFS server and services.[root@CentOS7 ~]# 4、编辑 vim /etc/exports 添加一下内容 1/nfs_data 192.168.0.0/24(rw,no_root_squash,sync) exportfs -r 一下使其生效 注：配置文件说明： 1234567891011121314151617/nfs_data为共享目录192.168.0.0/24 可以为一个网段，一个IP，也可以是域名，域名支持通配符 如: *.qq.comrw：read-write，可读写；ro：read-only，只读；sync：文件同时写入硬盘和内存；async：文件暂存于内存，而不是直接写入内存；no_root_squash：NFS客户端连接服务端时如果使用的是:root的话，那么对服务端分享的目录来说，也拥有root权限。显然开启这项是不安全的。root_squash：NFS客户端连接服务端时如果使用的是root的话，那么对服务端分享的目录来说，拥有匿名用户权限，通常他将使用nobody或nfsnobody身份；all_squash：不论NFS客户端连接服务端时使用什么用户，对服务端分享的目录来说都是拥有匿名用户权限； 二、vsftp mysql 服务器挂载nfs 1234567891011121314[root@CentOS6 ~]# showmount -e 192.168.0.235Export list for 192.168.0.235:/nfs_data 192.168.0.0/24[root@CentOS6 ~]# mount -t nfs 192.168.0.235:/nfs_data /nfs_data[root@CentOS6 ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/vg_centos6-lv_root 18G 3.3G 13G 21% /tmpfs 3.9G 0 3.9G 0% /dev/shm/dev/sda1 477M 69M 383M 16% /boot192.168.0.235:/nfs_data 17G 6.9G 11G 41% /nfs_data 客户端在挂载的时候遇到的一个问题如下，可能是网络不太稳定，NFS默认是用UDP协议，换成TCP协议即可 mount -t nfs 192.168.0.235:/nfs_data /nfs_data -o proto=tcp -o nolock 在客户端写入一个有内容的文件测试，嘿嘿，服务端马上看到了，欧耶123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177**vsftp mysql 服务器 192.168.0.235安装MySQL/MariaDB**这里我就直接yum安装MariaDB了yum install mariadb-server.x86_64 mariadb-devel.x86_64 openssl-devel.x86_64systemctl start mariadb.service systemctl enable mariadb.service **安装PAM-MySQL，要跟vsftp安装在同一台机器上**下载源码包，加压安装前再次确认依赖包yum install pam-devel openssl-devel mariadb-devel**CentOS7**./configure --with-mysql=/usr --with-openssl --with-pam=/usr --with-pam-mods-dir=/usr/lib64/security**CentOS6**./configure --with-mysql=/usr --with-openssl --with-pam=/usr --with-pam-mods-dir=/lib64/security/make -j 4 &amp;&amp; make install**配置数据库，创建vsftpd的库和表**```mysql[root@CentOS7 pam_mysql-0.7RC1]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 3Server version: 5.5.52-MariaDB MariaDB ServerCopyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; create database vsftpd;Query OK, 1 row affected (0.00 sec)MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || test || vsftpd |+--------------------+5 rows in set (0.00 sec)MariaDB [(none)]&gt; use vsftpd;Database changedMariaDB [vsftpd]&gt; create table users ( -&gt; id int auto_increment not null primary key, -&gt; name char(30) not null, -&gt; password char(48) binary not null );Query OK, 0 rows affected (0.00 sec)MariaDB [vsftpd]&gt; desc users;+----------+----------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+----------+----------+------+-----+---------+----------------+| id | int(11) | NO | PRI | NULL | auto_increment || name | char(30) | NO | | NULL | || password | char(48) | NO | | NULL | |+----------+----------+------+-----+---------+----------------+3 rows in set (0.00 sec)MariaDB [vsftpd]&gt; insert into users(name,password) values (&apos;jerry&apos;,password(&apos;mageedu&apos;));Query OK, 1 row affected (0.00 sec)MariaDB [vsftpd]&gt; insert into users(name,password) values (&apos;tom&apos;,password(&apos;mageedu111&apos;));Query OK, 1 row affected (0.00 sec)MariaDB [vsftpd]&gt; select * from users;+----+-------+-------------------------------------------+| id | name | password |+----+-------+-------------------------------------------+| 1 | jerry | *9A94EE7D14C10908118B62D2DA88E6932E11E438 || 2 | tom | *67CF267D9D554496768C605C2D66754EAE874C12 |+----+-------+-------------------------------------------+2 rows in set (0.00 sec)MariaDB [vsftpd]&gt; #我这边vsftpd跟mysql不是同一台机器，所以开启远程授权 MariaDB [mysql]&gt; grant select on vsftpd.* to vsftpd@&apos;192.168.0.248&apos; identified by &apos;mageedu&apos;;Query OK, 0 rows affected (0.00 sec)MariaDB [mysql]&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)[root@CentOS7 pam_mysql-0.7RC1]# mysql -uvsftpd -pmageeduWelcome to the MariaDB monitor. Commands end with ; or \\g.Your MariaDB connection id is 14Server version: 5.5.52-MariaDB MariaDB ServerCopyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || test || vsftpd |+--------------------+3 rows in set (0.00 sec)MariaDB [(none)]&gt; use vsftpd;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [vsftpd]&gt; select * from users;+----+-------+-------------------------------------------+| id | name | password |+----+-------+-------------------------------------------+| 1 | jerry | *9A94EE7D14C10908118B62D2DA88E6932E11E438 || 2 | tom | *67CF267D9D554496768C605C2D66754EAE874C12 |+----+-------+-------------------------------------------+2 rows in set (0.00 sec)MariaDB [vsftpd]&gt; exitBye[root@CentOS7 pam_mysql-0.7RC1]# ``` **迁移MariaDB的数据库默认数据存放目录，放到/nfs_data/目录中，形成NFS共享**```bash[root@CentOS7 /]# systemctl stop mariadb.service [root@CentOS7 /]# cp -r /var/lib/mysql/ /nfs_data/[root@CentOS7 /]#vim /etc/my.cnf修改成：datadir=/nfs_data/mysql[root@CentOS7 /]#cd /nfs_data/[root@CentOS7 /]# chown -R mysql:mysql mysql/[root@CentOS7 /]#systemctl start mariadb.service [root@CentOS7 /]#systemctl status mariadb.service● mariadb.service - MariaDB database server Loaded: loaded (/usr/lib/systemd/system/mariadb.service; enabled; vendor preset: disabled) Active: active (running) since 日 2017-03-26 15:16:34 CST; 18min ago Process: 94278 ExecStartPost=/usr/libexec/mariadb-wait-ready $MAINPID (code=exited, status=0/SUCCESS) Process: 94247 ExecStartPre=/usr/libexec/mariadb-prepare-db-dir %n (code=exited, status=0/SUCCESS) Main PID: 94277 (mysqld_safe) CGroup: /system.slice/mariadb.service ├─94277 /bin/sh /usr/bin/mysqld_safe --basedir=/usr └─94435 /usr/libexec/mysqld --basedir=/usr --datadir=/nfs_data...3月 26 15:16:32 CentOS7 systemd[1]: Starting MariaDB database server...3月 26 15:16:32 CentOS7 mysqld_safe[94277]: 170326 15:16:32 mysqld_safe....3月 26 15:16:32 CentOS7 mysqld_safe[94277]: 170326 15:16:32 mysqld_safe...l3月 26 15:16:34 CentOS7 systemd[1]: Started MariaDB database server.Hint: Some lines were ellipsized, use -l to show in full.```这时候，两边机器的NFS目录都看看，OK啦 安装vsftpd 1234567891011121314151617181920212223242526272829303132333435363738394041[root@CentOS6 mysql]# yum install vsftpdLoaded plugins: fastestmirrorSetting up Install ProcessLoading mirror speeds from cached hostfile * base: mirrors.aliyun.com * epel: mirrors.tuna.tsinghua.edu.cn * extras: mirrors.aliyun.com * updates: mirrors.aliyun.comResolving Dependencies--&gt; Running transaction check---&gt; Package vsftpd.x86_64 0:2.2.2-21.el6 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved============================================================================ Package Arch Version Repository Size============================================================================Installing: vsftpd x86_64 2.2.2-21.el6 base 155 kTransaction Summary============================================================================Install 1 Package(s)Total download size: 155 kInstalled size: 340 kIs this ok [y/N]: yDownloading Packages:vsftpd-2.2.2-21.el6.x86_64.rpm | 155 kB 00:00 Running rpm_check_debugRunning Transaction TestTransaction Test SucceededRunning Transaction Installing : vsftpd-2.2.2-21.el6.x86_64 1/1 Verifying : vsftpd-2.2.2-21.el6.x86_64 1/1 Installed: vsftpd.x86_64 0:2.2.2-21.el6 Complete! 配置vsftpd的pam文件 [root@CentOS6 ~]# vim /etc/pam.d/vsftpd.mysql 输入以下内容： 123auth required pam_mysql.so user=vsftpd passwd=mageedu host=192.168.0.235 db=vsftpd table=users usercolumn=name passwdcolumn=password crypt=2account required pam_mysql.so user=vsftpd passwd=mageedu host=192.168.0.235 db=vsftpd table=users usercolumn=name passwdcolumn=password crypt=2 创建系统用户 因为虚拟用户最终要映射为系统用户，所以得创建用于vsftpd映射使用滴用户啦。。。。。 1234[root@CentOS6 ~]# mkdir -pv /ftprootmkdir: created directory `/ftproot&apos;[root@CentOS6 /]# useradd -s /sbin/nologin -d /ftproot vuser 确保vuser的家目录其他用户能读能执行 1234567[root@CentOS6 /]# ll |grep ftproot/[root@CentOS6 /]# ll |grep ftprdrwx------ 3 vuser vuser 4096 Mar 27 13:59 ftproot[root@CentOS6 /]# chmod +rx -R /ftproot/[root@CentOS6 /]# ll |grep ftprdrwxr-xr-x 3 vuser vuser 4096 Mar 27 13:59 ftproot[root@CentOS6 /]# 配置/etc/vsftpd/vsftpd.conf vim /etc/vsftpd/vsftpd.conf 修改 pam_service_name=vsftpd.mysql 匿名用户只允许下载，不允许上传 vim /etc/vsftpd/vsftpd.conf anonymous_enable=YES #允许匿名账户登录 anon_upload_enable=NO #不允许匿名用户上传文件 禁锢所有的用户于其家目录当中 chroot_local_user=YES #禁锢本地账户的家目录 限制最大并发连接数为200 max_clients=200 #最大允许的客户端连接数 匿名用户的最大传输速率512KB/s local_max_rate=512000 写入配置文件后，重启vsftp服务即可。","categories":[],"tags":[{"name":"vsftp","slug":"vsftp","permalink":"https://zhusas.github.io/tags/vsftp/"}]},{"title":"建立samba共享","slug":"建立samba共享","date":"2018-08-06T06:06:00.000Z","updated":"2018-08-06T06:07:34.810Z","comments":true,"path":"2018/08/06/建立samba共享/","link":"","permalink":"https://zhusas.github.io/2018/08/06/建立samba共享/","excerpt":"数据目录为 /data 1）共享名为shared，工作组为whmall vim /etc/samba/smb.conf","text":"数据目录为 /data 1）共享名为shared，工作组为whmall vim /etc/samba/smb.conf 12345678910修改workgroup = MYGROUP为workgroup = whmall修改passdb backend = tdbsam为 passdb backend = smbpasswd smb passwd file = /etc/samba/smbpasswd 2)添加组develop，添加用户gentoo,centos和ubuntu，其中gentoo和centos以develop为附加组，ubuntu不属于develop组；密码均为用户名 1234567891011[root@CentOS7 samba]# groupadd develop[root@CentOS7 samba]# useradd -G develop gentoo[root@CentOS7 samba]# useradd -G develop centos[root@CentOS7 samba]# useradd ubuntu[root@CentOS7 samba]# echo \"gentoo\"| passwd --stdin gentoo更改用户 gentoo 的密码 。passwd：所有的身份验证令牌已经成功更新。[root@CentOS7 samba]# echo \"centos\"| passwd --stdin centos更改用户 centos 的密码 。passwd：所有的身份验证令牌已经成功更新。[root@CentOS7 samba]# echo \"ubuntu\"| passwd --stdin ubuntu 3)添加samba用户gentoo,centos和ubuntu，密码均为“111111” 1234567891011121314[root@CentOS7 samba]# smbpasswd -a gentooNew SMB password:Retype new SMB password:startsmbfilepwent_internal: file /etc/samba/smbpasswd did not exist. File successfully created.Added user gentoo.[root@CentOS7 samba]# smbpasswd -a centosNew SMB password:Retype new SMB password:Added user centos.[root@CentOS7 samba]# smbpasswd -a ubuntuNew SMB password:Retype new SMB password:Added user ubuntu.[root@CentOS7 samba]# 4)此samba共享shared仅允许develop组具有写权限，其他用户只能以只读方式访问 vim smb.conf 1234567末尾添加[shared]comment = whmall.compath = /dataguest = yes writable = nowrite list = +develop 5)此samba共享服务仅允许来自于172.16.0.0/16网络的主机访问； vim smb.conf 12添加 hosts allow = 172.16.0.0/16 启动samba服务 1234567891011121314151617181920212223[root@CentOS7 samba]# systemctl start smb.service[root@CentOS7 samba]# systemctl status smb.service● smb.service - Samba SMB Daemon Loaded: loaded (/usr/lib/systemd/system/smb.service; disabled; vendor preset: disabled) Active: active (running) since 四 2017-03-23 14:39:18 CST; 5s ago Main PID: 101560 (smbd) Status: \"smbd: ready to serve connections...\" CGroup: /system.slice/smb.service ├─101560 /usr/sbin/smbd ├─101561 /usr/sbin/smbd ├─101562 /usr/sbin/smbd └─101563 /usr/sbin/smbd3月 23 14:39:18 CentOS7 systemd[1]: Starting Samba SMB Daemon...3月 23 14:39:18 CentOS7 smbd[101557]: [2017/03/23 14:39:18.773050, 0] .....)3月 23 14:39:18 CentOS7 smbd[101557]: Unknown parameter encountered: \"g...\"3月 23 14:39:18 CentOS7 smbd[101557]: [2017/03/23 14:39:18.773117, 0] .....)3月 23 14:39:18 CentOS7 smbd[101557]: Ignoring unknown parameter \"guest\"3月 23 14:39:18 CentOS7 systemd[1]: smb.service: Supervising process 101...s.3月 23 14:39:18 CentOS7 smbd[101560]: [2017/03/23 14:39:18.787425, 0] .....)3月 23 14:39:18 CentOS7 smbd[101560]: STATUS=daemon 'smbd' finished sta...s3月 23 14:39:18 CentOS7 systemd[1]: Started Samba SMB Daemon.Hint: Some lines were ellipsized, use -l to show in full. PS： CentOS7最好关闭防火墙，还有SELinux 123456[root@CentOS7 ~]# systemctl list-unit-files |grep firefirewalld.service enabled [root@CentOS7 ~]# systemctl stop firewalld.service [root@CentOS7 ~]# systemctl disable firewalld.service Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.Removed symlink /etc/systemd/system/basic.target.wants/firewalld.service. 亲测OK，有图有真相 PS:这里我把hosts allow = 172.16.0.0/16 改为了hosts allow = 192.168.0.0/24 workgroup 改为WORKGROUP 这样就看到了，欧耶~","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://zhusas.github.io/tags/linux/"},{"name":"samba","slug":"samba","permalink":"https://zhusas.github.io/tags/samba/"}]},{"title":"php编译成httpd模块形式和php以fpm工作为独立守护进程的方式来支持httpd详细过程","slug":"php编译成httpd模块形式和php以fpm工作为独立守护进程的方式来支持httpd详细过程","date":"2018-08-06T05:55:00.000Z","updated":"2018-08-06T05:57:19.977Z","comments":true,"path":"2018/08/06/php编译成httpd模块形式和php以fpm工作为独立守护进程的方式来支持httpd详细过程/","link":"","permalink":"https://zhusas.github.io/2018/08/06/php编译成httpd模块形式和php以fpm工作为独立守护进程的方式来支持httpd详细过程/","excerpt":"php编译成httpd模块形式","text":"php编译成httpd模块形式 略。。。。。。 php以fpm工作为独立守护进程的方式来支持httpd 1234567891011121314151617./configure –prefix=/opt/php5-fpm \\–with-mysql=mysqlnd \\–with-openssl \\–with-mysqli=mysqlnd \\–enable-mbstring \\–with-freetype-dir \\–with-jpeg-dir \\ –with-png-dir \\–with-zlib \\–with-libxml-dir=/usr \\–enable-xml \\–enable-sockets \\–enable-fpm \\–with-mcrypt \\–with-config-file-path=/opt/php5-fpm/conf \\–with-config-file-scan-dir=/opt/php5-fpm/conf.d \\–with-bz2 添加了–enable-fpm选项 ，这是重点啊，各位记住。 1make &amp;&amp; make install 拷贝配置文件至/opt/php5-fpm/conf目录 1cp php.ini-production /etc/php.ini 拷贝php-fpm配置文件，并同时取消pid选项的注释 123cp /usr/local/php5/etc/php-fpm.conf.default /usr/local/php5/etc/php-fpm.confvim /usr/local/php5/etc/php-fpm.confpid = /usr/local/php5/var/run/php-fpm.pid 添加服务脚本 12345678#进入源码目录，拷贝开机启动服务文件cp init.d.php-fpm /etc/rc.d/init.d/php-fp#加上执行属性chmod +x /etc/rc.d/init.d/php-fpm#加入到开机启动服务chkconfig –add php-fpm 启动php-fpm service php-fpm start 配置httpd 1234567# vim /etc/httpd24/httpd.conf#启用这两个模块:LoadModule proxy_module modules/mod_proxy.soLoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so 添加文件类型 12345678910111213#添加文件类型AddType application/x-httpd-php .phpAddType application/x-httpd-php-source .phps添加php文件的访问通过fpmProxyRequests OffProxyPassMatch ^/(.*.php)$ fcgi://127.0.0.1:9000/usr/local/apache24/htdocs/$1找到 DirectoryIndex index.html改为DirectoryIndex index.php index.html 编辑php测试页并开启httpd进行测试 123456789101112cd /usr/local/apache24/htdocs/vim index.php&lt;h1&gt;phpfpmtest&lt;/h1&gt;&lt;?php phpinfo();?&gt; 123456789101112131415161718192021222324252627282930[root@localhost htdocs]# apachectl startAH00558: httpd: Could not reliably determine the server&apos;s fully qualified domain name, using localhost.localdomain. Set the &apos;ServerName&apos; directive globally to suppress this[root@localhost htdocs]# ss -tnls State Recv-Q Send-Q Local Address:Port Peer Address:PortLISTEN 0 128 :::80 :::* LISTEN 0 128 :::22 :::* LISTEN 0 128 *:22 *:* LISTEN 0 100 ::1:25 :::* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 128 127.0.0.1:6010 *:* LISTEN 0 128 ::1:6010 :::* LISTEN 0 128 127.0.0.1:6011 *:* LISTEN 0 128 ::1:6011 :::* LISTEN 0 128 127.0.0.1:9000 *:* 此时的Server API为FPM/FastCGI","categories":[],"tags":[{"name":"apache","slug":"apache","permalink":"https://zhusas.github.io/tags/apache/"},{"name":"php","slug":"php","permalink":"https://zhusas.github.io/tags/php/"},{"name":"fpm","slug":"fpm","permalink":"https://zhusas.github.io/tags/fpm/"}]},{"title":"自签证书使用户可以通过https访问站点","slug":"自签证书使用户可以通过https访问站点","date":"2018-08-06T05:51:00.000Z","updated":"2018-08-06T05:54:21.703Z","comments":true,"path":"2018/08/06/自签证书使用户可以通过https访问站点/","link":"","permalink":"https://zhusas.github.io/2018/08/06/自签证书使用户可以通过https访问站点/","excerpt":"生成私钥 12345[root@lampw pki]# (umask 077; openssl genrsa -out /etc/pki/ca-trust/cakey.pem 8192)Generating RSA private key, 8192 bit long modulus...................................................................................................................++....................................................................... .................................................................................................................................................................................++e is 65537 (0x10001)","text":"生成私钥 12345[root@lampw pki]# (umask 077; openssl genrsa -out /etc/pki/ca-trust/cakey.pem 8192)Generating RSA private key, 8192 bit long modulus...................................................................................................................++....................................................................... .................................................................................................................................................................................++e is 65537 (0x10001) 生成自签证书 12345678910111213141516[root@lampw pki]# openssl req -new -x509 -key /etc/pki/ca-trust/cakey.pem -out /etc/pki/ca-trust/cacert.pem -days 3655You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter '.', the field will be left blank.-----Country Name (2 letter code) [AU]:CN State or Province Name (full name) [Some-State]:HALocality Name (eg, city) []:ZZOrganization Name (eg, company) [Internet Widgits Pty Ltd]:TmallOrganizational Unit Name (eg, section) []:TmallCommon Name (e.g. server FQDN or YOUR name) []:www2.stuX.comEmail Address []:admin@stuX.com[root@lampw pki]# 为CA提供所需的目录及文件 12345678[root@lampw pki]# mkdir -pv /etc/pki/CA/&#123;certs,crl,newcerts&#125;mkdir: created directory `/etc/pki/CA'mkdir: created directory `/etc/pki/CA/certs'mkdir: created directory `/etc/pki/CA/crl'mkdir: created directory `/etc/pki/CA/newcerts'[root@lampw pki]# touch /etc/pki/CA/&#123;serial,index.txt&#125;[root@lampw pki]# echo 01 &gt; /etc/pki/CA/serial[root@lampw pki]# 用到证书的主机生成私钥 12345678910111213141516[root@lampw pki]# mkdir -pv /etc/pki/CA/&#123;certs,crl,newcerts&#125;mkdir: created directory `/etc/pki/CA'mkdir: created directory `/etc/pki/CA/certs'mkdir: created directory `/etc/pki/CA/crl'mkdir: created directory `/etc/pki/CA/newcerts'[root@lampw pki]# touch /etc/pki/CA/&#123;serial,index.txt&#125;[root@lampw pki]# echo 01 &gt; /etc/pki/CA/serial[root@lampw pki]# mkdir -pv /opt/apache24/sslmkdir: created directory `/opt/apache24/ssl'[root@lampw pki]# cd /opt/apache24/ssl[root@lampw ssl]# (umask 077; openssl genrsa -out /opt/apache24/ssl/httpd.key 8192)Generating RSA private key, 8192 bit long modulus.............................................................................................................++....................................................++e is 65537 (0x10001)[root@lampw ssl]# 生成证书签署请求 1234567891011121314151617181920[root@lampw ssl]# openssl req -new -key /opt/apache24/ssl/httpd.key -out /opt/apache24/ssl/httpd.csr -days 365You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter '.', the field will be left blank.-----Country Name (2 letter code) [AU]:CNState or Province Name (full name) [Some-State]:HALocality Name (eg, city) []:ZZOrganization Name (eg, company) [Internet Widgits Pty Ltd]:TmallOrganizational Unit Name (eg, section) []:TmallCommon Name (e.g. server FQDN or YOUR name) []:www2.stuX.comEmail Address []:admin@stuX.comPlease enter the following 'extra' attributesto be sent with your certificate requestA challenge password []:An optional company name []: 将请求通过可靠方式发送给CA主机，这次是在同一台机器，我就略过，如果是生产环境，估计就是要发给可信的证书签署机构 1、在CA主机上签署证书 1234567891011121314151617181920212223242526272829303132333435363738[root@centos ssl]# openssl ca -in /etc/httpd/ssl/httpd.csr -out /etc/pki/CA/certs/httpd.crt -days 365Using configuration from /etc/pki/tls/openssl.cnfCheck that the request matches the signatureSignature okCertificate Details: Serial Number: 1 (0x1) Validity Not Before: Mar 22 03:49:48 2017 GMT Not After : Mar 22 03:49:48 2018 GMT Subject: countryName = CN stateOrProvinceName = HA organizationName = Tmall organizationalUnitName = ops commonName = www2.stuX.com emailAddress = admin@stuX.com X509v3 extensions: X509v3 Basic Constraints: CA:FALSE Netscape Comment: OpenSSL Generated Certificate X509v3 Subject Key Identifier: EC:C4:48:10:BE:BD:1D:D2:48:38:17:B7:FD:0D:57:DE:51:B1:8F:64 X509v3 Authority Key Identifier: keyid:ED:42:A1:59:88:A2:45:0A:F2:64:46:A6:BA:C9:7A:5D:E3:9C:FB:AECertificate is to be certified until Mar 22 03:49:48 2018 GMT (365 days)Sign the certificate? [y/n]:y 1 out of 1 certificate requests certified, commit? [y/n]y Write out database with 1 new entries Data Base Updated[root@centos ssl]# lshttpd.crt httpd.csr httpd.key ​ 2、修改配置文件提供ssl服务 开启主配置文件的ssl调用，删除www2在httpd-vhosts中的定义 12345678910111213141516171819202122232425262728293031323334353637383940Include /etc/httpd24/extra/httpd-ssl.conf~]# vim /etc/httpd24/extra/httpd-ssl.conf[root@localhost httpd24]# cat extra/httpd-ssl.conf | grep -v &quot;^#&quot;Listen 443SSLPassPhraseDialog builtin&lt;VirtualHost 192.168.150.136:443&gt;DocumentRoot &quot;/web/vhost/www2&quot;ServerName www2.stuX.com:443ServerAdmin you@example.comErrorLog &quot;/var/log/httpd/www2.err&quot;TransferLog &quot;/usr/local/apache24/logs/access_log&quot;SSLEngine onSSLCertificateFile &quot;/etc/httpd24/ssl/httpd.crt&quot;SSLCertificateKeyFile &quot;/etc/httpd24/ssl/httpd.key&quot;&lt;Directory &quot;/web/vhost/www2&quot;&gt; AllowOverride NoneOptions NoneRequire all granted&lt;/Directory&gt;&lt;/VirtualHost&gt; 主配置文件中启用ssl模块 123~]# vim /etc/httpd24/httpd.confLoadModule ssl_module modules/mod_ssl.so 重启httpd服务后测试 123httpd24]# ss -tnl | grep 443LISTEN 0 128 :::443 :::*","categories":[],"tags":[{"name":"CA","slug":"CA","permalink":"https://zhusas.github.io/tags/CA/"},{"name":"SSL","slug":"SSL","permalink":"https://zhusas.github.io/tags/SSL/"},{"name":"https","slug":"https","permalink":"https://zhusas.github.io/tags/https/"}]},{"title":"Apache所支持的处理模型及应用环境","slug":"Apache所支持的处理模型及应用环境","date":"2018-08-06T05:48:00.000Z","updated":"2018-08-06T05:49:29.291Z","comments":true,"path":"2018/08/06/Apache所支持的处理模型及应用环境/","link":"","permalink":"https://zhusas.github.io/2018/08/06/Apache所支持的处理模型及应用环境/","excerpt":"prefork：多进程模型，每个进程响应一个请求 一个主进程：负责生成子进程及回收子进程；负责创建套接字；负责接收请求，并将其派发给某子进程进行处理； n个子进程：每个子进程处理一个请求； 工作模型：会预先生成几个空闲进程，随时等待用于响应用户请求；最大空闲和最小空闲；","text":"prefork：多进程模型，每个进程响应一个请求 一个主进程：负责生成子进程及回收子进程；负责创建套接字；负责接收请求，并将其派发给某子进程进行处理； n个子进程：每个子进程处理一个请求； 工作模型：会预先生成几个空闲进程，随时等待用于响应用户请求；最大空闲和最小空闲； worker：多进程多线程模型，每线程处理一个用户请求 一个主进程：负责生成子进程；负责创建套接字；负责接收请求，并将其派发给某子进程进行处理； 多个子进程：每个子进程负责生成多个线程； 每个线程：负责响应用户请求； 并发响应数量：m*n m：子进程数量 n：每个子进程所能创建的最大线程数量； event：事件驱动模型，多进程模型，每个进程响应多个请求 一个主进程 ：负责生成子进程；负责创建套接字；负责接收请求，并将其派发给某子进程进行处理； 子进程：基于事件驱动机制直接响应多个请求；","categories":[],"tags":[{"name":"apache","slug":"apache","permalink":"https://zhusas.github.io/tags/apache/"}]},{"title":"一次完整的http请求处理过程","slug":"一次完整的http请求处理过程","date":"2018-08-06T05:45:00.000Z","updated":"2018-08-06T05:46:10.699Z","comments":true,"path":"2018/08/06/一次完整的http请求处理过程/","link":"","permalink":"https://zhusas.github.io/2018/08/06/一次完整的http请求处理过程/","excerpt":"简介一次完整的HTTP请求过程从TCP三次握手建立连接成功后开始,客户端按照指定的格式开始向服务端发送HTTP请求，服务端接收请求后，解析HTTP请求，处理完业务逻辑，最后返回一个HTTP的响应给客户端，HTTP的响应内容同样有标准的格式。无论是什么客户端或者是什么服务端，大家只要按照HTTP的协议标准来实现的话，那么它一定是通用的。","text":"简介一次完整的HTTP请求过程从TCP三次握手建立连接成功后开始,客户端按照指定的格式开始向服务端发送HTTP请求，服务端接收请求后，解析HTTP请求，处理完业务逻辑，最后返回一个HTTP的响应给客户端，HTTP的响应内容同样有标准的格式。无论是什么客户端或者是什么服务端，大家只要按照HTTP的协议标准来实现的话，那么它一定是通用的。 1、客户端发起http请求阶段 客户端在与服务端TCP三次握手建立连接成功后 开始按照指定的格式开始向服务端发送HTTP请求 HTTP请求格式主要有四部分组成，分别是：请求行、请求头、空行、消息体，每部分内容占一行，如下图： 下面我们来详解一下这个来自客户端的http请求 请求行：请求行是请求消息的第一行，由三部分组成：分别是请求方法（GET/POST/DELETE/PUT/HEAD）、请求资源的URI路径、HTTP的版本号 请求头：请求头中的信息有和缓存相关的头（Cache-Control，If-Modified-Since）、客户端身份信息（User-Agent）等等。 消息体：请求体是客户端发给服务端的请求数据，这部分数据并不是每个请求必须的。 2、服务端接收客户端http请求阶段 服务端接收来自于网络上的主机请求报文中对某特定资源的一次请求的过程 3、服务端处理客户端http请求阶段 对请求报文进行解析，获取客户端请求的资源及请求方法等相关信息； 根据请求报文的头信息，来确定请求合适，编码等 4、服务端根据客户端http请求与访问自己本地资源 获取请求报文中请求的资源，根据请求，从应用-》系统内核-》驱动-》资源存放媒介（硬盘、内存）获取客户端需要的信息 5、服务端构建http响应报文 服务器接收处理完请求后返回一个HTTP响应消息给客户端。HTTP响应消息的格式包括：状态行、响应头、空行、消息体。每部分内容占一行。 状态行：状态行位于相应消息的第一行，有HTTP协议版本号，状态码和状态说明三部分构成。 响应头：响应头是服务器传递给客户端用于说明服务器的一些信息，以及将来继续访问该资源时的策略。 响应体：响应体是服务端返回给客户端的HTML文本内容，或者其他格式的数据，比如：视频流、图片或者音频数据。 6、服务端将http响应报文发送给客户端 就是在已建立的tcp链接之上将相应报文及客户请求的数据从应用层，传输层、传输层、链路层、物理层层层打包头依次传输到客户端的物理层、链路层、传输层、应用层层层解包，最后客户端获得自己http请求的数据。 7、记录日志 服务端记录http请求访问日志","categories":[],"tags":[{"name":"http","slug":"http","permalink":"https://zhusas.github.io/tags/http/"}]},{"title":"自建DNS总结","slug":"自建DNS总结","date":"2018-08-05T04:05:00.000Z","updated":"2018-08-05T04:07:01.997Z","comments":true,"path":"2018/08/05/自建DNS总结/","link":"","permalink":"https://zhusas.github.io/2018/08/05/自建DNS总结/","excerpt":"DNS查询过程以及DNS服务器类别DNS查询过程 1、在浏览器中输入www.qq.com域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。 2、如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 3、如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/ip参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 4、如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。","text":"DNS查询过程以及DNS服务器类别DNS查询过程 1、在浏览器中输入www.qq.com域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。 2、如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 3、如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/ip参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 4、如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。 5、如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到www.qq.com主机。 6、如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。 从客户端到本地DNS服务器是属于递归查询，而DNS服务器之间就是的交互查询就是迭代查询。 DNS服务器类别 主域名服务器 负责维护这个区域的所有域名信息，是特定的所有信息的权威信息源 辅助域名服务器 当主域名服务器出现故障、关闭或负载过重时，辅助域名服务器作为备份服务提供域名解析服务。辅助域名服务器中的区域文件内的数据是从另外一台域名服务器复制过来的，并不是直接输入的，也就是说这个区域文件只是一份副本，这里的数据是无法修改的。 缓存服务器 可运行域名服务器软件但没有域名数据库。它从某个远程服务器取得每次域名服务器查询的回答，一旦获取一个答案，就将它放在高速缓存中，以后查询相同的信息时就用它予以回答。缓存域名服务器不是权威性服务器，因为提供的所有信息都是间接信息。 转发服务器 负责所有非本地域名的本地查询。转发域名服务器接到查询请求时，在其缓存中查找，如找不到就把请求依次转发到指定的域名服务器，直到查询到结果为止，否则返回无法映射的结果。 搭建一套DNS服务器，负责解析qq.com域名（自行设定主机名及IP） (1)、能够对一些主机名进行正向解析和逆向解析； (2)、对子域cdn.qq.com进行子域授权，子域负责解析对应子域中的主机名； (3)、为了保证DNS服务系统的高可用性，请设计一套方案，并写出详细的实施过程 先来个架构图： 先来安装bind 12345678[root@DNS2 ~]# yum install bind[root@DNS2 ~]# rpm -qa |grep bind #查看安装的包和版本bind-9.8.2-0.47.rc1.el6_8.4.x86_64bind-libs-9.8.2-0.47.rc1.el6_8.4.x86_64PackageKit-device-rebind-0.5.8-26.el6.x86_64bind-utils-9.8.2-0.47.rc1.el6_8.4.x86_64[root@DNS2 ~]# 我是两台DNS测试机一起安装的，这里只列出其中同一台的安装操作命令。 主配置文件之一：/etc/named.conf 主配置文件之二：/etc/named.rfc1912.zones 在文件尾部加上一下内容，这里就实现了能够对qq.com域名进行正向解析和逆向解析 1234567891011zone \"qq.com\" IN &#123; type master; file \"qq.com.zone\"; allow-transter &#123; 192.168.0.244; &#125;; #这里这行IP是从DNS服务器的IP&#125;;zone \"0.168.192.in-addr.arpa\" IN &#123; type master file \"0.168.192.zone\"; allow-transter &#123; 192.168.0.244; &#125;; #这里这行IP是从DNS服务器的IP&#125;; 测试 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@centos named]# dig -x 192.168.0.116; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.47.rc1.el6_8.4 &lt;&lt;&gt;&gt; -x 192.168.0.116;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 31489;; flags: qr aa rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 1, ADDITIONAL: 1;; QUESTION SECTION:;116.0.168.192.in-addr.arpa. IN PTR;; ANSWER SECTION:116.0.168.192.in-addr.arpa. 3600 IN PTR www.qq.com.116.0.168.192.in-addr.arpa. 3600 IN PTR ns1.qq.com.;; AUTHORITY SECTION:0.168.192.in-addr.arpa. 3600 IN NS ns1.qq.com.;; ADDITIONAL SECTION:ns1.qq.com. 3600 IN A 192.168.0.116;; Query time: 0 msec;; SERVER: 127.0.0.1#53(127.0.0.1);; WHEN: Tue Feb 28 13:50:38 2017;; MSG SIZE rcvd: 120[root@centos named]# dig -t A www.qq.com; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.47.rc1.el6_8.4 &lt;&lt;&gt;&gt; -t A www.qq.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 31217;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 1, ADDITIONAL: 1;; QUESTION SECTION:;www.qq.com. IN A;; ANSWER SECTION:www.qq.com. 3600 IN A 192.168.0.116;; AUTHORITY SECTION:qq.com. 3600 IN NS ns1.qq.com.;; ADDITIONAL SECTION:ns1.qq.com. 3600 IN A 192.168.0.116;; Query time: 0 msec;; SERVER: 127.0.0.1#53(127.0.0.1);; WHEN: Tue Feb 28 13:51:04 2017;; MSG SIZE rcvd: 82[root@centos named]# 接下来配置对子域cdn.qq.com进行子域授权，子域负责解析对应子域中的主机名、 另外启动一台，安装bind vim /etc/named.conf vim /etc/named.rfc1912.zones 加入以下内容 1234zone \"cdn.qq.com\" IN &#123; type master; file \"cdn.qq.com.zone\";&#125;; ​ 12345678910111213141516171819202122232425vim /var/named/cdn.qq.com.zone$TTL 3600$ORIGIN cdn.qq.com.@ IN SOA ns1.cdn.qq.com. admin.qq.com. ( 122701 2H 10M 1W 1D ) IN NS ns1ns1 IN A 192.168.20.51www IN A 192.168.20.199# chown :named /var/named/cdn.qq.com.zone# chmod 640 /var/named/cdn.qq.com.zone检查named配置文件及区域配置文件：# named-checkconf# named-checkzone cdn.qq.com /var/named/cdn.qq.com.zone# systemctl start named.service在主域S1上的配置：# vim /var/named/qq.com.zonecdn IN NS ns1.cdnns1.cdn IN A 192.168.20.51# rndc reload测试解析：# dig -t A www.cdn.qq.com DNS服务器主从其实不难，就是很多细节要注意，我先贴配置文件吧 主机 192.168.0.116 /etc/named.conf 123456789101112131415161718192021222324252627282930313233options &#123; listen-on port 53 &#123; 192.168.0.116; &#125;;// listen-on-v6 port 53 &#123; ::1; &#125;; directory \"/var/named\"; dump-file \"/var/named/data/cache_dump.db\"; statistics-file \"/var/named/data/named_stats.txt\"; memstatistics-file \"/var/named/data/named_mem_stats.txt\"; allow-query &#123; any; &#125;; recursion yes; dnssec-enable no; dnssec-validation no; dnssec-lookaside no; /* Path to ISC DLV key */// bindkeys-file \"/etc/named.iscdlv.key\";// managed-keys-directory \"/var/named/dynamic\";&#125;;logging &#123; channel default_debug &#123; file \"data/named.run\"; severity dynamic; &#125;;&#125;;zone \".\" IN &#123; type hint; file \"named.ca\";&#125;;include \"/etc/named.rfc1912.zones\";include \"/etc/named.root.key\"; 从机 192.168.0.117 /etc/named.conf 123456789101112131415161718192021222324252627282930313233options &#123; listen-on port 53 &#123; 192.168.0.117; &#125;;// listen-on-v6 port 53 &#123; ::1; &#125;; directory \"/var/named\"; dump-file \"/var/named/data/cache_dump.db\"; statistics-file \"/var/named/data/named_stats.txt\"; memstatistics-file \"/var/named/data/named_mem_stats.txt\"; allow-query &#123; any; &#125;; recursion yes; dnssec-enable no; dnssec-validation no; dnssec-lookaside no; /* Path to ISC DLV key */// bindkeys-file \"/etc/named.iscdlv.key\";// managed-keys-directory \"/var/named/dynamic\";&#125;;logging &#123; channel default_debug &#123; file \"data/named.run\"; severity dynamic; &#125;;&#125;;zone \".\" IN &#123; type hint; file \"named.ca\";&#125;;include \"/etc/named.rfc1912.zones\";include \"/etc/named.root.key\"; 打开辅助DNS服务器的/etc/named.rfc1912.zones文件，添加两个区域记录，这两个记录是主DNS服务器配置文件里已经存在的记录，一个是正向解析记录，一个是反向解析记录 type: slave，表示此时DNS服务器为辅助DNS服务器，于是下面一行就要定义主DNS服务器的IP地址，辅助DNS服务器才知道去哪里同步数据。辅助DNS服务器的资源类型数据文件通常保存在slaves目录，只需定义一个名称，文件内容通常是自动生成。 1234567891011zone \"qq.com\" IN &#123; type slave; file \"slaves/qq.com.zone\"; masters &#123; 192.168.0.116; &#125;;&#125;;zone \"0.168.192.in-addr.arpa\" IN &#123; type slave; file \"slaves/192.168.0.116.zone\"; masters &#123; 192.168.0.116; &#125;;&#125;; 修改主DNS服务器的数据文件，添加一条辅助DNS服务器记录，给辅助DNS服务器授权。 正向解析文件vim /var/named/qq.com.zone 123456789101112131415$TTL 3600$ORIGIN qq.com.@ IN SOA ns1.qq.com. admin.qq.com. ( 2016122703 2H 10M 1W 1D ) IN NS ns1ns1 IN A 192.168.0.116www IN A 192.168.0.116cdn IN NS ns1.cdnns1.cdn IN A 192.168.0.117 IN NS ns2ns2 IN A 192.168.0.117 添加了一条NS记录，值为，ns2.qq.com.，对应的A记录也要增加一条，把IP地址指向对应的辅助DNS服务器的IP地址。修改完成后，记得要把序列号的值加1，用于通知辅助DNS服务器自动更新数据文件。 修改反向解析文件/var/named/0.168.192.zone 12345678910111213$TTL 3600$ORIGIN 0.168.192.in-addr.arpa.@ IN SOA ns1.qq.com. nsadmin.qq.com. ( 16122702 1H 10M 3D 12H ) IN NS ns1.qq.com.116 IN PTR ns1.qq.com.116 IN PTR www.qq.com. IN NS ns2.qq.com.117 IN PTR ns2.qq.com. 同样的也增加了两条记录，一条辅助DNS服务器的NS记录和对应的PTR记录。修改完成后记得所序列号的值加1，用于通知辅助DNS服务器自动更新数据文件。 最后两边都把named服务重启一下，再rndc reload 就好","categories":[],"tags":[{"name":"DNS","slug":"DNS","permalink":"https://zhusas.github.io/tags/DNS/"}]},{"title":"通讯加密及私有CA","slug":"通讯加密及私有CA","date":"2018-08-05T03:37:00.000Z","updated":"2018-08-05T03:40:00.167Z","comments":true,"path":"2018/08/05/通讯加密及私有CA/","link":"","permalink":"https://zhusas.github.io/2018/08/05/通讯加密及私有CA/","excerpt":"记一次加密通讯的过程 第一阶段：ClientHello：支持的协议版本，比如tls 1.2；客户端生成一个随机数，稍后用户生成“会话密钥”支持的加密算法，比如AES、3DES、RSA；支持的压缩算法；","text":"记一次加密通讯的过程 第一阶段：ClientHello：支持的协议版本，比如tls 1.2；客户端生成一个随机数，稍后用户生成“会话密钥”支持的加密算法，比如AES、3DES、RSA；支持的压缩算法； 第二阶段：ServerHello确认使用的加密通信协议版本，比如tls 1.2；服务器端生成一个随机数，稍后用于生成“会话密钥”确认使用的加密方法；服务器证书； 第三阶段：验正服务器证书，在确认无误后取出其公钥；（发证机构、证书完整性、证书持有者、证书有效期、吊销列表）发送以下信息给服务器端：一个随机数；编码变更通知，表示随后的信息都将用双方商定的加密方法和密钥发送；客户端握手结束通知； 第四阶段：收到客户端发来的第三个随机数pre-master-key后，计算生成本次会话所有到的“会话密钥”；向客户端发送如下信息：编码变更通知，表示随后的信息都将用双方商定的加密方法和密钥发送；服务端握手结束通知； 下图来个通俗版的(密匙版本，可能不是完全吻合)： 创建私有CA的过程，以及为客户端发来的证书请求进行颁发证书创建私有CA的过程 第一步：生成私钥 123456789[root@centos private]# (umask 077; openssl genrsa -out /etc/pki/CA/private/jerry_cakey.pam 8192)Generating RSA private key, 8192 bit long modulus......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................++..........++e is 65537 (0x10001)[root@centos private]# ll总用量 8-rw------- 1 root root 6363 2月 24 15:39 jerry_cakey.pam[root@centos private]# 第二步：生成自签证书 1234567891011[root@centos private]# openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -out /etc/pki/CA/cacert.pem -days 3655-new：生成新证书签署请求；-x509：生成自签格式证书，专用于创建私有CA时；-key：生成请求时用到的私有文件路径；-out：生成的请求文件路径；如果自签操作将直接生成签署过的证书；-days：证书的有效时长，单位是day； 第三步：为CA提供所需的目录及文件；** 123[root@centos private]# mkdir -pv /etc/pki/CA/&#123;certs,crl,newcerts&#125;[root@centos private]# touch /etc/pki/CA/&#123;serial,index.txt&#125;[root@centos private]# echo 01 &gt; /etc/pki/CA/serial 为客户端发来的证书请求进行颁发证书 第一步:用到证书的主机生成私钥: 1234567[root@centos ~]# cd /etc/httpd/ssl[root@centos ssl]# (umask 077; openssl genrsa -out /etc/httpd/ssl/httpd.key 8192)Generating RSA private key, 8192 bit long modulus......................................................................................................................................................................................................................................................................++......................................................................................................................................................................................++e is 65537 (0x10001)[root@centos ssl]# 第二步:生成证书签署请求 123456789101112131415161718192021[root@centos ssl]# openssl req -new -key /etc/httpd/ssl/httpd.key -out /etc/httpd/ssl/httpd.csr -days 365You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter '.', the field will be left blank.-----Country Name (2 letter code) [XX]:CNState or Province Name (full name) []:HubeiLocality Name (eg, city) [Default City]:WuhanOrganization Name (eg, company) [Default Company Ltd]:wanghuakejiOrganizational Unit Name (eg, section) []:OpsCommon Name (eg, your name or your server's hostname) []:whmall.comEmail Address []:caadmin@whmall.comPlease enter the following 'extra' attributesto be sent with your certificate requestA challenge password []:qweasdzxcAn optional company name []: [root@centos ssl]# 第三步:将请求通过可靠方式发送给CA主机 两台主机就用scp，我这里是都在一台虚拟机上就用cp命令，过于简单，就不贴过程了 第四步：在CA主机上签署证书 1234567891011121314151617181920212223242526272829303132[root@centos ssl]# openssl ca -in /etc/httpd/ssl/httpd.csr -out /etc/pki/CA/certs/httpd.crt -days 365Using configuration from /etc/pki/tls/openssl.cnfCheck that the request matches the signatureSignature okCertificate Details: Serial Number: 1 (0x1) Validity Not Before: Feb 24 09:08:16 2017 GMT Not After : Feb 24 09:08:16 2018 GMT Subject: countryName = CN stateOrProvinceName = Hubei organizationName = FBI organizationalUnitName = Ops commonName = xxx.com emailAddress = caadmin@xxx.com X509v3 extensions: X509v3 Basic Constraints: CA:FALSE Netscape Comment: OpenSSL Generated Certificate X509v3 Subject Key Identifier: D9:4A:37:A2:3E:C4:0D:B8:DF:BF:97:D2:DF:6F:21:6D:B5:56:E1:47 X509v3 Authority Key Identifier: keyid:07:17:C7:46:2F:05:5C:12:D3:10:65:DE:58:83:36:A3:A9:0D:02:17Certificate is to be certified until Feb 24 09:08:16 2018 GMT (365 days)Sign the certificate? [y/n]:y1 out of 1 certificate requests certified, commit? [y/n]yWrite out database with 1 new entriesData Base Updated[root@centos ssl]# ​","categories":[],"tags":[{"name":"CA","slug":"CA","permalink":"https://zhusas.github.io/tags/CA/"},{"name":"SSL","slug":"SSL","permalink":"https://zhusas.github.io/tags/SSL/"}]},{"title":"脚本写到手抽筋","slug":"脚本写到手抽筋","date":"2018-08-05T03:12:00.000Z","updated":"2018-08-05T03:13:52.635Z","comments":true,"path":"2018/08/05/脚本写到手抽筋/","link":"","permalink":"https://zhusas.github.io/2018/08/05/脚本写到手抽筋/","excerpt":"为运行于虚拟机上的CentOS 6添加一块新硬件，提供两个主分区 (1) 为硬盘新建两个主分区；并为其安装grub； (2) 为硬盘的第一个主分区提供内核和ramdisk文件； 为第二个分区提供rootfs； (3) 为rootfs提供bash、ls、cat程序及所依赖的库文件； (4) 为grub提供配置文件； (5) 将新的硬盘设置为第一启动项并能够正常启动目标主机；","text":"为运行于虚拟机上的CentOS 6添加一块新硬件，提供两个主分区 (1) 为硬盘新建两个主分区；并为其安装grub； (2) 为硬盘的第一个主分区提供内核和ramdisk文件； 为第二个分区提供rootfs； (3) 为rootfs提供bash、ls、cat程序及所依赖的库文件； (4) 为grub提供配置文件； (5) 将新的硬盘设置为第一启动项并能够正常启动目标主机； 为硬盘新建两个主分区 12345678910111213141516171819202122232425262728293031323334[root@centos ~]# fdisk -l #先来看看磁盘情况啊，你不看，一上来直接搞，小心搞出事情！！Disk /dev/sda: 171.8 GB, 171798691840 bytes255 heads, 63 sectors/track, 20886 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00098b32 Device Boot Start End Blocks Id System/dev/sda1 * 1 64 512000 83 LinuxPartition 1 does not end on cylinder boundary./dev/sda2 64 20887 167259136 8e Linux LVMDisk /dev/sdb: 42.9 GB, 42949672960 bytes255 heads, 63 sectors/track, 5221 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/mapper/vg_centos-lv_root: 170.2 GB, 170196467712 bytes255 heads, 63 sectors/track, 20691 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/mapper/vg_centos-lv_swap: 1073 MB, 1073741824 bytes255 heads, 63 sectors/track, 130 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000 ​ 不错不错，看到sdb了， 分的40G 开始分区 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061[root@centos ~]# fdisk /dev/sdbCommand (m for help): pDisk /dev/sdb: 42.9 GB, 42949672960 bytes255 heads, 63 sectors/track, 5221 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x86662f67 Device Boot Start End Blocks Id SystemCommand (m for help): nCommand action e extended p primary partition (1-4)pPartition number (1-4): 1First cylinder (1-5221, default 1): Using default value 1Last cylinder, +cylinders or +size&#123;K,M,G&#125; (1-5221, default 5221): +20GCommand (m for help): pDisk /dev/sdb: 42.9 GB, 42949672960 bytes255 heads, 63 sectors/track, 5221 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x86662f67 Device Boot Start End Blocks Id System/dev/sdb1 1 2612 20980858+ 83 LinuxCommand (m for help): nCommand action e extended p primary partition (1-4)pPartition number (1-4): 2First cylinder (2613-5221, default 2613): Using default value 2613Last cylinder, +cylinders or +size&#123;K,M,G&#125; (2613-5221, default 5221): Using default value 5221Command (m for help): pDisk /dev/sdb: 42.9 GB, 42949672960 bytes255 heads, 63 sectors/track, 5221 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x86662f67 Device Boot Start End Blocks Id System/dev/sdb1 1 2612 20980858+ 83 Linux/dev/sdb2 2613 5221 20956792+ 83 LinuxCommand (m for help): wThe partition table has been altered! 分区完了就开始格式化了啊 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[root@centos ~]# mkfs.ext4 /dev/sdb1mke2fs 1.41.12 (17-May-2010)文件系统标签=操作系统:Linux块大小=4096 (log=2)分块大小=4096 (log=2)Stride=0 blocks, Stripe width=0 blocks1313760 inodes, 5245214 blocks262260 blocks (5.00%) reserved for the super user第一个数据块=0Maximum filesystem blocks=4294967296161 block groups32768 blocks per group, 32768 fragments per group8160 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 4096000正在写入inode表: 完成 Creating journal (32768 blocks): 完成Writing superblocks and filesystem accounting information: 完成This filesystem will be automatically checked every 21 mounts or180 days, whichever comes first. Use tune2fs -c or -i to override.[root@centos ~]# mkfs.ext4 /dev/sdb2mke2fs 1.41.12 (17-May-2010)文件系统标签=操作系统:Linux块大小=4096 (log=2)分块大小=4096 (log=2)Stride=0 blocks, Stripe width=0 blocks1310720 inodes, 5239198 blocks261959 blocks (5.00%) reserved for the super user第一个数据块=0Maximum filesystem blocks=4294967296160 block groups32768 blocks per group, 32768 fragments per group8192 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 4096000正在写入inode表: 完成 Creating journal (32768 blocks): 完成Writing superblocks and filesystem accounting information: 完成This filesystem will be automatically checked every 26 mounts or180 days, whichever comes first. Use tune2fs -c or -i to override. 挂载分区sdb1到/mnt/boot下 12[root@centos mnt]#mkdir boot[root@centos mnt]#mount /dev/sdb1 /mnt/boot 安装grub 123456789[root@centos mnt]# grub-install --root-de[root@centos mnt]# grub-install --root-directory=/mnt /dev/sdbProbing devices to guess BIOS drives. This may take a long time./dev/mapper/vg_centos-lv_root does not have any corresponding BIOS drive.[root@centos mnt]# ll总用量 8drwxr-xr-x 3 root root 4096 2月 20 10:09 bootdrwxr-xr-x 2 root root 4096 10月 18 10:41 hgfs[root@centos mnt]# 复制内核及ramdisk文件到sdb1上 12[root@centos mnt]# cp /boot/vmlinuz-2.6.32-642.13.1.el6.x86_64 /mnt/boot/vmlinuz[root@centos mnt]# cp /boot/initramfs-2.6.32-642.13.1.el6.x86_64.img /mnt/boot/initramfs.img 在/mnt/boot/grub目录下编辑新建grub.conf文件 内容如下： 123456default=0timeout=5title CentOS6(test)root (hd0,0)kernel /vmlinuz ro root=/dev/sda2 selinux=0 init=/bin/bashinitrd /initramfs.img 挂载分区/dev/sdb2到/mnt/sysroot下 12mkdir /mnt/sysrootmount /dev/sdb2 /mnt/sysroot/ 建立FHS 123456789101112131415161718192021222324[root@centos sysroot]# mkdir -pv /mnt/sysroot/&#123;bin,dev,etc/&#123;rc.d/init.d,sysconfig/network-scripts&#125;,lib/modules,lib64,proc,sbin,sys,tmp,usr/local/&#123;bin,sbin&#125;,var/&#123;lock,log,run&#125;&#125;mkdir: 已创建目录 \"/mnt/sysroot/bin\"mkdir: 已创建目录 \"/mnt/sysroot/dev\"mkdir: 已创建目录 \"/mnt/sysroot/etc\"mkdir: 已创建目录 \"/mnt/sysroot/etc/rc.d\"mkdir: 已创建目录 \"/mnt/sysroot/etc/rc.d/init.d\"mkdir: 已创建目录 \"/mnt/sysroot/etc/sysconfig\"mkdir: 已创建目录 \"/mnt/sysroot/etc/sysconfig/network-scripts\"mkdir: 已创建目录 \"/mnt/sysroot/lib\"mkdir: 已创建目录 \"/mnt/sysroot/lib/modules\"mkdir: 已创建目录 \"/mnt/sysroot/lib64\"mkdir: 已创建目录 \"/mnt/sysroot/proc\"mkdir: 已创建目录 \"/mnt/sysroot/sbin\"mkdir: 已创建目录 \"/mnt/sysroot/sys\"mkdir: 已创建目录 \"/mnt/sysroot/tmp\"mkdir: 已创建目录 \"/mnt/sysroot/usr\"mkdir: 已创建目录 \"/mnt/sysroot/usr/local\"mkdir: 已创建目录 \"/mnt/sysroot/usr/local/bin\"mkdir: 已创建目录 \"/mnt/sysroot/usr/local/sbin\"mkdir: 已创建目录 \"/mnt/sysroot/var\"mkdir: 已创建目录 \"/mnt/sysroot/var/lock\"mkdir: 已创建目录 \"/mnt/sysroot/var/log\"mkdir: 已创建目录 \"/mnt/sysroot/var/run\"[root@centos sysroot]# 拷贝bash、ls、cat程序及其依赖库 12345[root@centos sysroot]# cp /bin/&#123;bash,ls,cat&#125; /mnt/sysroot/bin[root@centos bin]# cp `ldd /bin/&#123;bash,ls,cat&#125; |grep -oe \"/lib.*[[:space:]]\"|sort -u` /mnt/sysroot/lib64/[root@centos bin]# chroot /mnt/sysroot chroot先测试一下 123456[root@centos bin]# chroot /mnt/sysrootbash-4.1# lsbin dev etc lib lib64 proc sbin sys tmp usr varbash-4.1# exitexit[root@centos bin]# OK，接下来挂载到另外一台虚拟机上测试一下，亲测成功。 制作一个kickstart文件以及一个引导镜像。思路 找到一个已安装好的centos的ks文件，一般位于/root/anaconda-ks.cfg，修修改改，生成一个自定义的ks.cfg文件。 放到解压的原版IOS到某目录，添加ks文件。 修改光盘的isolinux.cfg文件，在 append 指令后附加 ks 设置。 再生成自定义的ISO文件。 最后用此ISO去安装启动一台裸虚拟机测试是否能自动安装。 找到一个已安装好的centos的ks文件，一般位于/root/anaconda-ks.cfg，修修改改，生成一个自定义的ks.cfg文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899#platform=x86, AMD64, 或 Intel EM64T#version=DEVEL# Firewall configurationfirewall --disabled# Install OS instead of upgradeinstall# Use CDROM installation mediacdrom# Root passwordrootpw --iscrypted $1$Qo3PJbQH$GyTUtGgr1U.th4KTIrvfT1# System authorization informationauth --useshadow --passalgo=sha512# Use graphical installgraphicalfirstboot --disable# System keyboardkeyboard us# System languagelang zh_CN# SELinux configurationselinux --disabled# Installation logging levellogging --level=info# System timezonetimezone Asia/Shanghai# Network informationnetwork --bootproto=dhcp --device=eth1 --onboot=on# System bootloader configurationbootloader --location=mbr# Partition clearing informationclearpart --all --initlabel # Disk partitioning informationpart /boot --fstype=\"ext4\" --size=500part swap --fstype=\"swap\" --size=2000part / --fstype=\"ext4\" --grow --size=1%packages@base@compat-libraries@graphical-admin-tools@legacy-unix@network-tools@xfce-desktopNetworkManager-openswanarptables_jfarpwatchaudit-viewerauthdcups-lpddbenchdropwatchdumpebtablesettercapfingerfinger-serverfirstaidkit-guiipsetiptrafiptstatekrb5-appl-serverskshlksctp-toolslshw-guimipv6-daemonmkshmrtgncompressnetlabel_toolsnmapopenvpnpolicycoreutils-guiqstatrshrsh-serverrusersrusers-serverrwhosabayonsetroubleshootstunnelsystem-config-kickstartsystem-config-lvmtalktalk-servertcp_wrapperstelnettelnet-servertftpvtunwiresharkwireshark-gnomeyumex-cpuspeed-irqbalance-mdadm%end 放到解压的原版IOS到某目录，添加ks文件 我这里是用软碟通直接提取修改，所以就省略了 还有一个坑就是ks配置文件里面用cdrom参数制定本地光盘安装会报错，建议用url方式。这个坑踩得我受伤了，就不写了。 应用服务服务脚本 (1) 能接受四个参数：start, stop, restart, status start: 输出“starting 脚本名 finished.” … (2) 其它任意参数，均报错退出； 123456789101112131415161718192021222324#!/bin/bash#case $1 in start) echo \"starting $0 finished\" ;; stop) echo \"stopping $0 finished\" ;; restart) echo \"restarting $0 finished\" ;; status) echo \" $0 status\" ;; *) echo \"Usage: $prog &#123;start|stop|restart|status&#125;\" exit 1 ;;esac ​ 判断给定的用户是否登录了当前系统 (1) 如果登录了，则显示用户登录，脚本终止； (2) 每3秒钟，查看一次用户是否登录； 12345#!/bin/bash#until who | grep \"^logstash\\&gt;\" &amp;&gt; /dev/null; do sleep 3done 显示用户选定要查看的信息； cpu) display cpu info mem) display memory info disk) display disk info quit) quit 非此四项选择，则提示错误，并要求用户重新选择，只到其给出正确的选择为止； 123456789101112131415161718192021222324252627282930313233#!/bin/bash#cat &lt;&lt; EOFDisplay information as following shown selectioncpu) display cpu infomem) display memory infodisk) display disk infoquit) quit************************************************EOFwhile true; do read -p \"Please input your selection: \" selection case $selection in cpu) lscpu ;; mem) free -m ;; disk) fdisk -l /dev/vd[a-z] ;; quit) echo \"Bye Bye\" exit 0 ;; *) echo \"Please input valid selection\" ;; esacdone 尝试用shell函数 (1) 用函数实现返回一个用户的UID和SHELL；用户名通过参数传递而来； (2) 提示用户输入一个用户名或输入“quit”退出； 当输入的是用户名，则调用函数显示用户信息； 当用户输入quit，则退出脚本；进一步地：显示键入的用户相关信息后，再次提醒输出用户名或quit: 123456789101112131415161718192021222324252627282930#!/bin/bash#userInfo() &#123; local userLine=$(grep $1 /etc/passwd) local userSHELL=$&#123;userLine##*:&#125; local userID=$(echo $userLine | cut -f3 -d:) echo \"$userSHELL and $userID\" &#125;quit() &#123; if [ \"$1\" == \"quit\" ]; then echo \"Bye Bye\" exit 2 fi&#125; while true; do read -p \"Please input your username or input 'quit': \" choice if [ \"$choice\" == \"quit\" ]; then quit $choice break fi if id $choice &gt;&amp; /dev/null; then userInfo $choice fidone ​ 完成如下功能（使用shell函数） (1) 提示用户输入一个可执行命令的名字；获取此命令依赖的所有库文件； (2) 复制命令文件至/mnt/sysroot目录下的对应的rootfs的路径上，例如，如果复制的文件原路径是/usr/bin/useradd，则复制到/mnt/sysroot/usr/bin/目录中； (3) 复制此命令依赖的各库文件至/mnt/sysroot目录下的对应的rootfs的路径上；规则同上面命令相关的要求； 12345678910111213141516171819202122232425#!/bin/bashread -p \"Please input a command: \" cmdcmdPath=$(which $cmd | grep bin)cpCmd() &#123;cp $cmdPath /mnt/sysroot$cmdpathecho \"Copy $cmdPath to path /mnt/sysroot/\"&#125;cpFile() &#123;libFile=$(ldd $cmdPath | grep -o \"/[^[:space:]]\\&#123;1,\\&#125;\")for i in $libFile; do cp $lib /mnt/sysroot$cmdPath echo \"Copy $libFile to path/mnt/sysroot/$cmdPath\"done&#125;cpCmdcpFile","categories":[],"tags":[{"name":"shell","slug":"shell","permalink":"https://zhusas.github.io/tags/shell/"}]},{"title":"CentOS系统的启动流程","slug":"CentOS系统的启动流程","date":"2018-08-05T03:08:00.000Z","updated":"2018-08-05T03:10:27.436Z","comments":true,"path":"2018/08/05/CentOS系统的启动流程/","link":"","permalink":"https://zhusas.github.io/2018/08/05/CentOS系统的启动流程/","excerpt":"详细到每个过程系统做了哪些事情","text":"详细到每个过程系统做了哪些事情 启动过程 （PC架构） POST –&gt; Boot Sequence(BIOS) –&gt; Boot Loader (MBR)–&gt;GRUB—&gt; Kernel(ramdisk) –&gt; rootfs –&gt; switchroot –&gt; /sbin/init–&gt;(/etc/inittab, /etc/init/*.conf) –&gt; 设定默认运行级别&gt; 系统初始化脚本 –&gt; 关闭或启动对应级别下的服务 –&gt; 启动终端 第一步：加电自检（POST） 系统加电之后，首先进行的硬件自检，一但通电后主板会自动读取ROM（只读）中的程序，进行加载，计算机会首先加载BIOS信息，BIOS信息是如此的重要，以至于计算机必须在最开始就找到它。检查各种硬件设备是否完整存在，如内存，硬盘，显示,IO设备等。如果有硬件故障的话将按两种情况理：对于严重故障(致命性故障)则停机，此时由于各种初始化操作还没完成，不能给出任何提示或信号；对于非严重故障则给出提示或声音报警信号，等待用户处理），如果没有故障，POST完成自己的接力任务，将尾部工作交接给BIOS处理。 第二步：系统引导过程Boot Sequence（BIOS） POST 过程结束后，系统的控制权从 BISO 转交到 boot loader。Boot loader 一般存储在系统的硬盘上（传统的 BIOS/MBR 系统），这个时候机器不能获取外部的存储或者网络信息，一些重要的值（日期、时间、其他外部值）都是从CMOS里读取. POST（POST-power on self test)—&gt;ROM-&gt;CMOS(互补金属氧化物)-&gt;BIOS (Basic Input Output System，基础输入输出系统） BIOS（Basic Input/Output System）启动初始化硬件的工作，包括屏幕和键盘，内存检测，这个过程也被成为 POST（Power On Self Test），通过ROM加载自检程序，然后按照 CMOS RAM 中设置的启动设备查找顺序，来寻找可启动设备 。注：BIOS 程序嵌在主板的 ROM 芯片上的。 第三步：启动加载器阶段Master Boot Loader(MBR) 硬盘上第0磁道第一个扇区被称为MBR，也就是Master Boot Record，即主引导记录，决定启动介质按照BIOS所设定的系统启动流程，根据引导次序(Boot Sequence)自上而下的寻找对应存储设备上操作系统的MBR。它的大小仅有512字节，但里面却存放了预启动信息、分区表信息。可分为两部分： 第一部分为引导（PRE-BOOT）区，占了 446个字节； 第二部分为分区表（PARTITION TABLE），共有64个字节，每个主分区占用16字节，记录硬盘的分区信息。（这就是为什么一块硬盘只能有4个主分区）分区表有效性标记会占用2字节。 预引导区的作用之一是找到标记为活动（ACTIVE）的分区，并将活动分区的引导区读入内存。剩余两个字节为结束标记。寻找 grub，读取配置文件/etc/grub.conf，决定默认启动项根据MBR所指引的活动分区上寻找系统分区中的 bootloader.在bootloader当中配置了所要引导操作系统的内核所在的位置，因此BIOS被载入内存以后，当它实现将控制权限转交给bootloader以后，bootloader接收整个系统的控制权限，而后根据用户的选择去读取相应操作系统中的内核，并将内核装载入内存的某个空间位置，解压缩，这时kernel就可以在内存中活动，并根据kernel本身功能在内存当中探索硬件并加载硬件驱动程序并完成内核初始化，bootloader会将控制权限转交给内核。 第四步：引导加载器阶段（GRUB加载器） 对于GRUB来说，一个比较好的方面就是它包含了linux文件系统的支持。GRUB能够从ext2或者ext3文件系统中加载linux内核。一旦Bootloader的第一阶段已完成MBR（启动加载器阶段），并能找到实际的引导加载程序位置，第1阶段启动加载器加载引导程序到内存中开始第二阶段。GRUB引导加载器阶段它是通过将本来两阶段的boot loader转换成三个阶段的boot loader。 stage1个阶段 ：BIOS加载MBR里面的GRUB（属于第1阶段的文件），由于只有GRUB只占用446字节所以不能实现太多的功能，所以就有此阶段里面的文件来加载第1.5阶段的文件（/boot/grub下的文件） stage1.5个阶段：这个阶段里面的就是加载识别文件系统的程序，来识别文件系统，不加载就无法识别文件系统，进而就找不到boot目录，由于GRUB是无法识别LVM，所以你不能把/boot分区设置为LVM，所以必须要把/boot单独分区 stage2个阶段：这里面才是正在的开始寻找内核的过程，然后是启动内核 （当stage1.5的boot loader被加载并运行时，stage2 的boot loader才能被加载。） 当stage2被加载时，GRUB能根据请求的情况显示一个可选内核的清单（在 /etc/grub.conf 中进行定义，同时还有几个软符号链接 /etc/grub/menu.lst 和 /etc/grub.conf)。你可以选择一个内核，修改其附加的内核参数。同时，你可以选择使用命令行的shell来对启动过程进行更深层次的手工控制。 GRUB的配置文件中的配置哪些信息 在第二阶段boot loader加载到内存中后，就可以对文件系统进行查询了，同时，默认的内核镜像以及初始化内存盘镜像也被加载到内存中。 根据grub设定的内核映像所在路径，系统读取内存映像，并进行解压缩操作。此时，屏幕一般会输出“Uncompressing Linux(解压内核中)”的提示。当解压缩内核完成后，屏幕输出“OK, booting the kernel(正在启动内核)”。 第五步：加载kernel GRUB把内核加载到内存后展开并运行，此时GRUB的任务已经完成，接下来内核将会接管并完成： 探测硬件—&gt;加载驱动—&gt;挂载根文件系统—&gt;切换至根文件系统（rootfs）—&gt;运行/sbin/init完成系统初始化 内核一般都是压缩的，所以它的首要任务是解压缩，然后检查和分析系统的硬件并初始化内核里的硬件驱动程序。内核刚加载到内存的时候，文件系统还不能使用，它使用的是 Boot Loader 加载进内存的 initramfs。系统将解压后的内核放置在内存之中，并调用start_kernel()函数来启动一系列的初始化函数并初始化各种设备，完成Linux核心环境的建立。至此，Linux内核已经建立起来了，基于Linux的程序应该可以正常运行了。 第六步：初始化initrd /etc/inittab 在核心加载完毕,进行完硬件侦测与驱动程序加载后,内核会启动第一个进程/sbin/init, init进程将会读取/etc/inittab，init进程是系统所有进程的起点，你可以把它比拟成系统所有进程的老祖宗，没有这个进程，系统中任何进程都不会启动。 /etc/inittab最主要的功能就是准备软件运行的环境，包括系统的主机名称、网络配置、语系处理、文件系统格式及其他服务的启动等,而所有的动作都根据在/etc/inittab中的配置.将会执行/etc/inittab来设定系统运行的默认级别， init进程首先会读取/etc/inittab文件，根据inittab文件中的内容依次执行 设定系统运行的默认级别（id:3:initdefault:） 执行系统初始化脚本文件（si::sysinit:/etc/rc.d/rc.sysinit） 执行在该运行级别下所启动或关闭对应的服务（l3:3:wait:/etc/rc.d/rc 3） 启动6个虚拟终端 0-6：7个级别的定义 0：关机, shutdown 1：单用户模式(singleuser)，root用户，无须认证；维护模式； 2：多用户模式(multiuser)，会启动网络功能，但不会启动NFS；维护模式； 3：多用户模式(mutliuser)，完全功能模式；文本界面； 4：预留级别：目前无特别使用目的，但习惯以同3级别功能使用； 5：多用户模式(multi user)，完全功能模式，图形界面； 6：重启，reboot 许多程序需要开机启动。它们在Windows叫做”服务”（service），在Linux就叫做”守护进程”（daemon）。init进程的一大任务，就是去运行这些开机启动的程序。但是，不同的场合需要启动不同的程序，比如用作服务器时，需要启动Apache，用作桌面就不需要。 Linux允许为不同的场合，分配不同的开机启动程序，这就叫做”运行级别”（runlevel）。也就是说，启动时根据”运行级别”，确定要运行哪些程序。 要访问根文件系统必须要加载根文件系统所在的设备，而这时根文件系统又没有挂载，要挂载根文件系统有需要根文件系统的驱动程序，这是一个典型的先有鸡先有蛋的问题！为解决这个问题，GRUB在加载内核同时，也把initrd加载到内存中并运行.那么initrd又起到了什么作用哪？ initrd展开后的文件 linux中/下的文件 我们可以看到，其实initrd文件其实是一个虚拟的根文件系统，里面有bin、lib、lib64、sys、var、etc、sysroot、dev、proc、tmp等根目录，它的功能就是讲内核与真正的根建立联系，内核通过它加载根文件系统的驱动程序，然后以读写方式挂载根文件系统，至此，内核加载完成。 第七步：运行/sbin/init，进行系统初始化 /sbin/init 最主要的功能就是准备软件运行的环境，包括系统的主机名称、网络配置、语系处理、文件系统格式及其他服务的启动等,而所有的动作都根据在/etc/inittab中的配置.init首先运行/etc/init/rcS.conf脚本 第八步：启动系统服务/etc/rc.d/rc.sysinit 可以看到，init进程通过执行/etc/rc.d/rcS.conf首先调用了/etc/rc.d/rc.sysinit，对系统做初始化设置，设置好整个系统环境。我们来看看这个脚本都是做了些什么哪？ 事实上init执行/etc/rc.d/rc.sysinit的初始化将会做很多设置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344451、获得网络环境 2、挂载设备 3、开机启动画面Plymouth（取替了过往的 RHGB） 4、判断是否启用SELinux 5、显示于开机过程中的欢迎画面 6、初始化硬件 7、用户自定义模块的加载 8、配置内核的参数 9、设置主机名 10、同步存储器 11、设备映射器及相关的初始化 12、初始化软件磁盘阵列（RAID） 13、初始化 LVM 的文件系统功能 14、检验磁盘文件系统（fsck） 15、设置磁盘配额(quota) 16、重新以可读写模式挂载系统磁盘 17、更新quota（非必要） 18、启动系统虚拟随机数生成器 19、配置机器（非必要） 20、清除开机过程当中的临时文件 21、创建ICE目录 22、启动交换分区（swap） 23、将开机信息写入/var/log/dmesg文件中 第九步：启动配置文件/etc/rc.d/rc.n 设定完系统默认运行级别以后，接着调用/etc/rc.d/rc脚本，/etc/rc.d, 里面存放了rc.local, rc.sysinit, init.d, rcX.d (X包括0-6对应相对runlevel).这个脚本接收默认运行级别参数后，依脚本设置启用或停止/etc/rc.d/rc[0-6].d/中相应的程序。 /etc/rc.d/rc3].d/下的脚本文件在系统初始化阶段，脚本名字以K开头的,表示STOP动作（关闭）,名字以S开头,表示Start动作（启动）,文件名K/S 后面的的数字代表优先级，名称中的数字表示执行次序（优先级）,数字越小表示越先执行，优先级越高 第十步：用户自定义开机启动程序 (/etc/rc.d/rc.local) 系统根据runlevel启动完rcX.d中的脚本之后,会调用rc.local脚本,如果你有一个脚本命令不论在3和5都想开机启动,那么就添加于此,免去rc3.d和rc5.d分别增加启动脚本工作量.最后，将执行/etc/rc.d/rc.local脚本，可以根据自己的需求将一些执行命令或者脚本写到其中，当开机时就可以加载。 第十一步：打印登录提示符 系统初始化完成后，init给出用户登录提示符（login）或者图形化登录界面，用户输入用户和密码登陆后，系统会为用户分配一个用户ID（uid）和组ID（gid），这两个ID是用户的身份标识，用于检测用户运行程序时的身份验证。登录成功后，整个系统启动流程运行完毕！","categories":[],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://zhusas.github.io/tags/CentOS/"}]},{"title":"脚本小练","slug":"脚本小练","date":"2018-08-05T02:49:00.000Z","updated":"2018-08-05T02:51:11.366Z","comments":true,"path":"2018/08/05/脚本小练/","link":"","permalink":"https://zhusas.github.io/2018/08/05/脚本小练/","excerpt":"1、判断当前系统上所有用户的shell是否为可登录shell（即用户的shell不是/sbin/nologin）；分别这两类用户的个数；通过字符串比较来实现； 1234567891011121314151617#脚本内容[root@centos script]# cat week9_title1.sh #!/bin/bash#Author Jerry##Display shell is nologin user's shell count echo \"The shell is nologin user count is $(grep -o \"nologin\" /etc/passwd |wc -l)\" #Display shell not's nologin user's shell count echo \"The shell not's nologin user count is $(grep -v \"nologin\" /etc/passwd |wc -l)\" #测试脚本[root@centos script]# bash week9_title1.sh The shell is nologin user count is 25The shell not's nologin user count is 7[root@centos script]#","text":"1、判断当前系统上所有用户的shell是否为可登录shell（即用户的shell不是/sbin/nologin）；分别这两类用户的个数；通过字符串比较来实现； 1234567891011121314151617#脚本内容[root@centos script]# cat week9_title1.sh #!/bin/bash#Author Jerry##Display shell is nologin user's shell count echo \"The shell is nologin user count is $(grep -o \"nologin\" /etc/passwd |wc -l)\" #Display shell not's nologin user's shell count echo \"The shell not's nologin user count is $(grep -v \"nologin\" /etc/passwd |wc -l)\" #测试脚本[root@centos script]# bash week9_title1.sh The shell is nologin user count is 25The shell not's nologin user count is 7[root@centos script]# 2、写一个脚本 (1) 获取当前主机的主机名，保存于hostname变量中； (2) 判断此变量的值是否为localhost，如果是，则将当前主机名修改为www.docker.com； (3) 否则，则显示当前主机名； 123456789101112131415[root@centos script]# cat week9_title2.sh #!/bin/bash#Author Jerry#hostname=$(hostname)if [ $hostname == \"localhost\" ];then hostname www.docker.com echo \"current hostname is:$hostname\"else echo \"current hostname is:$hostname\"fi[root@centos script]# 3、写一个脚本，完成如下功能 (1) 传递一个磁盘设备文件路径给脚本，判断此设备是否存在； (2) 如果存在，则显示此设备上的所有分区信息； 1234567891011[root@centos script]# cat week9_title3.sh #!/bin/bash#Author Jerry#[ $# -lt 1 ] &amp;&amp; echo \"please atleast input on\"if [ -b $1 ];then fdisk -l $1else echo \"nothing\"fi ​ 4、写一个脚本，完成如下功能, 脚本能够接受一个参数； (1) 如果参数1为quit，则显示退出脚本，并执行正常退出； (2) 如果参数1为yes，则显示继续执行脚本； (3) 否则，参数1为其它任意值，均执行非正常退出； 1234567891011121314151617181920212223242526272829303132333435[root@centos script]# bash week9_title4.sh please input one atleasterror!!!!![root@centos script]# bash week9_title4.sh quitexit....[root@centos script]# bash week9_title4.sh yesgo!go! go! [root@centos script]# echo $?0[root@centos script]# [root@centos script]# cat week9_title4.sh #!/bin/bash#Author Jerry#[ $# -eq 0 ] &amp;&amp; echo \"please input one atleast\"case $1 inyes) echo \"go!go! go! \";; quit) echo \"exit....\" exit 0;;*) echo \"error!!!!!\" exit 2;;esac[root@centos script]# 5、写一个脚本，完成如下功能 传递一个参数给脚本，此参数为gzip、bzip2或者xz三者之一； (1) 如果参数1的值为gzip，则使用tar和gzip归档压缩/etc目录至/backups目录中，并命名为/backups/etc-20160613.tar.gz； (2) 如果参数1的值为bzip2，则使用tar和bzip2归档压缩/etc目录至/backups目录中，并命名为/backups/etc-20160613.tar.bz2； (3) 如果参数1的值为xz，则使用tar和xz归档压缩/etc目录至/backups目录中，并命名为/backups/etc-20160613.tar.xz； (4) 其它任意值，则显示错误压缩工具，并执行非正常退出； ​ 12345678910111213141516171819202122232425[root@www /]# cat /script/week9_title5.sh #!/bin/bash if [ $# -eq 0 ];then echo \"give me a argument,the argument is gzip bzip2 xz \" exit 19 fi mkdir /backups &amp;&gt; /dev/null case $1 in gzip) tar -zcvf /backups/etc-`date +%Y%m%d`.tar.gz /etc ;; bzip2) tar -jvf /backups/etc-`date +%Y%m%d`.tar.bz2 /etc ;; xz) tar -Jvf /backups/etc-`date +%Y%m%d`.tar.xz /etc ;; *) echo \"error!!!\" ;; esac[root@www /]# 6、写一个脚本，接受一个路径参数： (1) 如果为普通文件，则说明其可被正常访问； (2) 如果是目录文件，则说明可对其使用cd命令； (3) 如果为符号链接文件，则说明是个访问路径； (4) 其它为无法判断； 1234567891011121314151617181920212223242526[root@www script]# cat week9_title6.sh #!/bin/bash#Author Jerry##Check whether the user is to script a path parameter[ $# -lt 1 ] &amp;&amp; echo \"Please give a path to the script parameters\"if [ -f $1 ]; then echo \"这是一个普通文件，可以被正常访问\"elif [ -d $1 ];then echo \"这是一个目录文件，可以使用cd命令\"elif [ -h $1 ];then echo \"这是一个符号链接文件，它是一个访问路径\"elif [ ! -h $1 ] &amp;&amp; [ ! -d $1 ] &amp;&amp; [ ! -f $1 ];then echo \"这是什么鬼，不想跟你说话并向你扔了一只狗！！！\" exitfi 7、写一个脚本，取得当前主机的主机名，判断 (1) 如果主机名为空或为localhost，或为””(none)””，则将其命名为mail.magedu.com； (2) 否则，显示现有的主机名即可； 1234567#!/bin/bashhostname=$(hostname)if [ -z \"$hostname\" -o \"$hostname\" == \"localhost\" -o \"$hostname\" == \"none\" ];then hostname mail.magedu.comelse echo \"$hostname\"fi 8、写一脚本，接受一个用户名为参数； (1) 如果用户的id号为0,则显示其为管理员； (2) 如果用户的id号大于0且小于500, 则显示其为系统用户； (3) 否则，则显示其为普通用户； 12345678910111213#!/bin/bashif [ $# -eq 0 ];then echo \"input argu\" exit 1fi userid=$(id -u)if [ $userid -eq 0 ];then echo \"admin\"elif [ $userid -gt 0 -a $userid -lt 500 ];then echo \"system\"else echo \"user\"fi 10、写一个脚本，传递一个用户名参数给脚本； (1) 如果用户的id号大于等于500，且其默认shell为以sh结尾的字符串，则显示“a user can log system.”类的字符串； (2) 否则，则显示无法登录系统； 1234567891011#!/bin/bashif [ $# -eq 0 ];then echo \"input argu\" exit 1fi userid=grep ^$1 /etc/passwd | grep sh$ | cut -d: -f3if [ $userid -ge 500 ];then echo \" a user can log system\"else echo \"nologin\"fi 11、写一个脚本，完成如下任务 ： (1) 按顺序分别复制/var/log目录下的每个直接文件或子目录至/tmp/test1-testn目录中； (2) 复制目录时，才使用cp -r命令； (3) 复制文件时使用cp命令； (4) 复制链接文件时使用cp -d命令； (5) 余下的所有类型，使用cp -a命令；” 123456789101112#!/bin/bashfor i in 'ls /var/log';do if [ -d $i ];then cp -r /var/log/$i /tmp/test/test1-testn/$i elif [ -f $i ];then cp /var/log/$i /tmp/test/test1-testn/$i elif [ -L $i ];then cp -d /var/log/$i /tmp/test/test1-testn/$i else cp -a /var/log/$i /tpm/test/test1-testn/$i fidone","categories":[],"tags":[]},{"title":"OSI七层模型及脚本小工具","slug":"脚本小工具","date":"2018-08-02T09:33:00.000Z","updated":"2018-08-05T03:36:27.323Z","comments":true,"path":"2018/08/02/脚本小工具/","link":"","permalink":"https://zhusas.github.io/2018/08/02/脚本小工具/","excerpt":"网桥、集线器、二层交换机、三层交换机、路由器的功能、使用场景与区别。集线器是属于物理层的设备，可以理解为一根网线中间串接出了多个接口，这么多接口共享这一根网线的带宽，因此这些接口上的设备在使得网络时就会出现冲突，或者‘道路’挤占的情况。（所有的设备在一个广播域，冲突域中），集线器现在很少使用了。 交换机、网桥都是数据链路层的设备，网桥的出现就是为了解决集线器多个接口共处于一个冲突域的问题，网桥具有2个接口，且每个接口设备发送接收数据都是独立的互不影响（每个接口是一个冲突域）。现在这种设备不再使用。交换机可以理解为是一个多接口的网桥，当然具备了网桥分割冲突的功能（每个接口是一个冲突域）。但是交换机（2层交换机）所有接口都在一个广播域中。 路由器属于网络层设备，路由器不但可以隔离冲突域，同时也可以隔离广播。每个接口是一个冲突域，一个广播域。路由器对于广播数据包不做转发。路由器根据3层地址（现用的IP地址）进行转发数据包到相应的接口。实现不同的IP网段互相通讯。 二层交换机属数据链路层设备，可以识别数据包中的MAC地址信息，根据MAC地址进行转发，并将这些MAC地址与对应的端口记录在自己内部的一个地址表中。","text":"网桥、集线器、二层交换机、三层交换机、路由器的功能、使用场景与区别。集线器是属于物理层的设备，可以理解为一根网线中间串接出了多个接口，这么多接口共享这一根网线的带宽，因此这些接口上的设备在使得网络时就会出现冲突，或者‘道路’挤占的情况。（所有的设备在一个广播域，冲突域中），集线器现在很少使用了。 交换机、网桥都是数据链路层的设备，网桥的出现就是为了解决集线器多个接口共处于一个冲突域的问题，网桥具有2个接口，且每个接口设备发送接收数据都是独立的互不影响（每个接口是一个冲突域）。现在这种设备不再使用。交换机可以理解为是一个多接口的网桥，当然具备了网桥分割冲突的功能（每个接口是一个冲突域）。但是交换机（2层交换机）所有接口都在一个广播域中。 路由器属于网络层设备，路由器不但可以隔离冲突域，同时也可以隔离广播。每个接口是一个冲突域，一个广播域。路由器对于广播数据包不做转发。路由器根据3层地址（现用的IP地址）进行转发数据包到相应的接口。实现不同的IP网段互相通讯。 二层交换机属数据链路层设备，可以识别数据包中的MAC地址信息，根据MAC地址进行转发，并将这些MAC地址与对应的端口记录在自己内部的一个地址表中。 三层交换机就是具有部分路由器功能的交换机，三层交换机的最重要目的是加快大型局域网内部的数据交换，所具有的路由功能也是为这目的服务的，能够做到一次路由，多次转发。对于数据包转发等规律性的过程由硬件高速实现，而像路由信息更新、路由表维护、路由计算、路由确定等功能，由软件实现。三层交换技术就是二层交换技术+三层转发技术。传统交换技术是在OSI网络标准模型第二层–数据链路层进行操作的，而三层交换技术是在网络模型中的第三层实现了数据包的高速转发，既可实现网络路由功能，又可根据不同网络状况做到最优网络性能。 IP地址的分类及子网掩码的表示形式及其作用IP地址分类 一般分类是指ipv4,IP地址有5类，A类到E类，各用在不同类型的网络中。地址分类反映了网络的大小以及数据包是单播还是组播的。 A类到C类地址用于单点编址方法，但每一类代表着不同的网络大小。A类地址（1.0.0.0-126.255.255.255）用于最大型的网络，该网络的节点数可达16,777,216个。 B类地址（128.0.0.0-191.255.255.25 5）用于中型网络，节点数可达65,536个。 C类地址（192.0.0.0-223.255.255.255）用于256个节点以下的小型网络的单点网络通信。 D类地址并不反映网络的大小，只是用于组播，用来指定所分配的接收组播的节点组，这个节点组由组播订阅成员组成。D类地址的范围为224.0.0.0-239.255.255.255。 E类（240.0.0.0-255.255.255.254）地址用于试验。 作用 子网掩码是一个32位地址，是与IP地址结合使用的一种技术。 它的主要作用有两个，一是用于屏蔽IP地址的一部分以区别网络标识和主机标识，并说明该IP地址是在局域网上，还是在远程网上。二是用于将一个大的IP网络划分为若干小的子网络。 使用子网是为了减少IP的浪费。因为随着互联网的发展，越来越多的网络产生，有的网络多则几百台，有的只有区区几台，这样就浪费了很多IP地址，所以要划分子网。使用子网可以提高网络应用的效率。 通过IP 地址的二进制与子网掩码的二进制进行与运算，确定某个设备的网络地址和主机号，也就是说通过子网掩码分辨一个网络的网络部分和主机部分。 子网掩码一旦设置，网络地址和主机地址就固定了。子网一个最显著的特征就是具有子网掩码。与IP地址相同，子网掩码的长度也是32位，也可以使用十进制的形式。例如，为二进制形式的子网掩码：1111 1111.1111 1111.1111 1111.0000 0000，采用十进制的形式为：255.255.255.0。 通过计算机的子网掩码判断两台计算机是否属于同一网段的方法是，将计算机十进制的IP地址和子网掩码转换为二进制的形式，然后进行二进制“与”(AND)计算（全1则得1，不全1则得0），如果得出的结果是相同的，那么这两台计算机就属于同一网段。 子网掩码表现形式 IP标识法一个完整IP描述包含IP 地址和子网掩码 具体标识有两种 点分十进制192.168.0.n 255.255.255.0（点分十进制） 这种暂时成为简写吧，懒人写法192.168.0.n/24 （/24表示子网掩码二进制标识法中前面24位1） 计算机网络的分层模型（OSI模型和TCP/IP模型）及每一层的功能及涉及到的物理设备有哪些。OSI模型 常见对应各层的设备 物理层：网卡，网线，集线器，中继器，调制解调器 数据链路层：网桥，交换机 网络层：路由器 网关工作在第四层传输层及其以上 物理层在OSI参考模型中，物理层（Physical Layer）是参考模型的最低层，也是OSI模型的第一层。 物理层的主要功能是：利用传输介质为数据链路层提供物理连接，实现比特流的透明传输。物理层的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。 数据链路层数据链路层（Data Link Layer）是OSI模型的第二层，负责建立和管理节点间的链路。该层的主要功能是：通过各种控制协议，将有差错的物理信道变为无差错的、能可靠传输数据帧的数据链路。在计算机网络中由于各种干扰的存在，物理链路是不可靠的。因此，这一层的主要功能是在物理层提供的比特流的基础上，通过差错控制、流量控制方法，使有差错的物理线路变为无差错的数据链路，即提供可靠的通过物理介质传输数据的方法。 该层通常又被分为介质访问控制（MAC）和逻辑链路控制（LLC）两个子层。 1、MAC子层的主要任务是解决共享型网络中多用户对信道竞争的问题，完成网络介质的访问控制； 2、LC子层的主要任务是建立和维护网络连接，执行差错校验、流量控制和链路控制。 数据链路层的具体工作是接收来自物理层的位流形式的数据，并封装成帧，传送到上一层；同样，也将来自上层的数据帧，拆装为位流形式的数据转发到物理层；并且，还负责处理接收端发回的确认帧的信息，以便提供可靠的数据传输。 网络层网络层（Network Layer）是OSI模型的第三层，它是OSI参考模型中最复杂的一层，也是通信子网的最高一层。它在下两层的基础上向资源子网提供服务。其主要任务是：通过路由选择算法，为报文或分组通过通信子网选择最适当的路径。该层控制数据链路层与传输层之间的信息转发，建立、维持和终止网络的连接。具体地说，数据链路层的数据在这一层被转换为数据包，然后通过路径选择、分段组合、顺序、进/出路由等控制，将信息从一个网络设备传送到另一个网络设备。一般地，数据链路层是解决同一网络内节点之间的通信，而网络层主要解决不同子网间的通信。例如在广域网之间通信时，必然会遇到路由（即两节点间可能有多条路径）选择问题。 在实现网络层功能时，需要解决的主要问题如下：寻址：数据链路层中使用的物理地址（如MAC地址）仅解决网络内部的寻址问题。在不同子网之间通信时，为了识别和找到网络中的设备，每一子网中的设备都会被分配一个唯一的地址。由于各子网使用的物理技术可能不同，因此这个地址应当是逻辑地址（如IP地址）。 交换：规定不同的信息交换方式。常见的交换技术有：线路交换技术和存储转发技术，后者又包括报文交换技术和分组交换技术。 路由算法：当源节点和目的节点之间存在多条路径时，本层可以根据路由算法，通过网络为数据分组选择最佳路径，并将信息从最合适的路径由发送端传送到接收端。 连接服务：与数据链路层流量控制不同的是，前者控制的是网络相邻节点间的流量，后者控制的是从源节点到目的节点间的流量。其目的在于防止阻塞，并进行差错检测。 传输层OSI下3层的主要任务是数据通信，上3层的任务是数据处理。而传输层（Transport Layer）是OSI模型的第4层。因此该层是通信子网和资源子网的接口和桥梁，起到承上启下的作用。 该层的主要任务是：向用户提供可靠的端到端的差错和流量控制，保证报文的正确传输。传输层的作用是向高层屏蔽下层数据通信的细节，即向用户透明地传送报文。该层常见的协议：TCP/IP中的TCP协议、Novell网络中的SPX协议和微软的NetBIOS/NetBEUI协议。 传输层提供会话层和网络层之间的传输服务，这种服务从会话层获得数据，并在必要时，对数据进行分割。然后，传输层将数据传递到网络层，并确保数据能正确无误地传送到网络层。因此，传输层负责提供两节点之间数据的可靠传送，当两节点的联系确定之后，传输层则负责监督工作。 综上，传输层的主要功能如下：传输连接管理：提供建立、维护和拆除传输连接的功能。传输层在网络层的基础上为高层提供“面向连接”和“面向无接连”的两种服务。 处理传输差错：提供可靠的“面向连接”和不太可靠的“面向无连接”的数据传输服务、差错控制和流量控制。在提供“面向连接”服务时，通过这一层传输的数据将由目标设备确认，如果在指定的时间内未收到确认信息，数据将被重发，监控服务质量。 会话层会话层（Session Layer）是OSI模型的第5层，是用户应用程序和网络之间的接口，主要任务是：向两个实体的表示层提供建立和使用连接的方法。将不同实体之间的表示层的连接称为会话。因此会话层的任务就是组织和协调两个会话进程之间的通信，并对数据交换进行管理。用户可以按照半双工、单工和全双工的方式建立会话。当建立会话时，用户必须提供他们想要连接的远程地址。而这些地址与MAC（介质访问控制子层）地址或网络层的逻辑地址不同，它们是为用户专门设计的，更便于用户记忆。域名（DN）就是一种网络上使用的远程地址例如：www.163.com就是一个域名。 会话层的具体功能如下： 会话管理：允许用户在两个实体设备之间建立、维持和终止会话，并支持它们之间的数据交换。例如提供单方向会话或双向同时会话，并管理会话中的发送顺序，以及会话所占用时间的长短。 会话流量控制：提供会话流量控制和交叉会话功能。 寻址：使用远程地址建立会话连接。 出错控制：从逻辑上讲会话层主要负责数据交换的建立、保持和终止，但实际的工作却是接收来自传输层的数据，并负责纠正错误。会话控制和远程过程调用均属于这一层的功能。但应注意，此层检查的错误不是通信介质的错误，而是磁盘空间、打印机缺纸等类型的高级错误。 表示层表示层（Presentation Layer）是OSI模型的第六层，它对来自应用层的命令和数据进行解释，对各种语法赋予相应的含义，并按照一定的格式传送给会话层。其主要功能是“处理用户信息的表示问题，如编码、数据格式转换和加密解密”等。 表示层的具体功能如下： 数据格式处理：协商和建立数据交换的格式，解决各应用程序之间在数据格式表示上的差异。 数据的编码：处理字符集和数字的转换。例如由于用户程序中的数据类型（整型或实型、有符号或无符号等）、用户标识等都可以有不同的表示方式，因此，在设备之间需要具有在不同字符集或格式之间转换的功能。 压缩和解压缩：为了减少数据的传输量，这一层还负责数据的压缩与恢复。 数据的加密和解密：可以提高网络的安全性。 应用层应用层（Application Layer）是OSI参考模型的最高层，它是计算机用户，以及各种应用程序和网络之间的接口，其功能是直接向用户提供服务，完成用户希望在网络上完成的各种工作。它在其他6层工作的基础上，负责完成网络中应用程序与网络操作系统之间的联系，建立与结束使用者之间的联系，并完成网络用户提出的各种网络服务及应用所需的监督、管理和服务等各种协议。此外，该层还负责协调各个应用程序间的工作。应用层为用户提供的服务和协议有：文件服务、目录服务、文件传输服务（FTP）、远程登录服务（Telnet）、电子邮件服务（E-mail）、打印服务、安全服务、网络管理服务、数据库服务等。上述的各种网络服务由该层的不同应用协议和程序完成，不同的网络操作系统之间在功能、界面、实现技术、对硬件的支持、安全可靠性以及具有的各种应用程序接口等各个方面的差异是很大的。 应用层的主要功能如下： 用户接口：应用层是用户与网络，以及应用程序与网络间的直接接口，使得用户能够与网络进行交互式联系。实现各种服务：该层具有的各种应用程序可以完成和实现用户请求的各种服务。 OSI 7层模型的小结由于OSI是一个理想的模型，因此一般网络系统只涉及其中的几层，很少有系统能够具有所有的7层，并完全遵循它的规定。在7层模型中，每一层都提供一个特殊的网络功能。从网络功能的角度观察：下面4层（物理层、数据链路层、网络层和传输层）主要提供数据传输和交换功能，即以节点到节点之间的通信为主；第4层作为上下两部分的桥梁，是整个网络体系结构中最关键的部分；而上3层（会话层、表示层和应用层）则以提供用户与应用程序之间的信息和数据处理功能为主。简言之，下4层主要完成通信子网的功能，上3层主要完成资源子网的功能。 TCP/IP模型 TCP/IP模型包括4层： 网络接口层–对应OSI参考模型的物理层和数据链路层； 网络层–对应OSI参考模型的网络层； 运输层–对应OSI参考模型的运输层； 应用层–对应OSI参考模型的5、6、7层。 TCP/IP协议的主要特点如下： 高可靠性 TCP/IP采用重新确认的方法保证数据的可靠传输，并采用“窗口”流量控制机制使可靠性得到进一步保证。 安全性 为建立TCP连接，在连接的每一端都必须与该连接的安全性控制达成一致。IP在它的控制分组头中有若干字段允许有选择地对传输的信息实施保护。 灵活性 TCP/IP要求下层支持该协议，而对上层应用协议不作特殊要求。因此，TCP/IP的使用不受传输介质和网络应用软件的限制。 总结 从网络通信的观点来看，Internet是一个由TCP/IP把各个国家、机构、部门的内部网络连接起来的庞大的数据通信网； 从信息资源的角度来看，Internet是一个集各个领域、部门内各种信息资源，以共享为目的的信息资源网；从技术的角度来看，Internet是一个“不同网络互连的网络（网际网）”,是由许多网络（包括局域网、城域网和广域网）互连形成的。 下面来看看网络的相关操作和脚本将Linux主机接入到TCP/IP网络的步骤。（手动指定的方式）我就不瞎BB了，直接上操作步骤，分centos和ubuntu两种操作系统，这是一道送分题。 总体来说有以下几步： 1、配置IP地址和掩码 2、配置网关 3、配置dns的IP地址 CentOS6 1234567891011121314151617vim /etc/sysconfig/network-scripts/ifcfg-eth0TYPE=Ethernet #90%以上都是以太网啦BOOTPROTO=none #如果是自动获取，此处是DHCP，手动指定就是noneIPADDR=192.168.0.243 #修改此处PREFIX=24 #修改此处GATEWAY=192.168.0.1 #修改此处DNS1=202.103.44.150 #修改此处DNS2=202.103.24.68 #修改此处DEFROUTE=yesIPV4_FAILURE_FATAL=yesIPV6INIT=noNAME=eth0UUID=b33d04cb-b415-4874-b5a2-e201bb20b46e #网卡的唯一标识ONBOOT=yes #是否开机启动最后：wq 保存退出， 再执行 service network restart #使其生效 Ubuntu 14.04 123456789101112131415161718192021222324root@ubuntu:~# vim /etc/network/interfaces #配置IP、掩码、网关# This file describes the network interfaces available on your system# and how to activate them. For more information, see interfaces(5).# The loopback network interfaceauto loiface lo inet loopback# The primary network interfaceauto eth0iface eth0 inet staticaddress 192.168.0.245netmask 255.255.255.0gateway 192.168.0.1root@ubuntu:~# vim /etc/resolvconf/resolv.conf.d/base #配置DNSnameserver 202.103.24.68nameserver 202.103.44.150最后：wq 保存退出root@ubuntu:~# service networking restart #使其生效 ​ 为Linux主机配置网络信息的方式方法一：使用ifconfig或者ip 临时添加网络信息，并使用route命令添加默认网关 123456789101112131415161718192021**注意：所有操作均使用root用户**修改IP：ifconfig eth0 192.168.0.66则直接将第一张网卡的IP修改成192.168.0.66增加IP：ifconfig eth0 add 192.168.2.77 #增加一个IPifconfig eth0:0 broadcast 192.168.2.255 ##修改刚刚增加IP的广播地址再增加一个IP：ifconfig eth0:0 add 10.10.44.145ifconfig eth0:0:1 broadcast 10.10.44.255 #修改刚刚增加IP的广播地址上述增加完，立刻生效，但是机器重新启动后，就无效了。route add -net 192.168.0.0/24 gw 192.168.0.1 dev eth1 #增加网关[root@centos ~]# vim /etc/resolv.conf #增加dns[root@centos ~]# cat /etc/resolv.conf #Generated by NetworkManagernameserver 202.103.44.150nameserver 202.103.24.68 ​ 不过这种方法是临时的，服务器一重启就失效了 ​ 方法二：使用修改/etc/sysconfig/network-scripts/ifcfg-IF_NAME文件 1234567891011121314151617181920212223242526272829303132333435363738[root@centos ~]# vim /etc/sysconfig/network-scripts/ifcfg-eth0ifcfg-IFACE 配置文件参数：DEVICE：此配置文件对应的设备的名称；ONBOOT：在系统引导过程中，是否激活此接口；UUID：此设备的惟一标识；IPV6INIT：是否初始化 IPv6；BOOTPROTO：激活此接口时使用什么协议来配置接口属性，常用的有 dhcp、bootp、static、none；TYPE：接口类型，常见的有 Ethernet, Bridge；DNS1：第一 DNS 服务器指向；DNS2：备用 DNS 服务器指向；DOMAIN：DNS 搜索域；IPADDR： IP 地址；NETMASK：子网掩码；CentOS 7 支持使用 PREFIX 以长度方式指明子网掩码；GATEWAY：默认网关；USERCTL：是否允许普通用户控制此设备；PEERDNS：如果 BOOTPROTO 的值为“dhcp”，是否允许 dhcp server 分配的 dns 服务器指向覆盖本地手动指定的 DNS 服务器指向；默认为允许；HWADDR：设备的 MAC 地址； [root@centos ~]# cat /etc/resolv.conf #示例# Generated by NetworkManagernameserver 202.103.44.150nameserver 202.103.24.68[root@centos ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 TYPE=EthernetBOOTPROTO=noneIPADDR=192.168.0.243PREFIX=24GATEWAY=192.168.0.1DNS1=202.103.44.150DNS2=202.103.24.68DEFROUTE=yesIPV4_FAILURE_FATAL=yesIPV6INIT=noNAME=eth0UUID=b33d04cb-b415-4874-b5a2-e201bb20b46eONBOOT=yes 一般最常用的就是这两种了。 用ping命令探测172.16.250.1-172.16.250.254之间的所有主机的在线状态；在线的主机使用绿色显示；不在线的主使用红色显示一开始我很茫然，无从下手，用for循环，记得for循环大了会占用内存空间，例如ping B类局域网地址的话，就想着不用for，用while或者until实现可否，折腾了一天多的时间（处女座作的），精益求精，经过N次死循环及失败，于是有了下面的脚本: 123456789101112131415161718[root@centos Jerry_go]# wc -l ping4.sh 14 ping4.sh[root@centos Jerry_go]# cat ping4.sh #!/bin/sh#ping IP#Author Jerryip=0while [ $ip -lt 254 ];do ip=$[$ip+1] ping -c 2 192.168.0.$ip &gt;&gt; /dev/null if [ $? == 0 ];then echo -e \"\\e[1;32m 192.168.0.$ip ok \\e[0m\" &amp;&amp; continue else echo -e \"\\e[1;31m 192.168.0.$ip no response \\e[0m\" &amp;&amp; continue fidone[root@centos Jerry_go]# 执行效果： 用for实现 1234567891011121314[root@centos Jerry_go]# cat ping.sh #!/bin/bash#ping ip#Author Jerryfor ((i=1;i&lt;255;i++));do ping -w 1 -c 1 172.16.250.$i &amp;&gt;/dev/null if [ $? -eq 0 ];then echo -e \"\\e[1;32m 172.16.250.$i ok \\e[0m\" else echo -e \"\\e[1;31m 172.16.250.$i no response \\e[0m\" fidone[root@centos Jerry_go]# 经测试效果一样 描述每个网络接口的配置文件中各个参数的含义和其所对应的值123456789101112131415161718ifcfg-IFACE配置文件参数： DEVICE：此配置文件对应的设备的名称； ONBOOT：在系统引导过程中，是否激活此接口； UUID：此设备的惟一标识； IPV6INIT：是否初始化IPv6； BOOTPROTO：激活此接口时使用什么协议来配置接口属性，常用的有dhcp、bootp、static、none； TYPE：接口类型，常见的有Ethernet, Bridge； DNS1：第一DNS服务器指向； DNS2：备用DNS服务器指向； DOMAIN：DNS搜索域； IPADDR： IP地址； NETMASK：子网掩码；CentOS 7支持使用PREFIX以长度方式指明子网掩码； GATEWAY：默认网关； USERCTL：是否允许普通用户控制此设备； PEERDNS：如果BOOTPROTO的值为“dhcp”，是否允许dhcp server分配的dns服务器指向覆盖本地手动指定的DNS服务器指向；默认为允许； HWADDR：设备的MAC地址； NM_CONTROLLED：是否使用NetworkManager服务来控制接口； 给网络接口配置多个地址，有哪些方式？这个也分快捷跟永久两种方式。主要用到ifconfig 快捷方式呢，即生效，如下： 12345678910111213141516171819202122232425262728293031323334353637[root@centos ~]# ifconfig eth0:0 192.168.3.243 netmask 255.255.255.0 up [root@centos ~]# ifconfig eth0:1 192.168.3.2 netmask 255.255.255.0 up [root@centos ~]# ip addr show #查看网卡IP地址方法一1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:04:bd:c1 brd ff:ff:ff:ff:ff:ff inet 192.168.0.243/24 brd 192.168.0.255 scope global eth0 inet 192.168.3.243/24 brd 192.168.3.255 scope global eth0:0 inet 192.168.3.2/24 brd 192.168.3.255 scope global secondary eth0:1[root@centos ~]# ifconfig #查看网卡IP地址方法二eth0 Link encap:Ethernet HWaddr 00:0C:29:04:BD:C1 inet addr:192.168.0.243 Bcast:192.168.0.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:8122248 errors:0 dropped:0 overruns:0 frame:0 TX packets:51751 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:526472342 (502.0 MiB) TX bytes:3884350 (3.7 MiB)eth0:0 Link encap:Ethernet HWaddr 00:0C:29:04:BD:C1 inet addr:192.168.3.243 Bcast:192.168.3.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1eth0:1 Link encap:Ethernet HWaddr 00:0C:29:04:BD:C1 inet addr:192.168.3.2 Bcast:192.168.3.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:290 errors:0 dropped:0 overruns:0 frame:0 TX packets:290 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:26660 (26.0 KiB) TX bytes:26660 (26.0 KiB)[root@centos ~]# 永久方式呢，稍微麻烦点，不过永久嘛，一劳永逸，值得 是仿照/etc/sysconfig/network-scripts/ifcfg-eth0增加一文件根据网络虚拟接口的名字进行命名例如ifcfg-eth0:0或者ifcfg-eth0:1等等 开始飙车了啊，系好安全带！ [root@centos ~]# cd /etc/sysconfig/network-scripts/ [root@centos network-scripts]# cp ifcfg-eth0 ifcfg-eth0:0 [root@centos network-scripts]# vim ifcfg-eth0:0 保存退出，重启系统，再看。应该是没问题的啦。 常用的网络管理类工具及使用方法。ifconfig命令:接口及地址查看和管理 可以使用ifconfig命令配置网卡属性,设置后立即生效，重启后失效。 显示活动接口信息 ifconfig eth0 显示所有接口信息 ifconfig -a 启用或禁用给定接口 ifconfig eth0 up/down 设置IP地址及掩码 ifconfig eth0 172.168.1.100/24 route命令：路由查看及管理 添加主机路由 route add -host 192.168.1.3 gw 172.16.0.1 dev eth0 添加网络路由 route add -net 192.168.0.0/24 gw 172.16.0.1 dev eth0 添加默认路由 route add default gw 172.16.0.1 删除主机路由 route del -host 192.168.1.3 删除网络路由 route del -net 192.168.0.0 netmask 255.255.255.0 netstat命令:打印网络连接，路由表，接口统计信息 以数字形式显示TCP协议相关所有状态 netstat -tan 以数字形式显示UDP协议相关所有状态 netstat -uan 以数字形式显示TCP协议相关的监听状态 netstat -tnl 以数字形式显示UDP协议相关的监听状态 netstat -unl 显示内核路由表 netstat -r 显示所有接口统计数据 netstat -i 显示指定接口信息 netstat -I eth0 dig命令:解析DNS地址工具 正解DNS 域名至IP地址 dig -t A www.magedu.com 反解DNS IP地址至域名 dig -x 127.0.0.1 ip命令:显示/操纵路由，设备，策略路由和隧道 禁用接口 ip link set dev eth0 down 启用接口 ip link set dev eth0 up 显示接口信息 ip link show dev eth0 显示主地址 ip addr show dev eth0 primary 显示次地址 ip addr show dev eth0 secondary 添加IP地址 ip addr add 172.16.100.13/16 dev eth0 添加网卡别名 ip addr add 172.16.100.13/16 dev eth0 label ‘eth:0’ 删除别名 ip addr flush dev eth0 label ‘eth0:0’ 添加主路由 ip route add 192.168.1.3 via 172.16.0.1 dev eth0 添加网络路由 ip route add 192.168.0.0/16 via 172.16.0.1 dev eth0 添加默认路由 ip route add default via 127.16.0.1 删除路由 ip route del 192.168.1.3 查看路由 ip route show 清空路由 ip route flush dev eth0 ss命令:显示网络连接工具参数用法同netstat 指定显示某种状态ss -t state established ‘( dport = :ssh or sport = :ssh )’ Linux系统软件包管理方法（安装、升级、卸载等操作）Linux的软件系统包管理那就好玩了，根据这多年的使用经验，主要分为yum和apt两大系列， Debian 及其衍生产品如：Ubuntu、Linux Mint 和 Raspbian 的包格式为.deb文件，APT 是最常见包操作命令，可：搜索库、安装包及其依赖和管理升级,而要直接安装现成.deb包时需要使用dpkg命令。 APT还自吹有超级牛力，有图有真相: CentOS、Fedora 及 Red Hat 系列 Linux 使用RPM包文件，并使用yum命令管理包文件及与软件库交互。在最新的 Fedora 版本中，yum命令已被dnf取代进行包管理,而要直接安装现成.rpm包时需要使用rpm命令。 好嘛，都是利器啊。下边且看我分解。 RPM 包的安装 / 升级 / 查询 / 卸载一个 RPM 包包含了已压缩的软件文件集以及该软件的内容信息（在头文件中保存），通常表现为以 .rpm 扩展名结尾的文件，例如 package.rpm 。对其操作，需要使用 rpm 命令。下面介绍 rpm 工具的参数和使用方法。 RPM 命令常用参数 RPM 的常规使用方法为 rpm -参数 package.rpm ( 更多信息，请查阅帮助 $man rpm)： -q 在系统中查询软件或查询指定 rpm 包的内容信息 -i 在系统中安装软件 -U 在系统中升级软件 -e 在系统中卸载软件 -h 用 #(hash) 符显示 rpm 安装过程 -v 详述安装过程 -p 表明对 RPM 包进行查询，通常和其它参数同时使用，如：-qlp 查询某个 RPM 包中的所有文件列表-qip 查询某个 RPM 包的内容信息 RPM 命令参数使用方法以上参数有些需要组合使用，比如说 rpm -h package.rpm 是没有意义的，但 rpm -ih package.rpm 即表示安装 package 并用 # 符显示安装进度。 安装 RPM 包 rpm -ivh package.rpm 升级 RPM 包命令 rpm -Uvh package.rpm 卸载 RPM 包命令 rpm -ev package 查询 RPM 包中包含的文件列表命令 rpm -qlp package 查询 RPM 包中包含的文件列表命令 rpm -qlp package 查询 RPM 包中包含的内容信息命令 rpm -qip package 查询系统中所有已安装 RPM 包 rpm -qa DEB 包的安装 / 升级 / 查询 / 卸载一个 DEB 包包含了已压缩的软件文件集以及该软件的内容信息（在头文件中保存），通常表现为以 .deb 扩展名结尾的文件，例如 package.deb 。对其操作，需要使用 dpkg 命令。下面介绍 dpkg 工具的参数和使用方法，并以 IBM Lotus Notes 在 UBUNTU 904 安装为例做具体说明。 DPKG 命令常用参数 DPKG 的常规使用方法为 dpkg -参数 Package(.rpm),( 更多信息，请查阅帮助 $man rpm) -l 在系统中查询软件内容信息 –info 在系统中查询软件或查询指定 rpm 包的内容信息 -i 在系统中安装 / 升级软件 -r 在系统中卸载软件 , 不删除配置文件 -P 在系统中卸载软件以及其配置文件 DPKG 命令参数使用方法 安装 DEB 包命令 dpkg -i package.deb 升级 DEB 包命令 dpkg -i package.deb ( 和安装命令相同） 卸载 DEB 包命令 dpkg -r package.deb # 不卸载配置文件或 dpkg -P package.deb # 卸载配置文件 查询 DEB 包中包含的文件列表命令 dpkg-deb -c package.deb 查询 DEB 包中包含的内容信息命令 dpkg –info package.deb 查询系统中所有已安装 DEB 包 dpkg -l package YUM/APT大多数 Linux 都使用本地数据库来存储远程可用的包仓库列表，所以在安装或升级包之前最好更新一下这个数据库。 Debian/Ubuntu sudo apt-get update CentOS yum check-update Fedora dnf check-update 升级已安装的包 Debian/Ubuntu sudo apt-get upgrade #仅升级已安装的软件包 sudo apt-get dist-upgrade #可添加或删除程序包，以满足新的依赖。 CentOS sudo yum update Fedora sudo dnf upgrade 查找/搜索软件包 Debian/Ubuntuapt-cache search #搜索内容 CentOSyum search #搜索内容yum search all #搜索内容 搜索所有内容，包括包描述。 Fedoradnf search #搜索内容dnf search all #搜索内容 搜索所有内容，包括包描述。 查看某个软件包信息 Debian/Ubuntu apt-cache show 包名 #显示有关软件包的本地缓存信息 dpkg -s 包名 #显示包的当前安装状态 CentOS yum info 包名 yum deplist 包名 #列出包的以来 Fedoradnf info 包名dnf repoquery –requires 包名 #列出包的以来 从软件仓库安装包 一旦我们知道某个软件包的名称之后，便可以使用如下命令从软件仓库安装包。 Debian/Ubuntu sudo apt-get install 包名sudo apt-get install 包1 包2 … #安装所有列出的包sudo apt-get install -y 包名 #无需提示直接安装 CentOSsudo yum install 包名sudo yum install 包1 包2 … #安装所有列出的包sudo yum install -y 包名 #无需提示直接安装 Fedorasudo dnf install 包名sudo dnf install 包1 包2 … #安装所有列出的包sudo dnf install -y 包名 #无需提示直接安装 使用发行版光盘作为yum repository1、将主机base源及media源备份并将media源切换至iso mount目录 1234[root@centos /]# cd /etc/yum.repos.d[root@centos yum.repos.d]# mv CentOS-Base.repo CentOS-Base.repo.bak[root@centos yum.repos.d]# cp CentOS-Media.repo CentOS-Media.repo.bak[root@centos yum.repos.d]# vim CentOS-Media.repo 2、将iso光盘插入光驱或将iso包挂载到机器中（本次测试直接将iso挂载到虚拟机centos中） 123[root@centos /]# mkdir /media/CentOS #建立光盘挂载目录 ，其实就是跟CentOS-Media.repo里面默认的一样啦[root@centos dev]# mount /dev/sr0 /media/CentOS/ #挂载光盘 3、测试安装policycoreutils-python 先清空yum的缓存，再重建yum缓存，看看从光盘的yum repository能否正常读取。 貌似是OK的。 再来一发 大功告成！ 完成以下功能 (1) 假设某目录(/etc/rc.d/rc3.d/)下分别有K开头的文件和S开头的文件若干； (2) 显示所有以K开头的文件的文件名，并且给其附加一个stop字符串； (3) 显示所有以S开头的文件的文件名，并且给其附加一个start字符串； (4) 分别统计S开头和K开头的文件各有多少； 123456789101112131415161718192021#!/bin/bash##定义统计文件个数的变量，初始化啦filename_S_sum=0filename_K_sum=0#利用for循环列表支持文件路径*通配S开头的文件for filename_S in /etc/rc.d/rc3.d/S*;do echo $(basename $filename_S) start let filename_S_sum++done#利用for循环列表支持文件路径*通配S开头的文件for filename_K in /etc/rc.d/rc3.d/K*;do echo $(basename $filename_K) stop let filename_K_sum++doneecho \"There is $filename_S_sum files by S At the beginning of the file name\"echo \"There is $filename_K_sum files by K At the beginning of the file name\" ​ 1234567891011121314151617181920212223242526272829303132333435363738394041[root@centos Jerry_go]# bash week8_title12-2.sh &gt; week8_title12-2.txt &amp;&amp; cat week8_title12-2.txt S01sysstat startS02lvm2-monitor startS10network startS11portreserve startS12rsyslog startS22messagebus startS23NetworkManager startS25blk-availability startS26haldaemon startS26udev-post startS55memcached startS55sshd startS58ntpd startS90crond startS95atd startS99local startK01smartd stopK05wdaemon stopK10psacct stopK10saslauthd stopK16abrt-ccpp stopK16abrtd stopK30spice-vdagentd stopK50kdump stopK61nfs-rdma stopK75netfs stopK75ntpdate stopK75quota_nld stopK84wpa_supplicant stopK87restorecond stopK88auditd stopK89netconsole stopK89rdisc stopK92ip6tables stopK92iptables stopK95firstboot stopK95rdma stopK99rngd stopThere is 16 files by S At the beginning of the file nameThere is 22 files by K At the beginning of the file name 完成以下功能 (1) 脚本能接受用户名作为参数； (2) 计算此些用户的ID之和； 1234567891011121314151617[root@centos Jerry_go]# cat week8_title13.sh #开始装逼#!/bin/bash#[ $# -lt 1 ] &amp;&amp; echo “At least input one users name ” &amp;&amp; exit 1 #提前判断一下，最少输入一个脚本参数并提示用户userid_sum=0 #初始化userid_sum变量for user in $*;do #开始用for循环，$*参数表示读取脚本后的任意个参数作为循环列表 if id $user &amp;&gt; /dev/null;then #判断一下用户是否存在 echo \"$user userid is $(id -u $user)\" #显示每次循环的当前系统用户的ID let userid_sum+=$(id -u $user) #变量自增 else echo \"$user is not an existing user\" #如果用户不存在，输出提示给用户 fidoneecho \"They're userid sum is $userid_sum\" #输出用户ID的总和 ​ 12345678[root@centos Jerry_go]# bash week8_title13.sh root bin jerry sshd FBIroot userid is 0bin userid is 1jerry userid is 500sshd userid is 74FBI is not an existing userThey're userid sum is 575[root@centos Jerry_go]# (1) 传递一些目录给此脚本； (2) 逐个显示每个目录的所有一级文件或子目录的内容类型； (3) 统计一共有多少个目录；且一共显示了多少个文件的内容类型； 123456789101112131415161718192021222324[root@centos Jerry_go]# cat week8_title14.sh #!/bin/bash#Author Jerry##Not less than one script parameters[ $# -lt 1 ] &amp;&amp; echo \"please aleast input one directory\" &amp;&amp; exit 1#Judge whether the script parameters of the input from the user directory[ -d $* ] || echo \"Please enter the directory!!!\" dsum=0fsum=0for file_name in $1;do ls -l $* |awk '&#123;print $NF&#125;' let dsum+=$(ls -l $* |grep ^d |wc -l) let fsum+=$(ls -l $* |grep -v ^d |wc -l) shift break doneecho \"the directories sum:$dsum\"echo \"the file sum:$fsum\" ​ 写一个脚本 通过命令行传递一个参数给脚本，参数为用户名 如果用户的id号大于等于500，则显示此用户为普通用户； 123456789[root@centos jerry_go]# cat week8_title14.sh #!/bin/bash#Determine the user's inputgrep \"^$1\\&gt;\" /etc/passwd &amp;&gt; /dev/null || echo \"Please enter a user name\" userid=$(id -u $1)[ $userid -ge 500 ] &amp;&amp; echo \"This is a common user,it's userid is $userid \" || echo \"This is a system user,it's userid is $userid \" 写一个脚本 (1) 添加10用户user1-user10；密码同用户名； (2) 用户不存在时才添加；存在时则跳过； (3) 最后显示本次共添加了多少用户； 12345678910#!/bin/bashdeclare -i numfor((i=1;i&lt;11;i++))&#123; if ! id user$i &amp;&gt; /dev/null;then useradd user$i echo user$i:user$i | chpasswd let num++ fi&#125;echo \"Add $num users!\" 用ping命令测试172.16.250.20-172.16.250.100以内有哪些主机在线，将在线的显示出来； 12345678#!/bin/bashnet=\"172.16.250.\"for((i=20;i&lt;=100;i++))&#123; ping -c 1 $net$i &amp;&gt; /dev/null if [ $? -eq 0 ];then echo $net$i fi&#125; 打印九九乘法表； 12345678910111213141516171819[root@centos jerry_go]# bash week8_title18.sh 1*1=1 1*2=2 2*2=4 1*3=3 2*3=6 3*3=9 1*4=4 2*4=8 3*4=12 4*4=16 1*5=5 2*5=10 3*5=15 4*5=20 5*5=25 1*6=6 2*6=12 3*6=18 4*6=24 5*6=30 6*6=36 1*7=7 2*7=14 3*7=21 4*7=28 5*7=35 6*7=42 7*7=49 1*8=8 2*8=16 3*8=24 4*8=32 5*8=40 6*8=48 7*8=56 8*8=64 1*9=9 2*9=18 3*9=27 4*9=36 5*9=45 6*9=54 7*9=63 8*9=72 9*9=81 [root@centos jerry_go]# cat week8_title18.sh #!/bin/bashfor ((i=1;i&lt;=9;i++))&#123; for((j=1;j&lt;=i;j++));do echo -e -n \"$j*$i=$(($i*$j))\\t\" done echo &#125;","categories":[],"tags":[{"name":"shell","slug":"shell","permalink":"https://zhusas.github.io/tags/shell/"}]},{"title":"脚本又见脚本","slug":"脚本又见脚本","date":"2018-08-02T09:07:00.000Z","updated":"2018-08-02T09:09:16.508Z","comments":true,"path":"2018/08/02/脚本又见脚本/","link":"","permalink":"https://zhusas.github.io/2018/08/02/脚本又见脚本/","excerpt":"创建一个10G分区，并格式为ext4文件系统； (1) 要求其block大小为2048, 预留空间百分比为2, 卷标为MYDATA, 默认挂载属性包含acl； (2) 挂载至/data/mydata目录，要求挂载时禁止程序自动运行，且不更新文件的访问时间戳；","text":"创建一个10G分区，并格式为ext4文件系统； (1) 要求其block大小为2048, 预留空间百分比为2, 卷标为MYDATA, 默认挂载属性包含acl； (2) 挂载至/data/mydata目录，要求挂载时禁止程序自动运行，且不更新文件的访问时间戳； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100[root@centos ~]# fdisk -l #不写注释的都是耍流氓Disk /dev/sda: 171.8 GB, 171798691840 bytes255 heads, 63 sectors/track, 20886 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00098b32 Device Boot Start End Blocks Id System/dev/sda1 * 1 64 512000 83 LinuxPartition 1 does not end on cylinder boundary./dev/sda2 64 20887 167259136 8e Linux LVMDisk /dev/sdb: 10.7 GB, 10737418240 bytes #创建一个10G分区255 heads, 63 sectors/track, 1305 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000 Disk /dev/mapper/vg_centos-lv_root: 170.2 GB, 170196467712 bytes255 heads, 63 sectors/track, 20691 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/mapper/vg_centos-lv_swap: 1073 MB, 1073741824 bytes255 heads, 63 sectors/track, 130 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000[root@centos ~]# fdisk /dev/sdb Device contains neither a valid DOS partition table, nor Sun, SGI or OSF disklabelBuilding a new DOS disklabel with disk identifier 0x248136bc.Changes will remain in memory only, until you decide to write them.After that, of course, the previous content won't be recoverable.Warning: invalid flag 0x0000 of partition table 4 will be corrected by w(rite)WARNING: DOS-compatible mode is deprecated. It's strongly recommended to switch off the mode (command 'c') and change display units to sectors (command 'u').Command (m for help): nCommand action e extended p primary partition (1-4)pPartition number (1-4): 1First cylinder (1-1305, default 1): Using default value 1Last cylinder, +cylinders or +size&#123;K,M,G&#125; (1-1305, default 1305): Using default value 1305Command (m for help): wqThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks.[root@centos ~]# fdisk -lDisk /dev/sda: 171.8 GB, 171798691840 bytes255 heads, 63 sectors/track, 20886 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00098b32 Device Boot Start End Blocks Id System/dev/sda1 * 1 64 512000 83 LinuxPartition 1 does not end on cylinder boundary./dev/sda2 64 20887 167259136 8e Linux LVMDisk /dev/sdb: 10.7 GB, 10737418240 bytes255 heads, 63 sectors/track, 1305 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x248136bc Device Boot Start End Blocks Id System/dev/sdb1 1 1305 10482381 83 LinuxDisk /dev/mapper/vg_centos-lv_root: 170.2 GB, 170196467712 bytes255 heads, 63 sectors/track, 20691 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/mapper/vg_centos-lv_swap: 1073 MB, 1073741824 bytes255 heads, 63 sectors/track, 130 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000 12345678910111213141516171819202122232425262728293031323334353637383940414243444546[root@centos ~]# mkfs -b 2048 -t ext4 -L MYDATA -m 2 /dev/sdb1 #格式为ext4文件系统，其block大小为2048, 预留空间百分比为2, 卷标为MYDATAmke2fs 1.41.12 (17-May-2010)文件系统标签=MYDATA操作系统:Linux块大小=2048 (log=1)分块大小=2048 (log=1)Stride=0 blocks, Stripe width=0 blocks655360 inodes, 5241190 blocks262059 blocks (5.00%) reserved for the super user第一个数据块=0Maximum filesystem blocks=542113792320 block groups16384 blocks per group, 16384 fragments per group2048 inodes per groupSuperblock backups stored on blocks: 16384, 49152, 81920, 114688, 147456, 409600, 442368, 802816, 1327104, 2048000, 3981312正在写入inode表: 完成 Creating journal (32768 blocks): 完成Writing superblocks and filesystem accounting information: 完成This filesystem will be automatically checked every 20 mounts or180 days, whichever comes first. Use tune2fs -c or -i to override.[root@centos ~]# tune2fs -o acl /dev/sdb1 #默认挂载属性包含acltune2fs 1.41.12 (17-May-2010)[root@centos ~]# mkdir -p /data/mydata &amp;&amp; mount -o noexec,noatime /dev/sdb1 /data/mydata #挂载至/data/mydata目录，要求挂载时禁止程序自动运行，且不更新文件的访问时间戳[root@centos ~]# echo $? 0[root@centos ~]# cd /data/[root@centos data]# ll总用量 2drwxr-xr-x 3 root root 2048 12月 26 17:36 mydata[root@centos data]# cd mydata/[root@centos mydata]# ll总用量 16drwx------ 2 root root 16384 12月 26 17:36 lost+found[root@centos mydata]# df -hFilesystem Size Used Avail Use% Mounted on/dev/mapper/vg_centos-lv_root 156G 3.8G 145G 3% /tmpfs 1.9G 72K 1.9G 1% /dev/shm/dev/sda1 477M 160M 292M 36% /boot/dev/sdb1 9.8G 13M 9.3G 1% /data/mydata[root@centos mydata]# 2、创建一个大小为1G的swap分区，并创建好文件系统，并启用之； 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@centos ~]# fdisk /dev/sdb Device contains neither a valid DOS partition table, nor Sun, SGI or OSF disklabelBuilding a new DOS disklabel with disk identifier 0x70af3aab.Changes will remain in memory only, until you decide to write them.After that, of course, the previous content won't be recoverable.Warning: invalid flag 0x0000 of partition table 4 will be corrected by w(rite)WARNING: DOS-compatible mode is deprecated. It's strongly recommended to switch off the mode (command 'c') and change display units to sectors (command 'u').Command (m for help): nCommand action e extended p primary partition (1-4)Command action e extended p primary partition (1-4)pPartition number (1-4): 1First cylinder (1-130, default 1): Using default value 1Last cylinder, +cylinders or +size&#123;K,M,G&#125; (1-130, default 130): Using default value 130Command (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks. [root@centos ~]# mkswap /dev/sdb1Setting up swapspace version 1, size = 1044188 KiBno label, UUID=85de9eea-a86d-48f4-a24d-00615a9812f8[root@centos ~]# swapon /dev/sdb1 [root@centos ~]# free -m total used free shared buffers cachedMem: 3816 517 3299 1 27 289-/+ buffers/cache: 200 3615Swap: 1019 0 1019[root@centos ~]# echo \"/dev/sdb1 swap swap defaults 0 0\" &gt;&gt; /etc/fstab #swap现已加入开机挂载全家桶！ 3、获取并列出当前系统上的所有磁盘设备；显示每个磁盘设备上每个分区相关的空间使用信息； 12345678910111213141516171819202122232425262728293031323334353637[root@centos gogogogogogogogoo]# cat DiskInfo_Jerry.sh #马哥说过，脚本就是命令的拼凑，所以，命令学好，脚本风骚。#!/bin/bash#Author: Jerrylsblkdf -ahT[root@centos gogogogogogogogoo]# bash DiskInfo_Jerry.sh NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 160G 0 disk ├─sda1 8:1 0 500M 0 part /boot└─sda2 8:2 0 159.5G 0 part ├─vg_centos-lv_root (dm-0) 253:0 0 158.5G 0 lvm / └─vg_centos-lv_swap (dm-1) 253:1 0 1G 0 lvm sdb 8:16 0 10G 0 disk └─sdb1 8:17 0 10G 0 part ├─vg_mage-mylv1-real (dm-3) 253:3 0 5G 0 lvm │ ├─vg_mage-mylv1 (dm-2) 253:2 0 5G 0 lvm │ └─vg_mage-snvg1 (dm-5) 253:5 0 5G 1 lvm └─vg_mage-snvg1-cow (dm-4) 253:4 0 160M 1 lvm └─vg_mage-snvg1 (dm-5) 253:5 0 5G 1 lvm sdc 8:32 0 60G 0 disk └─sdc1 8:33 0 60G 0 part Filesystem Type Size Used Avail Use% Mounted on/dev/mapper/vg_centos-lv_root ext4 156G 3.4G 145G 3% /proc proc 0 0 0 - /procsysfs sysfs 0 0 0 - /sysdevpts devpts 0 0 0 - /dev/ptstmpfs tmpfs 1.9G 68K 1.9G 1% /dev/shm/dev/sda1 ext4 477M 35M 418M 8% /boot/dev/mapper/vg_mage-mylv1 ext4 4.8G 10M 4.6G 1% /usersnone binfmt_misc 0 0 0 - /proc/sys/fs/binfmt_miscvmware-vmblock fuse.vmware-vmblock 0 0 0 - /var/run/vmblock-fuse[root@centos gogogogogogogogoo]# 4、总结RAID的各个级别及其组合方式和性能的不同； 1234567891011121314151617181920212223242526RAID-0: 读、写性能提升； 可用空间：N*min(S1,S2,...) 无容错能力 最少磁盘数：2, 2+RAID-1： 读性能提升、写性能略有下降； 可用空间：1*min(S1,S2,...) 有冗余能力 最少磁盘数：2, 2+RAID-4： 1101, 0110, 1011RAID-5： 读、写性能提升 可用空间：(N-1)*min(S1,S2,...) 有容错能力：1块磁盘 最少磁盘数：3, 3+RAID-6： 读、写性能提升 可用空间：(N-2)*min(S1,S2,...) 有容错能力：2块磁盘 最少磁盘数：4, 4+ ​ 123456混合类型 RAID-10： 读、写性能提升 可用空间：N*min(S1,S2,...)/2 有容错能力：每组镜像最多只能坏一块； 最少磁盘数：4, 4+ 5、创建一个大小为10G的RAID1，要求有一个空闲盘，而且CHUNK大小为128k; 1生产环境都是用服务器自带的磁盘阵列卡来做raid，具体详见各厂商的操作文档，此题我就跳过了，请老湿原谅我的直接。 6、创建一个大小为4G的RAID5设备，chunk大小为256k，格式化ext4文件系统，要求可开机自动挂载至/backup目录，而且不更新访问时间戳，且支持acl功能； 12生产环境都是用服务器自带的磁盘阵列卡来做raid，具体详见各厂商的操作文档，此题我就跳过了，请老湿原谅我的直接。更新访问时间戳我要说一下，生产环境一般都是要更新访问时间戳的 7、接受一个以上文件路径作为参数；显示每个文件拥有的行数；总结说明本次共为几个文件统计了其行数； 1234567891011121314151617181920[root@centos gogogogogogogogoo]# bash Sum_wc-l.sh /etc/ssh/sshd_config /etc/fstab /etc/rc.local Number of rows in /etc/ssh/sshd_config is 138Number of rows in /etc/fstab is 16Number of rows in /etc/rc.local is 7total of 3 files[root@centos gogogogogogogogoo]# cat Sum_wc-l.sh #!/bin/bash#if [ $# -lt 1 ];then echo \"At least one filesname \" exit 2fi for i in $*;do line=$(cat $i | wc -l) echo \"Number of rows in $i is $line\" done echo \"total of $# files\"[root@centos gogogogogogogogoo]# 8、传递两个以上字符串当作用户名；创建这些用户；且密码同用户名；(总结说明共创建了几个用户； 123456789101112131415161718192021222324252627282930[root@centos gogogogogogogogoo]# bash Creat_user.sh At least two username [root@centos gogogogogogogogoo]# bash Creat_user.sh abb1 abb2 abb3 abb4Add user abb1 finishedAdd user abb2 finishedAdd user abb3 finishedAdd user abb4 finishedtotal of Create 4 users[root@centos gogogogogogogogoo]# cat Creat_user.sh #!/bin/bashif [ $# -lt 2 ];then echo \"At least two username \" exit 2fi for i in $*;do if grep \"^$i\\&gt;\" /etc/passwd &amp;&gt; /dev/null;then echo \"User $i exists\" else useradd $i echo $i | passwd --stdin $i &amp;&gt; /dev/null echo \"Add user $i finished\" fi done echo \"total of Create $# users\"[root@centos gogogogogogogogoo]# 9、新建20个用户，visitor1-visitor20；计算他们的ID之和； 12345678910111213141516171819[root@centos gogogogogogogogoo]# bash sum_userid.sh The users ID sum is: 10330[root@centos gogogogogogogogoo]# cat sum_userid.sh #!/bin/bashnum=0for i in &#123;1..20&#125;;do if id visitor$i &amp;&gt; /dev/null;then echo \"visitor$i exists\" else useradd visitor$i id=$(grep \"^visitor$i\\&gt;\" /etc/passwd | cut -d: -f 3) let num+=$id fidoneecho \"The users ID sum is: $num\"[root@centos gogogogogogogogoo]# 10、分别统计/etc/rc.d/rc.sysinit、/etc/rc.d/init.d/functions和/etc/fstab文件中以#号开头的行数之和，以及总的空白行数； 123456789101112131415161718192021222324252627282930313233343536[root@centos jerry_go]# cat title10-2.sh #!/bin/bash#Author:Jerry#Description## if [ -e $1 ]; then jinghao1=$(grep \"^#\" $1 | wc -l) blank_line1=$(grep \"^$\" $1 | wc -l) echo \"The file $1 Jinghao_lines:$jinghao1 Blank_lines:$blank_line1 \" else echo \"The file $1 no exist\" exit 2 fi if [ -e $2 ]; then jinghao2=$(grep \"^#\" $2 | wc -l) blank_line2=$(grep \"^$\" $2 | wc -l) echo \"The file $2 Jinghao_lines:$jinghao2 Blank_lines:$blank_line2 \" else echo \"The file $2 no exist\" exit 2 fi if [ -e $3 ]; then jinghao3=$(grep \"^#\" $3 | wc -l) blank_line3=$(grep \"^$\" $3 | wc -l) echo \"The file $3 Jinghao_lines:$jinghao3 Blank_lines:$blank_line3 \" else echo \"The file $3 no exist\" exit 2 fi echo \"Total jinghao lines: $[$jinghao1+$jinghao2+$jinghao3]\" echo \"Total blank lines: $[$blank_line1+$blank_line2+$blank_line3]\" &amp;&amp; exit 0 ​ ​ 1234567891011121314151617181920212223走一个！come on baby！[root@centos jerry_go]# bash title10-2.sh /etc/rc.d/rc.sysinit /etc/rc.d/init.d/functions /etc/fstab The file /etc/rc.d/rc.sysinit Jinghao_lines:44 Blank_lines:100 The file /etc/rc.d/init.d/functions Jinghao_lines:43 Blank_lines:105 The file /etc/fstab Jinghao_lines:8 Blank_lines:1 Total jinghao lines: 95Total blank lines: 206[root@centos jerry_go]# 异常的走一个！ 欧耶！[root@centos jerry_go]# bash title10-2.sh /etc/rc.d/rc.sysinit /etc/rc.d/init.d/funct234ions /etc/fstab The file /etc/rc.d/rc.sysinit Jinghao_lines:44 Blank_lines:100 The file /etc/rc.d/init.d/funct234ions no exist[root@centos jerry_go]#异常的再走一个！ [root@centos jerry_go]# bash title10-2.sh /etc/rc.d/rc.sysinit /etc/rc.d/init.d/functions /etc/fst123ab The file /etc/rc.d/rc.sysinit Jinghao_lines:44 Blank_lines:100 The file /etc/rc.d/init.d/functions Jinghao_lines:43 Blank_lines:105 The file /etc/fst123ab no exist[root@centos jerry_go]# 最后发现井号的英文是well number ， 脚本里面用拼音实在是很low，不过我是刚开始嘛，who care...... 11、显示当前系统上所有默认shell为bash的用户的用户名、UID以及此类所有用户的UID之和； 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@centos jerry_go]# cat week7_title11.sh#!/bin/bash#Author:Jerry#Description##grep \"bin/bash$\" /etc/passwd |cut -d\":\" -f1,3for i in `grep \"bin/bash$\" /etc/passwd |awk -F \":\" '&#123;print $3&#125;'`;do let sum+=$idone echo \"Users ID sum is:$sum\"[root@centos jerry_go]# bash week7_title11.sh root:0magedu:500mamamamam:501magedu1:502abb1:503abb2:504abb3:505abb4:506visitor1:507visitor2:508visitor3:509visitor4:510visitor5:511visitor6:512visitor7:513visitor8:514visitor9:515visitor10:516visitor11:517visitor12:518visitor13:519visitor14:520visitor15:521visitor16:522visitor17:523visitor18:524visitor19:525visitor20:526Users ID sum is:13851 12、显示当前系统上所有，拥有附加组的用户的用户名；并说明共有多少个此类用户； 1234567891011121314151617[root@centos jerry_go]# bash week7_title12.sh bindaemonsysadmlpmailhaldaemonThis users has 7.[root@centos jerry_go]# cat week7_title12.sh #!/bin/bash#Author:Jerry#Description#grep -v \":$\" /etc/group |awk -F \":\" '&#123;print $1&#125;'echo \"This users has $(grep -v \":$\" /etc/group |awk -F \":\" '&#123;print $1&#125;'|wc -l).\" 13、创建一个由至少两个物理卷组成的大小为20G的卷组；要求，PE大小为8M；而在卷组中创建一个大小为5G的逻辑卷mylv1，格式化为ext4文件系统，开机自动挂载至/users目录，支持acl； 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[root@centos ~]# pvdisplay #先看看环境 --- Physical volume --- PV Name /dev/sda2 VG Name vg_centos PV Size 159.51 GiB / not usable 3.00 MiB Allocatable yes (but full) PE Size 4.00 MiB Total PE 40834 Free PE 0 Allocated PE 40834 PV UUID 1O2YO5-7puR-3Pfu-nR15-tqCc-JjPN-giIZeh \"/dev/sdb1\" is a new physical volume of \"10.00 GiB\" --- NEW Physical volume --- PV Name /dev/sdb1 VG Name PV Size 10.00 GiB Allocatable NO PE Size 0 Total PE 0 Free PE 0 Allocated PE 0 PV UUID dmUkps-1j6e-q50O-yOh8-nBlT-lw6t-nGKnat \"/dev/sdc1\" is a new physical volume of \"60.00 GiB\" --- NEW Physical volume --- PV Name /dev/sdc1 VG Name PV Size 60.00 GiB Allocatable NO PE Size 0 Total PE 0 Free PE 0 Allocated PE 0 PV UUID WfoY2H-efkl-qx0z-Yetm-wyV0-3lUU-u815Aq [root@centos ~]# vgcreate -s 8m vg_mage /dev/sdb1 /dev/sdc1 #创建一个由至少两个物理卷组成的大小为20G的卷组，我这里不止了，无伤大雅。 Volume group \"vg_mage\" successfully created[root@centos ~]# lvcreate -L 5G -n mylv1 vg_mage &amp;&amp; mkfs.ext4 /dev/vg_mage/mylv1 #在卷组中创建一个大小为5G的逻辑卷mylv1，格式化为ext4文件系统[root@centos ~]# mkdir /users &amp;&amp; echo \"/dev/vg_mage/mylv1 /users ext4 defaults,acl 0 0\" &gt;&gt; /etc/fstab #自动挂载至/users目录，支持acl[root@centos ~]# cat /etc/fstab ## /etc/fstab# Created by anaconda on Thu Jun 23 18:40:21 2016## Accessible filesystems, by reference, are maintained under '/dev/disk'# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/vg_centos-lv_root / ext4 defaults 1 1UUID=7b714956-acd7-44cb-af53-4eacde793fd9 /boot ext4 defaults 1 2#/dev/mapper/vg_centos-lv_swap swap swap defaults 0 0tmpfs /dev/shm tmpfs defaults 0 0devpts /dev/pts devpts gid=5,mode=620 0 0sysfs /sys sysfs defaults 0 0proc /proc proc defaults 0 0/dev/vg_mage/mylv1 /users ext4 defaults,acl 0 0 [root@centos ~]# 14、新建用户magedu；其家目录为/users/magedu，而后su切换至此用户，复制多个文件至家目录； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546[root@centos ~]# useradd magedu -d /users/magedu[root@centos ~]# su - magedu[magedu@centos ~]$ cp /etc/*.conf ~[magedu@centos ~]$ ls -al总用量 188drwx------ 4 magedu magedu 4096 12月 27 12:52 .drwxr-xr-x. 4 root root 4096 12月 27 12:48 ..-rw-r--r-- 1 magedu magedu 148 12月 27 12:52 asound.conf-rw-r--r-- 1 magedu magedu 18 5月 11 2016 .bash_logout-rw-r--r-- 1 magedu magedu 176 5月 11 2016 .bash_profile-rw-r--r-- 1 magedu magedu 124 5月 11 2016 .bashrc-rw-r--r-- 1 magedu magedu 1780 12月 27 12:52 cas.conf-rw-r--r-- 1 magedu magedu 21214 12月 27 12:52 dnsmasq.conf-rw-r--r-- 1 magedu magedu 519 12月 27 12:52 dracut.conf-rw-r--r-- 1 magedu magedu 20 12月 27 12:52 fprintd.conf-rw-r--r-- 1 magedu magedu 0 12月 27 12:52 gai.confdrwxr-xr-x 2 magedu magedu 4096 11月 12 2010 .gnome2-rw-r--r-- 1 magedu magedu 9 12月 27 12:52 host.conf-rw-r--r-- 1 magedu magedu 0 12月 27 12:52 init.conf-rw-r--r-- 1 magedu magedu 8120 12月 27 12:52 kdump.conf-rw-r--r-- 1 magedu magedu 449 12月 27 12:52 krb5.conf-rw-r--r-- 1 magedu magedu 1662 12月 27 12:52 latrace.conf-rw-r--r-- 1 magedu magedu 47 12月 27 12:52 ld.so.conf-rw-r--r-- 1 magedu magedu 2293 12月 27 12:52 libuser.conf-rw-r--r-- 1 magedu magedu 662 12月 27 12:52 logrotate.conf-rw-r--r-- 1 magedu magedu 10814 12月 27 12:52 ltrace.conf-rw-r--r-- 1 magedu magedu 827 12月 27 12:52 mke2fs.confdrwxr-xr-x 4 magedu magedu 4096 6月 23 2016 .mozilla-rw-r--r-- 1 magedu magedu 2620 12月 27 12:52 mtools.conf-rw-r--r-- 1 magedu magedu 1688 12月 27 12:52 nsswitch.conf-rw-r--r-- 1 magedu magedu 1698 12月 27 12:52 ntp.conf-rw-r--r-- 1 magedu magedu 370 12月 27 12:52 pm-utils-hd-apm-restore.conf-rw-r--r-- 1 magedu magedu 789 12月 27 12:52 prelink.conf-rw-r--r-- 1 magedu magedu 966 12月 27 12:52 readahead.conf-rw-r--r-- 1 magedu magedu 81 12月 27 12:52 resolv.conf-rw-r--r-- 1 magedu magedu 2875 12月 27 12:52 rsyslog.conf-rw-r--r-- 1 magedu magedu 216 12月 27 12:52 sestatus.conf-rw-r--r-- 1 magedu magedu 6717 12月 27 12:52 smartd.conf-rw-r--r-- 1 magedu magedu 256 12月 27 12:52 sos.conf-rw-r--r-- 1 magedu magedu 1800 12月 27 12:52 sysctl.conf-rw-r--r-- 1 magedu magedu 1309 12月 27 12:52 tpvmlp.conf-rw-r--r-- 1 magedu magedu 45 12月 27 12:52 Trolltech.conf-rw-r--r-- 1 magedu magedu 485 12月 27 12:52 updatedb.conf-rw-r--r-- 1 magedu magedu 3008 12月 27 12:52 warnquota.conf-rw-r--r-- 1 magedu magedu 969 12月 27 12:52 yum.conf[magedu@centos ~]$ ​ 15、扩展mylv1至9G，确保扩展完成后原有数据完全可用； 12lvextend -L +4G /dev/mapper/myvg-mylv1 resize2fs /dev/mapper/myvg-mylv1 16、缩减mylv1至7G，确保缩减完成后原有数据完全可用； 12345# umount /dev/vg_mage/mylv1# e2fsck -f /dev/vg_mage/mylv1# resize2fs /dev/vg_mage/mylv11 7G# lvreduce -L 7G /dev/vg_mage/mylv1# mount /dev/vg_mage/mylv1 /users/ 17、对mylv1创建快照，并通过备份数据；要求保留原有的属主属组等信息； 12[root@centos users]# lvcreate -s -l 20 -n snvg1 -p r /dev/vg_mage/mylv1Logical volume \"snvg1\" created.","categories":[],"tags":[{"name":"shell","slug":"shell","permalink":"https://zhusas.github.io/tags/shell/"}]},{"title":"Vim编辑器和脚本小试牛刀","slug":"Vim编辑器和脚本小试牛刀","date":"2018-08-02T08:44:00.000Z","updated":"2018-08-02T08:45:50.218Z","comments":true,"path":"2018/08/02/Vim编辑器和脚本小试牛刀/","link":"","permalink":"https://zhusas.github.io/2018/08/02/Vim编辑器和脚本小试牛刀/","excerpt":"VIM很强大，但是万变不离其宗，最核心的三模式以下图表示： 1、复制/etc/rc.d/rc.sysinit文件至/tmp目录，将/tmp/rc.sysinit文件中的以至少一个空白字符开头的行的行首加#；1:%s/^[[:blank:]]\\+.*/\\0#/g","text":"VIM很强大，但是万变不离其宗，最核心的三模式以下图表示： 1、复制/etc/rc.d/rc.sysinit文件至/tmp目录，将/tmp/rc.sysinit文件中的以至少一个空白字符开头的行的行首加#；1:%s/^[[:blank:]]\\+.*/\\0#/g 2、复制/boot/grub/grub.conf至/tmp目录中，删除/tmp/grub.conf文件中的行首的空白字符；1:%s/^[[:space:]]\\+//g 3、删除/tmp/rc.sysinit文件中的以#开头，且后面跟了至少一个空白字符的行行的#和空白字符1:%s/^#[[:blank:]]\\+//g 4、为/tmp/grub.conf文件中前三行的行首加#号；1:1,3s/^/\\0#/g 5、将/etc/yum.repos.d/CentOS-Media.repo文件中所有的enabled=0或gpgcheck=0的最后的0修改为1；1:%s/\\(enabled\\|gpgcheck\\)=0/\\1=1/g 6、每4小时执行一次对/etc目录的备份，备份至/backup目录中，保存的目录名为形如etc-2015040202021* */4 * * * /usr/bin/cp /etc /backup/etc-$(date +%Y%m%d%H%M)/ 7、每周2，4，6备份/var/log/messages文件至/backup/messages_logs/目录中，保存的文件名形如messages-201504021* * * * 2,4,6 /usr/bin/cp /var/log/messages /backupmessages_logs/messages-$(date +%Y%m%d) 8、每天每两小时取当前系统/proc/meminfo文件中的所有以S开头的信息至/stats/memory.txt文件中1* */2 * * * /usr/bin/grep -E \"S.*\" /proc/meminfo&gt;&gt;/stats/memory.txt 9、工作日的工作时间内，每两小时执行一次echo “howdy”1* 9-18/2 * * 1-5 /usr/bin/echo \"howdy\" 脚本编程部分创建目录/tmp/testdir-当前日期时间; 在此目录创建100个空文件：file1-file1001234567891011[root@centos7 ~]# cat testdir#!/bin/bash#Author:Jerrycd /tmp &amp;&amp; mkdir testdir-$(date +%Y%m%d%H%M%S)cd testdir-$(date +%Y%m%d%H%M%S)for i in &#123;1..100&#125;; do touch file$idone 123456789[root@centos7 ~]# bash testdir[root@centos7 ~]# ls /tmp/testdir-20161219144412/file1 file14 file2 file25 file30 file36 file41 file47 file52 file58 file63 file69 file74 file8 file85 file90 file96file10 file15 file20 file26 file31 file37 file42 file48 file53 file59 file64 file7 file75 file80 file86 file91 file97file100 file16 file21 file27 file32 file38 file43 file49 file54 file6 file65 file70 file76 file81 file87 file92 file98file11 file17 file22 file28 file33 file39 file44 file5 file55 file60 file66 file71 file77 file82 file88 file93 file99file12 file18 file23 file29 file34 file4 file45 file50 file56 file61 file67 file72 file78 file83 file89 file94file13 file19 file24 file3 file35 file40 file46 file51 file57 file62 file68 file73 file79 file84 file9 file95[root@centos7 ~]# 12、显示/etc/passwd文件中位于第偶数行的用户的用户名；1234567891011121314151617181920212223242526272829[root@centos7 ~]# sed -n '2~2p' /etc/passwd |cut -d \":\" -f1binadmsynchaltoperatorftpavahi-autoipdsystemd-networkpolkitdapacheabrtunboundsaslauthamandabackupgeocluesetroubleshootntpnfsnobodyqemumysqlpulsegnome-initial-setupsshdtcpdumphadooptestbashnologinuser1 13、创建10用户user10-user19；密码同用户名；1234567891011#!/bin/bash# for i in &#123;10..19&#125;;do if id user$i ;then echo \"user$i exists.\" else useradd user$i echo \"user$i\" | passwd --stdin user$i fi done 14、在/tmp/创建10个空文件file10-file19; 把file10的属主和属组改为user10，依次类推。12345678910111213#!/bin/bash# cd /tmp/ for i in &#123;10..19&#125;;do if [ -e file$i ] ;then echo \"file$i exists.\" chown user$i:user$i file$i else touch file$i chown user$i:user$i file$i fi done","categories":[],"tags":[{"name":"shell","slug":"shell","permalink":"https://zhusas.github.io/tags/shell/"}]},{"title":"skr! grep~ skr~~find!","slug":"skr-grep-skr-find","date":"2018-08-02T08:32:00.000Z","updated":"2018-08-02T08:33:30.996Z","comments":true,"path":"2018/08/02/skr-grep-skr-find/","link":"","permalink":"https://zhusas.github.io/2018/08/02/skr-grep-skr-find/","excerpt":"1、显示当前系统上root、fedora或user1用户的默认shell； 1grep -E \"^(root|hadoop|user1)\\&gt;\" /etc/passwd |cut -d\":\" -f1,7 2、找出/etc/rc.d/init.d/functions文件中某单词后面跟一组小括号的行，形如：hello()； 123456789101112131415161718192021222324[root@centos7 /]# grep -E -o \"[_[:alnum:]]+\\(\\)\" /etc/rc.d/init.d/functionscheckpid()__pids_var_run()__pids_pidof()daemon()killproc()pidfileofproc()pidofproc()status()echo_success()echo_failure()echo_passed()echo_warning()update_boot_stage()success()failure()passed()warning()action()strstr()is_ignored_file()is_true()is_false()apply_sysctl()","text":"1、显示当前系统上root、fedora或user1用户的默认shell； 1grep -E \"^(root|hadoop|user1)\\&gt;\" /etc/passwd |cut -d\":\" -f1,7 2、找出/etc/rc.d/init.d/functions文件中某单词后面跟一组小括号的行，形如：hello()； 123456789101112131415161718192021222324[root@centos7 /]# grep -E -o \"[_[:alnum:]]+\\(\\)\" /etc/rc.d/init.d/functionscheckpid()__pids_var_run()__pids_pidof()daemon()killproc()pidfileofproc()pidofproc()status()echo_success()echo_failure()echo_passed()echo_warning()update_boot_stage()success()failure()passed()warning()action()strstr()is_ignored_file()is_true()is_false()apply_sysctl() 3、使用echo命令输出一个绝对路径，使用grep取出其基名；扩展：取出其路径名 12345[root@centos7 /]# echo \"/etc/rc.d/init.d/functions\" |grep -E -o \"[^/]+$\"functions[root@centos7 /]# echo \"/etc/rc.d/init.d/functions\" |grep -E -o \"^/.*/\"/etc/rc.d/init.d/ 4、找出ifconfig命令结果中的1-255之间数字； 1ifconfig | grep -E -o \"\\&lt;([1-9]|[1-9][0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\\&gt;\" 5、挑战题：写一个模式，能匹配合理的IP地址； 1grep -E -o \"\\&lt;([0-9]|[1-9][0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\\&gt;.\\&lt;([0-9]|[1-9][0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\\&gt;.\\&lt;([0-9]|[1-9][0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\\&gt;.\\&lt;([0-9]|[1-9][0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\\&gt;\" 6、挑战题：写一个模式，能匹配出所有的邮件地址； 1grep -E -o “\\&lt;[a-z0-9A-Z._%+-]+@[a-z0-9A-Z.-]+\\.[a-zA-Z]&#123;2,6&#125;\\&gt;” 7、查找/var目录下属主为root，且属组为mail的所有文件或目录； 123[root@centos7 /]# find /var/ -user root -a -group mail/var/spool/mail/var/spool/mail/root 8、查找当前系统上没有属主或属组的文件；进一步：查找当前系统上没有属主或属组，且最近3天内曾被访问过的文件或目录； 1find / -nouser -o -nogroup -atime 3 9、查找/etc目录下所有用户都有写权限的文件； 1find /etc/ -perm -020 10、查找/etc目录下大于1M，且类型为普通文件的所有文件； 1find /etc/ -size +1M -type f 11、查找/etc/init.d/目录下，所有用户都有执行权限，且其它用户有写权限的文件； 1find /etc/init.d/ -perm -111 -perm -002 12、查找/usr目录下不属于root、bin或hadoop的文件； 123[root@centos7 /]# find /usr ! \\( -user root -o -user bin -o -user hadoop \\)/usr/share/polkit-1/rules.d/usr/libexec/abrt-action-install-debuginfo-to-abrt-cache 13、查找/etc/目录下至少有一类用户没有写权限的文件； 123456789101112131415161718192021222324252627282930313233[root@centos7 /]# find /usr ! \\( -user root -o -user bin -o -user hadoop \\)/usr/share/polkit-1/rules.d/usr/libexec/abrt-action-install-debuginfo-to-abrt-cache[root@centos7 /]# find /usr -not \\( -user root -o -user bin -o -user hadoop \\)/usr/share/polkit-1/rules.d/usr/libexec/abrt-action-install-debuginfo-to-abrt-cache[root@centos7 /]# find /usr ! \\( -user root -o -user bin -o -user hadoop \\)/usr/share/polkit-1/rules.d/usr/libexec/abrt-action-install-debuginfo-to-abrt-cache[root@centos7 /]# find /etc/ -not -perm /222/etc/pki/ca-trust/extracted/java/cacerts/etc/pki/ca-trust/extracted/openssl/ca-bundle.trust.crt/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem/etc/pki/ca-trust/extracted/pem/email-ca-bundle.pem/etc/pki/ca-trust/extracted/pem/objsign-ca-bundle.pem/etc/gshadow/etc/openldap/certs/password/etc/shadow/etc/ld.so.conf.d/kernel-3.10.0-327.el7.x86_64.conf/etc/ld.so.conf.d/kernel-3.10.0-327.36.3.el7.x86_64.conf/etc/udev/hwdb.bin/etc/gshadow-/etc/dbus-1/system.d/cups.conf/etc/shadow-/etc/lvm/profile/cache-mq.profile/etc/lvm/profile/cache-smq.profile/etc/lvm/profile/command_profile_template.profile/etc/lvm/profile/metadata_profile_template.profile/etc/lvm/profile/thin-generic.profile/etc/lvm/profile/thin-performance.profile/etc/pam.d/cups/etc/machine-id/etc/sudoers 14、查找/etc目录下最近一周内其内容被修改过，且不属于root或hadoop的文件； 1find /etc -mtime -7 ! \\( -user root -o -user hadoop \\)","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://zhusas.github.io/tags/linux/"}]},{"title":"Linux一些基本操作","slug":"Linux一些基本操作","date":"2018-08-02T07:47:08.000Z","updated":"2018-08-02T07:47:53.093Z","comments":true,"path":"2018/08/02/Linux一些基本操作/","link":"","permalink":"https://zhusas.github.io/2018/08/02/Linux一些基本操作/","excerpt":"一，列出当前系统上所有已经登录的用户的用户名，注意，同一个用户登录多次只显示一次即可12w -h | cut -d\" \" -f1 | uniqwho |cut -d\" \" -f1|uniq 二，取出最后登录到当前系统的用户相关信息1w| tail -n 1","text":"一，列出当前系统上所有已经登录的用户的用户名，注意，同一个用户登录多次只显示一次即可12w -h | cut -d\" \" -f1 | uniqwho |cut -d\" \" -f1|uniq 二，取出最后登录到当前系统的用户相关信息1w| tail -n 1 三，取出当前系统上被用户当作默认shell的最多的那个shell1cat /etc/passwd |cut -d \":\" -f7|grep /bin/bash|uniq 四，将/etc/passwd中的第三个字段数值最大的后10个用户的信息全部改为大写后保存至/tmp/maxusers.txt文件中1sort -t: -k3 -n /etc/passwd |tail -10|tr 'a-z' 'A-Z' &gt; /tmp/maxusers.txt 五，取出当前主机的IP地址，提示：对ifconfig命令的结果进行切分。12CentOS7 ifconfig |grep inet |cut -d' ' -f10|head -1 六，列出/etc/目录下所有以.conf结尾的文件的文件名，并将其名字转换为大写后保存至/tmp/etc.conf文件中1ll /etc/*.conf|cut -d'/' -f3|tr 'a-z' 'A-Z' &gt;/tmp/etc.conf 七，显示/var目录下一级子目录或文件的总个数1ls -al /var/|head -1|cut -d' ' -f2 八，取出/etc/group文件中第三个字段数值最小的10个组的名字1sort -t: -k3 -n /etc/group|head -10|cut -d':' -f1 九，将/etc/fstab和/etc/issue文件的内容合并为同一个内容保存至/tmp/etc.test文件中1cat /etc/fstab /etc/issue &gt; /tmp/etc.test 十，请总结描述用户和组管理类命令的使用方法并完成练习(1)、创建组distro，其GID为2016; 1groupadd distro -g 2016 (2)、创建用户mandriva, 其ID号为1005；基本组为distro; 1adduser mandriva -u 1005 -g distro (3)、创建用户mageia，其ID号为1100，家目录为/home/linux; 1useradd mageia -u 1100 -d /home/linux (4)、给用户mageia添加密码，密码为mageedu; 1234567[root@centos7 home]# passwd mageia 更改用户 mageia 的密码 。新的 密码：无效的密码： 密码少于 8 个字符重新输入新的 密码：passwd：所有的身份验证令牌已经成功更新。[root@centos7 home]# (5)、删除mandriva，但保留其家目录; 1userdel mandriva (6)、创建用户slackware，其ID号为2002，基本组为distro，附加组peguin; 1groupadd peguin &amp;&amp; useradd slackware -u 2002 -g distro -G peguin (7)、修改slackware的默认shell为/bin/tcsh; 1usermod -s /usr/bin/tcsh slackware (8)、为用户slackware新增附加组admins; 1groupadd admins &amp;&amp; usermod -G admins slackware (9)、为slackware添加密码，且要求密码最短使用期限为3天，最长为180天，警告为3天; 12echo \"123456\" | passwd --stdin slackwarepasswd -n 3 -x 180 -w 3 slackware (10)、添加用户openstack，其ID号为3003, 基本组为clouds，附加组为peguin和nova; 1groupadd nova &amp;&amp; groupadd clouds &amp;&amp; useradd openstack -u 3003 -g clouds -G peguin,nova (11)、添加系统用户mysql，要求其shell为/sbin/nologin; 1useradd -s /sbin/nologin mysql (12)、使用echo命令，非交互式为openstack添加密码. 1echo \"123456\" | passwd –stdin openstack","categories":[],"tags":[]},{"title":"Linux上的文件管理类命令其常用的使用方法及其相关示例演示","slug":"Linux上的文件管理类命令其常用的使用方法及其相关示例演示","date":"2018-08-02T07:41:00.000Z","updated":"2018-08-02T07:43:17.404Z","comments":true,"path":"2018/08/02/Linux上的文件管理类命令其常用的使用方法及其相关示例演示/","link":"","permalink":"https://zhusas.github.io/2018/08/02/Linux上的文件管理类命令其常用的使用方法及其相关示例演示/","excerpt":"目录管理类的命令mkdir用法： 1mkdir [选项]... 目录... 选项： 1-p 递归创建多个目录 实例： 1234567891011121314[root@centos7 ~]# mkdir -p /tmp/jerry/2016/11/4[root@centos7 /]# tree /tmp /tmp├── akonadi-root.9I0Ba3├── anaconda.log├── hogsuspend├── hsperfdata_root│ └── 88148├── hsperfdata_user├── ifcfg.log├── jerry│ └── 2016│ └── 11│ └──4 12**注意：****centos7&amp;6默认没有安装tree命令，记得yum install tree 就OK。**","text":"目录管理类的命令mkdir用法： 1mkdir [选项]... 目录... 选项： 1-p 递归创建多个目录 实例： 1234567891011121314[root@centos7 ~]# mkdir -p /tmp/jerry/2016/11/4[root@centos7 /]# tree /tmp /tmp├── akonadi-root.9I0Ba3├── anaconda.log├── hogsuspend├── hsperfdata_root│ └── 88148├── hsperfdata_user├── ifcfg.log├── jerry│ └── 2016│ └── 11│ └──4 12**注意：****centos7&amp;6默认没有安装tree命令，记得yum install tree 就OK。** 选项： 1-v 显示创建过程即命令执行过程 实例： 123456[root@centos7 /]# mkdir -pv /tmp/aaa/bbb/ccc/2016/11qamkdir: 已创建目录 \"/tmp/aaa\"mkdir: 已创建目录 \"/tmp/aaa/bbb\"mkdir: 已创建目录 \"/tmp/aaa/bbb/ccc\"mkdir: 已创建目录 \"/tmp/aaa/bbb/ccc/2016\"mkdir: 已创建目录 \"/tmp/aaa/bbb/ccc/2016/11qa\" 选项： 1-m：设定目录权限，不加则为默认权限 实例： 12345678910111213141516[root@centos7 /]# mkdir -m 777 -pv /tmp/fbi/ciamkdir: 已创建目录 \"/tmp/fbi\"mkdir: 已创建目录 \"/tmp/fbi/cia\" [root@centos7 /]# ll /tmp/fbi总用量 0drwxrwxrwx. 2 root root 6 11月 4 15:52 cia[root@centos7 /]# mkdir -m 775 -pv /tmp/hbo/oom/ubuntumkdir: 已创建目录 \"/tmp/hbo\"mkdir: 已创建目录 \"/tmp/hbo/oom\"mkdir: 已创建目录 \"/tmp/hbo/oom/ubuntu[root@centos7 /]# ll /tmp/hbo/oom/总用量 0drwxrwxr-x. 2 root root 6 11月 4 16:00 ubuntu注意：-m 参数设定的目录权限只对最后一级的目录生效，其上级目录均是默认的755。哈哈~~ rmdir用法： 1rmdir [选项]... 目录... 选项参数： 1234567 --ignore-fail-on-non-empty 忽略仅由目录非空产生的所有错误-p, --parents remove DIRECTORY and its ancestors; e.g., 'rmdir -p a/b/c' is similar to 'rmdir a/b/c a/b a'-v, --verbose output a diagnostic for every directory processed --help 显示此帮助信息并退出 --version 显示版本信息并退出 实例： 123[root@centos7 tmp]# rmdir -pv fbi/cia/rmdir: 正在删除目录 \"fbi/cia/\"rmdir: 正在删除目录 \"fbi\" 文件查看类命令cat用法： 12用法：cat [选项]... [文件]...将[文件]或标准输入组合输出到标准输出。 选项： 123456789101112-A, --show-all 等于-vET-b, --number-nonblank 对非空输出行编号-e 等于-vE-E, --show-ends 在每行结束处显示\"$\"-n, --number 对输出的所有行编号-s, --squeeze-blank 不输出多行空行-t 与-vT 等价-T, --show-tabs 将跳格字符显示为^I-u (被忽略)-v, --show-nonprinting 使用^ 和M- 引用，除了LFD和 TAB 之外 --help 显示此帮助信息并退出 --version 显示版本信息并退出 平时可能用到的选项就是输出行号了，实例如下： 123456789101112131415[root@centos7 /]# cat -n /etc/rc.local 1 #!/bin/bash 2 # THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES 3 # 4 # It is highly advisable to create own systemd services or udev rules 5 # to run scripts during boot instead of using this file. 6 # 7 # In contrast to previous versions due to parallel execution during boot 8 # this script will NOT be run after all other services. 9 #10 # Please note that you must run 'chmod +x /etc/rc.d/rc.local' to ensure11 # that this script will be executed during boot.12 13 touch /var/lock/subsys/local[root@centos7 /]# tactac命令：与cat功能相近，只是逆序显示文件内容 head用法： 12head [选项]... [文件]...查看文件的前N行，默认为10行 选项： 12-n -# 实例： 1234567891011121314151617181920212223242526272829[root@centos7 ~]# head /etc/passwdroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltmail:x:8:12:mail:/var/spool/mail:/sbin/nologinoperator:x:11:0:operator:/root:/sbin/nologin[root@centos7 ~]# head - 15 /etc/passwd[root@centos7 ~]# head -15 /etc/passwdroot:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltmail:x:8:12:mail:/var/spool/mail:/sbin/nologinoperator:x:11:0:operator:/root:/sbin/nologingames:x:12:100:games:/usr/games:/sbin/nologinftp:x:14:50:FTP User:/var/ftp:/sbin/nologinnobody:x:99:99:Nobody:/:/sbin/nologinavahi-autoipd:x:170:170:Avahi IPv4LL Stack:/var/lib/avahi-autoipd:/sbin/nologinsystemd-bus-proxy:x:999:997:systemd Bus Proxy:/:/sbin/nologin tail用法： 1tail [选项]... [文件]... 选项参数： 123-n：指定显示的行数。不加任何参数默认显示10行，从最后一行开始；-#：直接指定显示的行数，从最后一行开始；-f：查看文件尾部内容结束后不退出，跟随显示新增的行； 实例： 123456789101112131415[root@centos7 ~]# tail -2 /etc/passwdtcpdump:x:72:72::/:/sbin/nologinuser:x:1000:1000:user:/home/user:/bin/bash[root@centos7 ~]# tail /etc/passwdmysql:x:27:27:MariaDB Server:/var/lib/mysql:/sbin/nologinpcp:x:988:985:Performance Co-Pilot:/var/lib/pcp:/sbin/nologinpulse:x:171:171:PulseAudio System Daemon:/var/run/pulse:/sbin/nologingdm:x:42:42::/var/lib/gdm:/sbin/nologingnome-initial-setup:x:987:982::/run/gnome-initial-setup/:/sbin/nologinavahi:x:70:70:Avahi mDNS/DNS-SD Stack:/var/run/avahi-daemon:/sbin/nologinsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologinoprofile:x:16:16:Special user account to be used by OProfile:/var/lib/oprofile:/sbin/nologintcpdump:x:72:72::/:/sbin/nologinuser:x:1000:1000:user:/home/user:/bin/bash more用法： 12more [选项] 文件...特点：翻屏至文件尾部后自动退出； 选项参数： 1234567891011-d 显示帮助，而不是响铃-f 统计逻辑行数而不是屏幕行数-l 抑制换页(form feed)后的暂停-p 不滚屏，清屏并显示文本-c 不滚屏，显示文本并清理行尾-u 抑制下划线-s 将多个空行压缩为一行-NUM 指定每屏显示的行数为 NUM+NUM 从文件第 NUM 行开始显示+/STRING 从匹配搜索字符串 STRING 的文件位置开始显示-V 输出版本信息并退出 实例： 1略过，给你个眼神自己体会^_^ less 特点： 其实man读取帮助手册就是调用的less指令。所以less命令的操作方式同man 文件管理类命令cp用法： 1234567891011121314151617单源复制：cp [OPTION]... [-T] SOURCE DEST多源复制：cp [OPTION]... SOURCE... DIRECTORY cp [OPTION]... -t DIRECTORY SOURCE...单源复制：cp [OPTION]... [-T] SOURCE DEST 如果DEST不存在：则事先创建此文件，并复制源文件的数据流至DEST中； 如果DEST存在： 如果DEST是非目录文件：则覆盖目标文件； 如果DEST是目录文件：则先在DEST目录下创建一个与源文件同名的文件，并复制其数据流；多源复制：cp [OPTION]... SOURCE... DIRECTORY cp [OPTION]... -t DIRECTORY SOURCE... 如果DEST不存在：错误； 如果DEST存在： 如果DEST是非目录文件：错误； 如果DEST是目录文件：分别复制每个文件至目标目录中，并保持原名； 选项参数： 12345678910111213-i：交互式复制，即覆盖之前提醒用户确认；-f：强制覆盖目标文件；-r, -R：递归复制目录；-d：复制符号链接文件本身，而非其指向的源文件；-a：-dR --preserve=all, archive，用于实现归档；--preserv= mode：权限 ownership：属主和属组 timestamps: 时间戳 context：安全标签 xattr：扩展属性 links：符号链接 all：上述所有属性 实例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354`单源复制-目标文件不存在情况`[root@centos ~]# ls /tmp/whatis.q3Uigb yum.log[root@centos ~]# cp /etc/issue /tmp[root@centos ~]# ls /tmp/issue whatis.q3Uigb yum.log[root@centos ~]# cat /tmp/issue CentOS release 6.5 (Final)Kernel \\r on an \\m`单源复制-目标文件已存在情况`[root@centos ~]# cp /etc/hosts /tmp/issue cp: overwrite `/tmp/issue'? y[root@centos ~]# cat /tmp/issue 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6`多源复制-目标目录不存在情况`[root@centos ~]# cp /etc/hosts /etc/issue /tmp/xcp: target `/tmp/x' is not a directory`多源复制-目标目录已存在情况`[root@centos ~]# mkdir /tmp/x[root@centos ~]# cp /etc/hosts /etc/issue /tmp/x[root@centos ~]# ls /tmp/xhosts issue[root@centos ~]# `-r选项实例`[root@centos ~]# mkdir -p /tmp/souce/x/y/z[root@centos ~]# mkdir /tmp/dest[root@centos ~]# cp -r /tmp/souce/ /tmp/dest/[root@centos ~]# tree /tmp/dest/ /tmp/dest/└── souce └── x └── y └── z4 directories, 0 files[root@centos ~]# `--preserve选项实例`[root@centos ~]# ls -l /tmp/ |grep liubin-rw-rw-r--. 1 liubin liubin 0 Sep 27 04:56 liubin [root@centos ~]# cp --preserve=ownership /tmp/liubin /tmp/root[root@centos ~]# ls -l /tmp/total 16drwxr-xr-x. 3 root root 4096 Sep 27 04:53 dest-rw-r--r--. 1 root root 158 Sep 27 04:43 issue -rw-rw-r--. 1 liubin liubin 0 Sep 27 04:56 liubin -rw-rw-r--. 1 liubin liubin 0 Sep 27 04:59 root drwxr-xr-x. 3 root root 4096 Sep 27 04:49 soucedrwxr-xr-x. 2 root root 4096 Sep 27 04:44 x-rw-------. 1 root root 0 Sep 27 03:07 yum.log mv用法： 123mv [OPTION]... [-T] SOURCE DESTmv [OPTION]... SOURCE... DIRECTORYmv [OPTION]... -t DIRECTORY SOURCE.. 选项参数： 12-i：交互式 -f：强制移动 实例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@localhost ~]# tree testtest|-- 1p2a|-- 28pa|-- Pa99|-- cpdoc.txt|-- hahaha| |-- cpdoc.txt| |-- cpdoc1.txt| `-- text.txt|-- p,a|-- pa|-- pa12`-- papi1 directory, 11 files[root@localhost ~]# mv test/1p2a test/hahaha[root@localhost ~]# tree testtest|-- 28pa|-- Pa99|-- cpdoc.txt|-- hahaha| |-- 1p2a| |-- cpdoc.txt| |-- cpdoc1.txt| `-- text.txt|-- p,a|-- pa|-- pa12`-- papi1 directory, 11 files[root@localhost ~]# mv test/hahaha test/mvtest[root@localhost ~]# tree testtest|-- 28pa|-- Pa99|-- cpdoc.txt|-- mvtest| |-- 1p2a| |-- cpdoc.txt| |-- cpdoc1.txt| `-- text.txt|-- p,a|-- pa|-- pa12`-- papi1 directory, 11 files rm用法： 1rm [OPTION]... FILE... 选项参数： 123-i：interactive-f：force-r: recursive 实例： 123456789101112[root@centos ~]# ls /tmpdest issue liubin root souce yum.log[root@centos ~]# tree /tmp/souce//tmp/souce/└── x └── y └── z 3 directories, 0 files[root@centos ~]# rm -rf /tmp/souce/[root@centos ~]# lsanaconda-ks.cfg install.log install.log.syslog[root@centos ~]# bash的工作特性之命令执行状态返回值和命令行展开所涉及的内容及其示例演示。用法echo $?：显示最近一条命令的执行结果 只能查看最近一条命令的执行的状态结果返回值 命令执行成功，则显示：0 命令执行失败，则显示：1-255之间的任意数字 实例1234567891011121314[root@centos7 ~]# ls /varaccount cache db games kerberos local log nis preserve spool tmp ypadm crash empty gopher lib lock mail opt run target www[root@centos7 ~]# echo $?0[root@centos7 ~]# ls /vartels: 无法访问/varte: 没有那个文件或目录[root@centos7 ~]# echo $?2[root@centos7 ~]# lsd /varbash: lsd: 未找到命令...[root@centos7 ~]# echo $?127[root@centos7 ~]# 创建/tmp目录下的：a_c, a_d, b_c, b_d1234567891011[root@centos7 ~]# mkdir -v /tmp/&#123;a,b&#125;_&#123;c,d&#125;mkdir: 已创建目录 \"/tmp/a_c\"mkdir: 已创建目录 \"/tmp/a_d\"mkdir: 已创建目录 \"/tmp/b_c\"mkdir: 已创建目录 \"/tmp/b_d\"[root@centos7 ~]# ls /tmp/a_ca_danaconda.logb_c b_d 创建/tmp/mylinux目录下的：12345678910111213141516171819202122232425mylinux├── bin├── boot│ └── grub├── dev├── etc│ ├── rc.d│ │ └── init.d│ └── sysconfig│ └── network-scripts├── lib│ └── modules├── lib64├── proc├── sbin├── sys├── tmp├── usr│ └── local│ ├── bin│ └── sbin└── var ├── lock ├── log └── run 123456789101112131415161718192021222324252627[root@centos7 ~]# mkdir -pv /tmp/mylinux/&#123;bin,boot/grub,dev,etc/&#123;rc.d/init.d,sysconfig/network-scripts&#125;,lib/modules,lib64,proc,sbin,sys,tmp,usr/local/&#123;bin,sbin&#125;,var/&#123;lock,log,run&#125;&#125;mkdir: 已创建目录 \"/tmp/mylinux\"mkdir: 已创建目录 \"/tmp/mylinux/bin\"mkdir: 已创建目录 \"/tmp/mylinux/boot\"mkdir: 已创建目录 \"/tmp/mylinux/boot/grub\"mkdir: 已创建目录 \"/tmp/mylinux/dev\"mkdir: 已创建目录 \"/tmp/mylinux/etc\" mkdir: 已创建目录 \"/tmp/mylinux/etc/rc.d\"mkdir: 已创建目录 \"/tmp/mylinux/etc/rc.d/init.d\"mkdir: 已创建目录 \"/tmp/mylinux/etc/sysconfig\"mkdir: 已创建目录 \"/tmp/mylinux/etc/sysconfig/network-scripts\"mkdir: 已创建目录 \"/tmp/mylinux/lib\"mkdir: 已创建目录 \"/tmp/mylinux/lib/modules\"mkdir: 已创建目录 \"/tmp/mylinux/lib64\"mkdir: 已创建目录 \"/tmp/mylinux/proc\"mkdir: 已创建目录 \"/tmp/mylinux/sbin\"mkdir: 已创建目录 \"/tmp/mylinux/sys\"mkdir: 已创建目录 \"/tmp/mylinux/tmp\"mkdir: 已创建目录 \"/tmp/mylinux/usr\"mkdir: 已创建目录 \"/tmp/mylinux/usr/local\"mkdir: 已创建目录 \"/tmp/mylinux/usr/local/bin\"mkdir: 已创建目录 \"/tmp/mylinux/usr/local/sbin\"mkdir: 已创建目录 \"/tmp/mylinux/var\"mkdir: 已创建目录 \"/tmp/mylinux/var/lock\"mkdir: 已创建目录 \"/tmp/mylinux/var/log\"mkdir: 已创建目录 \"/tmp/mylinux/var/run\"[root@centos7 ~]# 文件的元数据信息有哪些，分别表示什么含义，如何查看？如何修改文件的时间戳信息。1234567891011121314151617181920[root@centos7 etc]# stat /bin/bash文件：\"/bin/bash\"大小：960392 块：1880 IO 块：4096 普通文件设备：fd00h/64768d Inode：67111627 硬链接：1权限：(0755/-rwxr-xr-x) Uid：( 0/ root) Gid：( 0/ root)环境：system_u:object_r:shell_exec_t:s0 最近访问：2016-11-06 13:06:17.318000042 +0800最近更改：2016-08-03 00:00:07.000000000 +0800最近改动：2016-11-03 13:47:45.414998262 +0800创建时间：-touch命令：touch - change file timestampstouch [OPTION]... FILE... -c: 指定的文件路径不存在时不予创建； -a: 仅修改access time； -m：仅修改modify time； -t STAMP [[CC]YY]MMDDhhmm[.ss] 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354实例一：创建不存在的文件命令：touch log2012.log log2013.log输出：［root@localhost test］# touch log2012.log log2013.log［root@localhost test］# ll -rw-r--r-- 1 root root 0 10-28 16:01 log2012.log -rw-r--r-- 1 root root 0 10-28 16:01 log2013.log如果log2014.log不存在，则不创建文件［root@localhost test］# touch -c log2014.log［root@localhost test］# ll -rw-r--r-- 1 root root 0 10-28 16:01 log2012.log -rw-r--r-- 1 root root 0 10-28 16:01 log2013.log实例二：更新log.log的时间和log2012.log时间戳相同命令：touch -r log.log log2012.log 输出：［root@localhost test］# ll -rw-r--r-- 1 root root 0 10-28 16:01 log2012.log -rw-r--r-- 1 root root 0 10-28 16:01 log2013.log -rw-r--r-- 1 root root 0 10-28 14:48 log.log［root@localhost test］# touch -r log.log log2012.log［root@localhost test］# ll -rw-r--r-- 1 root root 0 10-28 14:48 log2012.log -rw-r--r-- 1 root root 0 10-28 16:01 log2013.log -rw-r--r-- 1 root root 0 10-28 14:48 log.log实例三：设定文件的时间戳 命令：touch -t 201211142234.50 log.log输出：［root@localhost test］# ll -rw-r--r-- 1 root root 0 10-28 14:48 log2012.log -rw-r--r-- 1 root root 0 10-28 16:01 log2013.log -rw-r--r-- 1 root root 0 10-28 14:48 log.log［root@localhost test］# touch -t 201211142234.50 log.log［root@localhost test］# ll -rw-r--r-- 1 root root 0 10-28 14:48 log2012.log -rw-r--r-- 1 root root 0 10-28 16:01 log2013.log -rw-r--r-- 1 root root 0 2012-11-14 log.log说明： -t time 使用指定的时间值 time 作为指定文件相应时间戳记的新值．此处的 time规定为如下形式的十进制数：［［CC］YY］MMDDhhmm［.SS］ 这里，CC为年数中的前两位，即”世纪数”；YY为年数的后两位，即某世纪中的年数．如果不给出CC的值，则touch 将把年数CCYY限定1969--2068之内．MM为月数，DD为天将把年数CCYY限定在1969--2068之内．MM为月数，DD为天数，hh 为小时数（几点），mm为分钟数，SS为秒数．此处秒的设定范围是0--61，这样可以处理闰秒．这些数字组成的时间是环境变量TZ指定的时区中的一个时 间．由于系统的限制，早于1970年1月1日的时间是错误的 如何定义一个命令的别名，如何在命令中引用另一个命令的执行结果？1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253命令别名查看：[root@centos ~]# aliasalias cp='cp -i'alias l.='ls -d .* --color=auto'alias ll='ls -l --color=auto'alias ls='ls --color=auto'alias mv='mv -i'alias rm='rm -i'创建别名：[root@centos ~]# alias clear='cls'[root@centos ~]# aliasalias clear='cls'alias cp='cp -i'alias l.='ls -d .* --color=auto'alias ll='ls -l --color=auto'alias ls='ls --color=auto'alias mv='mv -i'alias rm='rm -i'引用命令的执行结果： 使用“引用：[root@centos ~]# echo `date`Tue Sep 27 06:45:08 CST 2016[root@centos ~]#使用$(COMMAND)引用[root@centos ~]# file $(which --skip-alias ls)/bin/ls: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.18, stripped[root@centos ~]# 显示var目录下所有以l开头，以一个小写字母结尾，且中间至少出现一位数字（可以有其它字符）的文件或目录。12345678[root@centos7 /]# ls -dl /var/l*[0-9]*[a-z]drwxr-xr-x. 2 root root 6 11月 6 14:58 /var/l42opmdrwxr-xr-x. 2 root root 6 11月 6 14:58 /var/l47wsd-rw-r--r--. 1 root root 0 11月 6 15:38 /var/l9cxzdrwxr-xr-x. 2 root root 6 11月 6 15:35 /var/ls4gsdrwxr-xr-x. 2 root root 6 11月 6 15:34 /var/lw56tcp-rw-r--r--. 1 root root 0 11月 6 15:37 /var/lw89cxz-rw-r--r--. 1 root root 0 11月 6 15:37 /var/lw99cxz ​ 12345678[root@centos7 /]# ls -dl /var/l*[[:digit:]]*[[:alpha:]]drwxr-xr-x. 2 root root 6 11月 6 14:58 /var/l42opmdrwxr-xr-x. 2 root root 6 11月 6 14:58 /var/l47wsd-rw-r--r--. 1 root root 0 11月 6 15:38 /var/l9cxzdrwxr-xr-x. 2 root root 6 11月 6 15:35 /var/ls4gsdrwxr-xr-x. 2 root root 6 11月 6 15:34 /var/lw56tcp-rw-r--r--. 1 root root 0 11月 6 15:37 /var/lw89cxz-rw-r--r--. 1 root root 0 11月 6 15:37 /var/lw99cxz 显示/etc目录下，以任意一个数字开头，且以非数字结尾的文件或目录。12345[root@centos7 /]# ls -dl /etc/[[:digit:]]*[[:alpha:]]drwxr-xr-x. 2 root root 6 11月 6 15:43 /etc/12sad-rw-r--r--. 1 root root 29 11月 6 15:45 /etc/12sddrwxr-xr-x. 2 root root 6 11月 6 15:43 /etc/23gfhg-rw-r--r--. 1 root root 35 11月 6 15:46 /etc/4543sdcsf ​ 12345[root@centos7 /]# ls -dl /etc/[0-9]*[^0-9]drwxr-xr-x. 2 root root 6 11月 6 15:43 /etc/12sad-rw-r--r--. 1 root root 29 11月 6 15:45 /etc/12sddrwxr-xr-x. 2 root root 6 11月 6 15:43 /etc/23gfhg-rw-r--r--. 1 root root 35 11月 6 15:46 /etc/4543sdcsf 显示/etc目录下，以非字母开头，后面跟了一个字母以及其它任意长度任意字符的文件或目录。12345[root@centos7 /]# ls -dl /etc/[^a-z]*[a-z]drwxr-xr-x. 2 root root 6 11月 6 15:43 /etc/12sad-rw-r--r--. 1 root root 29 11月 6 15:45 /etc/12sddrwxr-xr-x. 2 root root 6 11月 6 15:43 /etc/23gfhg-rw-r--r--. 1 root root 35 11月 6 15:46 /etc/4543sdcsf 在/tmp目录下创建以tfile开头，后跟当前日期和时间的文件，文件名形如：tfile-2016-05-27-09-32-22。1touch /tmp/tfile-$(date +%F-%H-%M-%S) 复制/etc目录下所有以p开头，以非数字结尾的文件或目录到/tmp/mytest1目录中。1mkdir /tmp/mytest1 &amp;&amp; cp -r /etc/p*[^0-9] /tmp/mytest1/ 复制/etc目录下所有以.d结尾的文件或目录至/tmp/mytest2目录中。1mkdir /tmp/mytest2 &amp;&amp; cp -r /etc/*.d /tmp/mytest2/ 复制/etc/目录下所有以l或m或n开头，以.conf结尾的文件至/tmp/mytest3目录中。1mkdir -p /tmp/mytest3 &amp;&amp; cp /etc/[lmn]*.conf /tmp/mytest3/","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhusas.github.io/tags/Linux/"}]},{"title":"Linux的基础知识","slug":"Linux的基础知识","date":"2018-08-02T06:22:00.000Z","updated":"2018-08-02T07:05:52.405Z","comments":true,"path":"2018/08/02/Linux的基础知识/","link":"","permalink":"https://zhusas.github.io/2018/08/02/Linux的基础知识/","excerpt":"硬件冯·洛伊曼体系 控制器(Control)：是整个计算机的中枢神经，其功能是对程序规定的控制信息进行解释，根据其要求进行控制，调度程序、数据、地址，协调计算机各部分工作及内存与外设的访问等。 运算器(Datapath)：运算器的功能是对数据进行各种算术运算和逻辑运算，即对数据进行加工处理。 存储器(Memory)：存储器的功能是存储程序、数据和各种信号、命令等信息，并在需要时提供这些信息。 输入(Input system)：输入设备是计算机的重要组成部分，输入设备与输出设备合称为外部设备，简称外设，输入设备的作用是将程序、原始数据、文字、字符、控制命令或现场采集的数据等信息输入到计算机。常见的输入设备有键盘、鼠标器、光电输入机、磁带机、磁盘机、光盘机等。 输出(Output system)：输出设备与输入设备同样是计算机的重要组成部分，它把外算机的中间结果或最后结果、机内的各种数据符号及文字或各种控制信号等信息输出出来。微机常用的输出设备有显示终端CRT、打印机、激光印字机、绘图仪及磁带、光盘机等。","text":"硬件冯·洛伊曼体系 控制器(Control)：是整个计算机的中枢神经，其功能是对程序规定的控制信息进行解释，根据其要求进行控制，调度程序、数据、地址，协调计算机各部分工作及内存与外设的访问等。 运算器(Datapath)：运算器的功能是对数据进行各种算术运算和逻辑运算，即对数据进行加工处理。 存储器(Memory)：存储器的功能是存储程序、数据和各种信号、命令等信息，并在需要时提供这些信息。 输入(Input system)：输入设备是计算机的重要组成部分，输入设备与输出设备合称为外部设备，简称外设，输入设备的作用是将程序、原始数据、文字、字符、控制命令或现场采集的数据等信息输入到计算机。常见的输入设备有键盘、鼠标器、光电输入机、磁带机、磁盘机、光盘机等。 输出(Output system)：输出设备与输入设备同样是计算机的重要组成部分，它把外算机的中间结果或最后结果、机内的各种数据符号及文字或各种控制信号等信息输出出来。微机常用的输出设备有显示终端CRT、打印机、激光印字机、绘图仪及磁带、光盘机等。 软件低级语言：汇编语言，汇编器；写驱动 高级语言：系统级：C，C++，对性能要求较高的服务类程序应用级：Java,Python,Ruby Linux 发行版RedHat Enterprise LinuxRedhat系列，包括RHEL(Redhat Enterprise Linux，也就是所谓的Redhat Advance Server，收费版本)、Fedora Core(由原来的Redhat桌面版本发展而来，免费版本)、CentOS(RHEL的社区 克隆版本，免费)。Redhat是在国内使用人群最多的Linux版本，甚至有人将Redhat等同于Linux。所以这个版本的特点就是使用人群数量大，资料非常多，言下之意就是如果你有什么不明白的地方，很容易找到人来问，而且网上的一般Linux教程都是以Redhat为例来讲解的。Redhat系列的包管理方式采用的是基于RPM包的YUM包管理方式，包分发方式是编译好的二进制文件。稳定性方面RHEL和CentOS的稳定性非常好，适合于服务器使用，但是Fedora Core的稳定性较差，最好只用于桌面应用。 CentOS 是一个基于Red Hat Linux 提供的可自由使用源代码的企业级Linux发行版本。每个版本的 CentOS都会获得十年的支持（通过安全更新方式）。新版本的 CentOS 大约每两年发行一次，而每个版本的 CentOS 会定期（大概每六个月）更新一次，以便支持新的硬件。这样，建立一个安全、低维护、稳定、高预测性、高重复性的 Linux 环境。CentOS是Community Enterprise Operating System的缩写。CentOS 是RHEL（Red Hat Enterprise Linux）源代码再编译的产物，而且在RHEL的基础上修正了不少已知的 Bug ，相对于其他 Linux 发行版，其稳定性值得信赖。 Debian：只有社区的发行版Debian系列，包括Debian和Ubuntu等。Debian是社区类Linux的典范，是迄今为止最遵循GNU规范的Linux系统。Debian最早由Ian Murdock于1993年创建，分为三个版本分支（branch）： stable, testing 和unstable。其中，unstable为最新的测试版本，其中包括最新的软件包，但是也有相对较多的bug，适合桌面用户。testing的版本都经过unstable中的测试，相对较为稳定，也支持了不少新技术（比如SMP等）。而stable一般只用于服务器，上面的软件包大部分都比较过时，但是稳定和安全性都非常的高。Debian最具特色的是apt-get / dpkg包管理方式，其实Redhat的YUM也是在模仿Debian的APT方式，但在二进制文件发行方式中，APT应该是最好的了。Debian的资料也很丰富，有很多支持的社区，有问题求教也有地方可去。Debian是包括Ubuntu在内许多发行版的上游，而Ubuntu又是Linux Mint及其他发行版的上游。Debian在服务器和桌面电脑领域都有着广泛的应用。Debian是一个纯开源计划并着重在一个关键点上，稳定性。它同时也提供了最大的和完整的软件仓库给用户。 Ubuntu是基于Debian的unstable版本加强而来，可以这么说，Ubuntu就是一个拥有Debian所有的优点，以及自己所加强的优点的近乎完美的 Linux桌面系统。根据选择的桌面系统不同，有三个版本可供选择，基于Gnome的Ubuntu，基于KDE的Kubuntu以及基于Xfc的Xubuntu。特点是界面非常友好，容易上手，对硬件的支持非常全面，是最适合做桌面系统的Linux发行版本。 Slackware LinuxSlackware Linux是由Patrick Volkerding开发的GNU/Linux发行版。与很多其他的发行版不同，它坚持KISS(Keep It Simple Stupid)的原则。一开始，配置系统会有一些困难，但是更有经验的用户会喜欢这种方式的透明性和灵活性。 Slackware 很多特性体现出了KISS原则，最为有名的一些例子就是不依赖图形界面的文本化系统配置、传统的服务管理方式和不解决依赖的包管理方式。它的最大特点就是安装灵活，目录结构严谨，版本力求稳定而非追新。Slackware的软件包都是通常的tgz(tar/gzip) 或者txz(xz) 格式文件再加上安装脚本。Tgz/Txz 对于有经验的用户来说，比RPM更为灵活，并避免了APT 之类管理器可能带来的的依赖地狱。 作为开源软件，Slackware与商业版本的关系并不大，但与几家提供付费支持的厂商一直保持的合作关系。作为最早的可用版本之一，Slackware Linux是由Patrick Volkerding开发的GNU/Linux发行版。与很多其他的发行版不同，它坚持KISS(Keep It Simple Stupid)的原则，就是说尽量不依赖配置系统的图形界面工具。其安装程序也是一些Dialog界面的shell脚本写成，你可以在安装的任何时候跳到任何安装步骤，而且这些脚本在安装之后也可以很方便的使用 Slackware与其他的发行版本（Red Hat、Debian、Gentoo、SuSE、 Mandriva、Ubuntu等）不同的道路，它力图成为“UNIX风格”的Linux发行版本。只吸收稳定版本的应用程序，并且缺少其他linux版本中那些为发行版本定制的配置工具。在当今systemd大势所趋的情况下，Slackware仍然坚持BSD启动风格。 Slackware主要为x86 PC开发，从2005年起开始出现针对System/390架构的官方移植。同时ARM、DEC Alpha、SPARC和PowerPC也存在一些非官方的移植。Slackware官方维护着一个开发版本（Slackware Current），不断有新的软件被加入到这个源，用户可以实现类似Archlinux的滚动升级，等到一个开发版本足够稳定，便会发布一个稳定版。Slackware是支持x86、amd64（即x86_64）、ARM、Alpha、SPARC、PowerPC的一套GNU/Linux操作系统，其正式发布由PatrickVolkerding 负责。 Linux发行版汇总 Linux各发行版的联系与区别：联系： 各发行版本均采用Linux的内核（kernel）； 各发行版本均遵守GPL版权协定； 各发行版本均遵循 Linux Standard Base (LSB)等标准来开发； 各发行版本均遵循FHS（File system Hierarchy Standard）标准规范； 区别： 不同的发行版采用的软件包管理方式不同；最有名的是 debain 的 deb 包，redhat 的 rpm 包，slackware 等的 tgz 包。 发行初衷不同，导致特点也不同，见下图： 三、Linux的哲学思想 一切皆文件 由众多的单一的程序完成一件比较复杂的工作，一个程序只做一件事，并且做好他。 尽量避免与用户交互 使用文本文件保存配置信息 提供机制（可选的策略、是一种框架），而非策略，提供做大的灵活性。 四、Linux系统上常用命令的使用格式命令的语法通用格式：COMMAND OPTIONS ARGUMENTS COMMAND说明发起命令时将请求内核将某个二进制程序运行为一个进程，命令本身是一个可执行的程序文件，二进制格式的文件有可能会调用共享库文件。[遵循ELF格式规范] 多数系统命令程序文件都存放在：/bin,/sbin,/usr/bin,/usr/sbin,/usr/local/bin,/usr/local/sbin，它们又分为普通命令和管理命令。 普通命令：存放在/bin,/usr/bin,/usr/local/bin 管理命令：存放在/sbin,/usr/sbin,/usr/local/sbin 用到的库文件都存放在：/lib,/lib64,/usr/lib,/usr/lib64,/usr/local/lib,/usr/local/lib64，它们分为32位和64位的库文件，32位使用于32位的操作系统，64位使用于64位的操作系统，64位兼容32位，而32不兼容64 32位库：存放在/lib,/usr/lib,/usr/local/lib 64位库：存放在/lib64,/usr/lib64,/usr/local/lib64 命令分为两类：​由shell自带的命令，叫作内嵌命令(builtin) 独立的可执行程序文件，文件名即命令名，叫作外部命令 查看命令的内容的类型： file命令： 例：~]# file /bin/ls 查看命令的类型： type命令： 例：~]# type COMMAND 注意：并非所有的命令都有一个在某目录与之对应的可执行程序文件 OPTIONS说明：指定命令的运行特性，有两种表现形式： 短选项：-C，例如 ls -l ,-d 注：有的命令选项没有 – ，同一命令同时使用多个短选项可合并：ls -ld 长选项：–word，例如 ls –help，有时候选项也带参数，例：du -h –max-depth=1 注：长选项不能合并 ARGUMENTS说明：参数：命令的作用对象，命令对什么生效，例：ls /etc ,作用在/etc 。注：有些命令可以可同时带多个参数，以空白分隔 常用命令示例：ifconfig作用：显示和配置网络信息 语法：ifconfig [网络设备][参数] 示例：ifconfig -a echo作用：显示文本 语法：echo [-ne][字符串]或 echo [–help][–version] 示例：echo ‘Hello World’ tty作用：显示终端机连接标准输入设备的文件名称 语法：tty [-s][–help][–version] 示例：tty startx作用：进入图形操作界面 示例：startx &amp; export作用：设置或显示环境变量 语法：export [-fnp][变量名称]=[变量设置值] 示例： 123export JAVA_HOME = /home/myuser/jdk1.7.0_03export PATH = $JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar pwd作用：显示当前工作目录 语法：pwd[–help][–version] 示例：pwd history作用：列出bash保存的所有历史命令 语法：history [选项] 示例1：history 示例2:使用HISTTIMEFORMAT环境变量在历史中显示TIMESTAMP 123456789101112131415命令：export HISTTIMEFORMAT='%F %T '$history输出如下：642 2016-10-25 17:05:46 ll643 2016-10-25 17:05:46 rm 333 644 2016-10-25 17:05:46 ll /etc/fstab 645 2016-10-25 17:05:51 history --help646 2016-10-25 17:05:59 history -h647 2016-10-25 17:06:14 man history648 2016-10-25 17:07:53 history 649 2016-10-25 17:07:57 export HISTTIMEFORMAT='%F %T '650 2016-10-25 17:07:59 history shutdown作用：系统关机命令 语法：shutdown [-cfFhknr][-t 秒数][时间][警告信息] 示例：shuntdown -r +5 poweroff作用：关机 语法：这个命令还说啥语法啊，生产环境上不要随便执行这个命令，否则会被捆绑、滴蜡、爆菊啊~ 示例：poweroff reboot作用：重启 语法：运维常用作死命令之一，最好在头脑清醒的前提下执行。 示例：reboot hwclock作用：用来查询和设置硬件时钟 语法： 123-r, --show 读取并打印硬件时钟（read hardware clock and print result ）-s, --hctosys 将硬件时钟同步到系统时钟（set the system time from the hardware clock ）-w, --systohc 将系统时钟同步到硬件时钟（set the hardware clock to the current system time ） 示例： 12[root@centos ~]# hwclock -r2016年10月25日 星期二 17时32分28秒 -0.671802 seconds date作用：取一个特定时间的linux时间戳 语法：date [参数]… [+格式] 示例： 12[root@centos ~]# date2016年 10月 25日 星期二 17:33:17 CST 五、如何在Linux系统上获取命令的帮助信息，请详细列出，并描述man文档的章节时如何划分的获取命令的使用帮助：12345678内部命令： help COMMAND外部命令： (1) 命令自带简要格式的使用帮助 # COMMAND –help (2) 使用手册：manual 位置：/usr/share/man # man COMMAND 先执行type COMMNAD 识别是内部命令还是外部命令 12345678910111213141516171819(3) info COMMAND 获取命令的在线文档；(4) 很多应用程序会自带帮助文档：/usr/share/doc/APP-VERSION README：程序的相关的信息； INSTALL: 安装帮助； CHANGES：版本迭代时的改动信息；(5) 主流发行版官方文档 http://www.redhat.com/doc(6) 程序官方的文档： 官方站点上的“Document”(7) 搜索引擎 google、baidu keyword filetype:pdf （输入文章类型更有针对性） keyword site:domain.tld man 文档章节如何划分使用手册：压缩格式的文件，有章节之分； /usr/share/man man1, man2, … 123456781：用户命令； （普通用户和管理员）2：系统调用；3：C库调用；4：设备文件及特殊文件；5：文件格式；（配置文件格式）6：游戏使用帮助；7：杂项；8：管理工具及守护进行； Linux发行版的基础目录名称命名法则及其功用规定FHS：1FHS：全称Filesystem Hierarchy Standard，其定义了两层规范， /下面的各个目录应该要放什么数据：12345678910111213141516171819202122232425262728293031/bin：所有用户可用的基本命令程序文件；/sbin：供系统管理使用的工具程序；/boot：引导加载器必须用到的各静态文件：kernel，initramfs（initrd），grub等；/dev：存储特殊文件或设备文件；设备有两种类型：字符设备（线性设备）例如：键盘、显示器；块设备（随机设备）例如：硬盘、内存；/etc：系统程序的配置文件，只能为静态/home：普通用户的家目录的集中位置；一般每个普通用户的家目录默认为此目录下与用户名同名的子目录，/home/USERNAME；/root：管理员的家目录；可选/lib：为系统启动或根文件系统上的应用程序（/bin，/sbin等）提供共享库，以及为内核提供的内核参数模块； libc.so.：动态链接的C库； ld：运行时链接器/加载器； modules：用于存储内核模块的目录；/lib64：64位系统特有的存放64位共享库的路径；/media：便携式设备挂载点，cdrom，floppy等；/mnt：其它文件系统的临时挂载点；/opt：附加应用程序的安装位置；可选路径；/srv：当前主机为服务提供的数据；/tmp：为那些会产生临时文件的程序提供的用于存储临时文件的目录；可供所有用户执行写入操作；有特殊权限；/usr：usr Hierarchy，全局共享的只读数据路径；/var：/var Hierarchy，存储经常发生变化的数据的目录；","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://zhusas.github.io/tags/linux/"}]},{"title":"MySQL启用的SSL连接的思考与实践","slug":"mysql-ssl","date":"2018-08-01T10:21:00.000Z","updated":"2018-08-02T02:36:02.010Z","comments":true,"path":"2018/08/01/mysql-ssl/","link":"","permalink":"https://zhusas.github.io/2018/08/01/mysql-ssl/","excerpt":"MySQL启用的SSL连接的思考与实践 由于工作上的业务发展和等保三级合规的要求，需要考虑为MySQL启用SSL连接，那么今天就来说说这个怎么玩。其实一个月前已经在实现了用docker跑MySQL SSL了，只不过后到今天才有时间静下心来总结一下。 有必要使用为MySQL启用SSL吗？先来了解一下SSL吧： SSL（Secure Socket Layer：安全套接字层）利用数据加密、身份验证和消息完整性验证机制，为基于TCP等可靠连接的应用层协议提供安全性保证。","text":"MySQL启用的SSL连接的思考与实践 由于工作上的业务发展和等保三级合规的要求，需要考虑为MySQL启用SSL连接，那么今天就来说说这个怎么玩。其实一个月前已经在实现了用docker跑MySQL SSL了，只不过后到今天才有时间静下心来总结一下。 有必要使用为MySQL启用SSL吗？先来了解一下SSL吧： SSL（Secure Socket Layer：安全套接字层）利用数据加密、身份验证和消息完整性验证机制，为基于TCP等可靠连接的应用层协议提供安全性保证。 SSL协议提供的功能主要有： ​ 1、 数据传输的机密性：利用对称密钥算法对传输的数据进行加密。 2.、身份验证机制：基于证书利用数字签名方法对服务器和客户端进行身份验证，其中客户端的身份验证是可选的。 3、 消息完整性验证：消息传输过程中使用MAC算法来检验消息的完整性。 如果用户的传输不是通过SSL的方式，那么其在网络中数据都是以明文进行传输的，而这给别有用心的人带来了可乘之机。所以，现在很多大型网站都开启了SSL功能。同样地，在我们数据库方面，如果客户端连接服务器获取数据不是使用SSL连接，那么在传输过程中，数据就有可能被窃取。 所以，我认为启用SSL是一个不错的选择。 那么SSL如何工作在MySQL中的这里分两说，因为工作中我涉及到MySQL5.6和MySQL 5.7两个版本，它们在SSL连接的实现上也有少许区别。 MySQL5.6的SSL MySQL 5.6中的SSL文档非常详细，它解释了SSL的工作原理。但首先让我们说清楚一点：MySQL支持使用TLS（传输层安全性）协议在客户端和服务器之间建立安全（加密）连接。 TLS有时被称为SSL（安全套接字层），但MySQL实际上并不使用SSL协议进行安全连接，因为它提供弱加密。 因此，当我们有人说MySQL正在使用SSL时，它实际上意味着它正在使用TLS。您可以使用以下命令检查您使用的协议： 123456show status like &apos;Ssl_version&apos;;+---------------+---------+| Variable_name | Value |+---------------+---------+| Ssl_version | TLSv1.2 |+---------------+---------+ TLS使用加密算法来确保可以信任通过公共网络接收的数据。它具有检测数据更改，丢失或重放的机制。 TLS还包含使用X509标准提供身份验证的算法。 X509可以识别互联网上的某个人。在基本术语中，应该有一些称为“证书颁发机构”（或CA）的实体，它将电子证书分配给需要它们的任何人。证书依赖于具有两个加密密钥（公钥和密钥）的非对称加密算法。证书所有者可以将证书提供给另一方作为身份证明。证书由其所有者的公钥组成。使用该公钥加密的任何数据只能使用由证书所有者持有的相应密钥解密。 MySQL5.6只支持TLSv1，MySQL5.7则支持TLSv1, TLSv1.1, and TLSv1.2 。 MySQL支持使用TLS协议的加密连接： 使用OpenSSL 1.0.1或更高版本编译时，MySQL支持TLSv1，TLSv1.1和TLSv1.2协议。 当使用捆绑版本的yaSSL进行编译时，MySQL支持TLSv1和TLSv1.1协议。 使用SSL配置服务器时，客户端必须具有客户端证书。获得后，它可以使用SSL连接到服务器。MySQL5.6的客户端必须指定密钥和证书。否则，我们无法使用SSL连接到服务器。 如下： my.cnf配置文件如下： 1234567891011121314151617[mysqld]skip-host-cacheskip-name-resolvepid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.sockdatadir = /var/lib/mysql#log-error = /var/log/mysql/error.log# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0ssl-ca=/etc/mysql/certs/ca.pemssl-cert=/etc/mysql/certs/MySQL1-cert.pemssl-key=/etc/mysql/certs/MySQL1-key.pem[client]ssl-ca=/etc/mysql/certs/ca.pemssl-cert=/etc/mysql/certs/MySQL-client-cert.pemssl-key=/etc/mysql/certs/MySQL-client-key.pem 客户端连接： 1mysql --ssl-ca=/etc/mysql/certs/ca.pem --ssl-cert=/etc/mysql/certs/MySQL-client-cert.pem --ssl-key=/etc/mysql/certs/MySQL-client-key.pem MySQL5.7的SSL 默认情况下，如果服务器支持加密连接，MySQL程序将尝试使用加密进行连接，如果无法建立加密连接，则会回退到未加密的连接。有关影响加密连接使用的选项的信息 。MySQL基于每个连接执行加密，并且对给定用户使用加密可以是可选的或强制的。可以根据各个应用程序的要求选择加密或未加密的连接。在CREATE USER的时候，有SSL相关的参数可以选择，这个创建用户参数取决于其用户连接时，是否必须使用密钥文件连接MySQL。 这些在官方文档里面都有说明，可以去详细了解下。这里就不铺开了。 MySQL 5.7中的加密连接支持进行了一些改进。以下时间表总结了这些变化： 5.7.3：在客户端，明确的–ssl选项不再是建议性的，而是规定性的。如果服务器支持加密连接，则客户端程序可以通过仅指定–ssl选项来要求加密连接。 （以前，客户端必须指定–ssl-ca选项，或者所有三个–ssl-ca， –ssl-key和–ssl-cert选项。）连接尝试失败如果无法建立加密连接。客户端的其他–ssl-xxx选项在没有–ssl的情况下是建议性的：客户端尝试使用加密进行连接，但如果无法建立加密连接，则会回退到未加密的连接。 5.7.5：默认情况下启用服务器端–ssl选项值。 对于使用OpenSSL编译的服务器，auto_generate_certs和sha256_password_auto_generate_rsa_keys系统变量可用于在启动时启用SSL / RSA证书和密钥文件的自动生成和自动发现。对于证书和密钥自动发现，如果启用了–ssl并且未给出其他–ssl-xxx选项以明确配置加密连接，则服务器会在启动时尝试自动启用对加密连接的支持，如果它发现必需的证书和密钥文件在数据目录中。 5.7.6：mysql_ssl_rsa_setup实用程序可用于手动生成SSL / RSA证书和密钥文件。启动时自动发现SSL / RSA文件将扩展为适用于所有服务器，无论是使用OpenSSL还是使用yaSSL编译。 （这意味着无需启用auto_generate_certs即可进行自动发现。） 如果服务器在启动时发现CA证书是自签名的，则会向错误日志写入警告。 （如果服务器自动创建证书，则证书是自签名的，或者使用mysql_ssl_rsa_setup手动创建证书。） 5.7.7：如果服务器支持加密连接，则C客户端库会默认尝试建立加密连接。这会影响客户程序，如下所示： 如果没有–ssl选项，客户端将尝试使用加密进行连接，如果无法建立加密连接，则会回退到未加密的连接。 显式–ssl选项或同义词（–ssl = 1， - enable-ssl）的存在是规定性的：客户端需要加密连接，如果无法建立，则会失败。 使用–ssl = 0选项或同义词（–skip-ssl， - disable-ssl），客户端使用未加密的连接.此更改还会影响基于C客户端库的MySQL连接器的后续版本：Connector / C，Connector / C ++和Connector / ODBC。 5.7.8：require_secure_transport系统变量可用于控制与服务器的客户端连接是否必须使用某种形式的安全传输。 5.7.10：TLS协议支持从TLSv1扩展到TLSv1.1和TLSv1.2。服务器端的tls_version系统变量和客户端的–tls-version选项可以选择支持级别。 5.7.11：MySQL客户端程序支持–ssl-mode选项，使您可以指定与服务器的连接的安全状态。 –ssl-mode选项包括客户端–ssl和–ssl-verify-server-cert选项的功能。因此，不推荐使用–ssl和–ssl-verify-server-cert，MySQL 8.0中已经删除它们。 好，上边说了这么多，各位都看明白了吗？不明白也没关系，我下面用docker来演示 坑点：我用许多客户端应用程序对它进行了测试，无论是MySQL5.6或5.7，MySQL客户端连接服务端时必须指定客户端密钥。没有密钥，无法连接到服务器。某些较旧的应用程序可能不支持此功能。 所以啊，官档说的也不一定全对。 实践这里以MySQL5.6为例 1、建立目录 1234# mkdir -pv mysql_ssl_&#123;data,config,cert&#125;mkdir: created directory 'mysql_ssl_data'mkdir: created directory 'mysql_ssl_config'mkdir: created directory 'mysql_ssl_cert' 准备好数据、证书、配置等文件 2、启动容器 1docker run --name mysql5.6_ssl_test -v /data/mysql_ssl_data/:/var/lib/mysql -v /data/mysql_ssl_config/my.cnf:/etc/my.cnf -v /data/mysql_ssl_cert/:/etc/mysql/certs -p 3306:3306 mysql:5.6.40 3、因为MySQL5.6默认用户是不开启SSL认证的，需要进行如下操作： 12345#修改已存在用户 GRANT USAGE ON *.* TO `user`@`%` REQUIRE X509;#新建必须使用SSL用户grant all privileges on *.* to 'user'@'%' identified by '111111' with grant option;GRANT USAGE ON *.* TO `user`@`%` REQUIRE X509; 对于具有REQUIRE X509的帐户，客户端必须指定要连接的–ssl-key和–ssl-cert选项。 （建议但不要求也指定–ssl-ca，以便验证服务器提供的公共证书。）对于ISSUER和SUBJECT也是如此，因为这些REQUIRE选项意味着X509的要求。 好，现在无论是用图形化工具还是使用命令行客户端，都必须指定客户端的证书及密钥文件，加上账户密码，才能连接登录MySQL了。 参考资料： https://www.cnblogs.com/mysql-dba/p/7061300.html https://dev.mysql.com/doc/refman/5.7/en/encrypted-connection-protocols-ciphers.html https://dev.mysql.com/doc/refman/5.6/en/encrypted-connection-protocols-ciphers.html https://dev.mysql.com/doc/refman/5.6/en/encrypted-connections.html https://dev.mysql.com/doc/refman/5.7/en/encrypted-connections.html ​","categories":[],"tags":[{"name":"SSL,MySQL","slug":"SSL-MySQL","permalink":"https://zhusas.github.io/tags/SSL-MySQL/"}]},{"title":"MongoDB备份数据引擎升级","slug":"mongodb","date":"2018-07-09T05:38:00.000Z","updated":"2018-07-31T06:42:32.431Z","comments":true,"path":"2018/07/09/mongodb/","link":"","permalink":"https://zhusas.github.io/2018/07/09/mongodb/","excerpt":"MongoDB备份数据引擎升级准备工作 确认已经安装需要运行的MongoDB版本 确保有足够的空间进行数据导出导入 您必须使用MongoDB版本3.0或更高版本才能使用WireldTiger存储引擎。 如果使用较早的MongoDB版本，则必须在继续更改存储引擎之前升级MongoDB版本。本文使用的是MongoDB 3.6 本文使用docker来操作，请自行安装好docker环境。","text":"MongoDB备份数据引擎升级准备工作 确认已经安装需要运行的MongoDB版本 确保有足够的空间进行数据导出导入 您必须使用MongoDB版本3.0或更高版本才能使用WireldTiger存储引擎。 如果使用较早的MongoDB版本，则必须在继续更改存储引擎之前升级MongoDB版本。本文使用的是MongoDB 3.6 本文使用docker来操作，请自行安装好docker环境。 直接在裸机安装MongoDB 3.6进行操作亦可。 这里演示从MongoDB 2.6备份出来的数据还原到MongoDB 3.6 并以WireldTiger引擎启动运行 步骤 1、启动你要运行的MongoDB版本，本文用的是3.6 ，Docker运行，配置文件写明要以wiredTiger 启动。 1docker run -d --name $CONTAINER_NAME -v $DATA_PATH:/data/db -v $OLD_DATA_PATH:/data2 -v /$CONFIG_PATH/mongod.conf:/etc/mongod.conf.orig -p $IP:27017:27017 mongo:3.6 变量名 作用说明 $CONTAINER_NAME 自定义的容器名字 $DATA_PATH 容器在宿主机上的数据卷路径 $OLD_DATA_PATH 待升级的老版本MongoDB备份数据 $CONFIG_PATH 新版MongoDB的配置文件目录 $IP MongoDB容器对外提供服务的IP地址 配置文件 123456789101112131415161718192021# Where and how to store data.storage: dbPath: /var/lib/mongodb journal: enabled: true engine: wiredTiger# where to write logging data. systemLog: destination: file logAppend: true path: /var/log/mongodb/mongod.log# network interfaces net: port: 27017 bindIp: 127.0.0.1# how the process runs processManagement: timeZoneInfo: /usr/share/zoneinfo 2、把 MongoDB 2.6的备份数据解压到$OLD_DATA_PATH 3、进入MongoDB 3.6的容器中执行以下命令 12docker exec -it $CONTAINER_NAME /bin/bash #进入docker并分配bash终端mongorestore data2/ #从data2目录中导入备份数据 OK，接下来静候佳音即可。中间会有一段漫长的导入数据，转换引擎，重建索引的过程。 当然，你要是土豪，用固态硬盘也是极好的。 4、最后一步，查看一下数据引擎。运行db.serverStatus()命令,查询结果包含如下内容即可： 12345\"storageEngine\" : &#123; \"name\" : \"wiredTiger\", \"supportsCommittedReads\" : true, \"readOnly\" : false, \"persistent\" : true","categories":[],"tags":[{"name":"MongoDB,Docker","slug":"MongoDB-Docker","permalink":"https://zhusas.github.io/tags/MongoDB-Docker/"}]}]}